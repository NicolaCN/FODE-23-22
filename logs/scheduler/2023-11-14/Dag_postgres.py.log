[2023-11-14T07:59:11.883+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T07:59:11.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T07:59:11.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:11.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T07:59:14.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T07:59:16.477+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:16.476+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T07:59:16.482+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:16.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T07:59:16.633+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:16.633+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T07:59:16.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.927 seconds
[2023-11-14T07:59:47.493+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T07:59:47.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T07:59:47.512+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:47.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T07:59:48.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T07:59:49.129+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:49.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T07:59:49.226+0000] {logging_mixin.py:151} INFO - [2023-11-14T07:59:49.226+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T07:59:49.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.825 seconds
[2023-11-14T08:00:19.836+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:00:19.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:00:19.841+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:00:19.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:00:20.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:00:20.659+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:00:20.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:00:20.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:00:20.700+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:00:20.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.913 seconds
[2023-11-14T08:00:51.362+0000] {processor.py:157} INFO - Started process (PID=185) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:00:51.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:00:51.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:00:51.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:00:52.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:00:52.287+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:00:52.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:00:52.426+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:00:52.425+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:00:52.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.146 seconds
[2023-11-14T08:01:23.118+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:01:23.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:01:23.127+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:01:23.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:01:23.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:01:23.860+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:01:23.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:01:23.897+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:01:23.896+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:01:23.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.835 seconds
[2023-11-14T08:01:54.522+0000] {processor.py:157} INFO - Started process (PID=227) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:01:54.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:01:54.569+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:01:54.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:01:55.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:01:55.425+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:01:55.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:01:55.465+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:01:55.464+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:01:55.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.002 seconds
[2023-11-14T08:02:26.053+0000] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:02:26.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:02:26.057+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:02:26.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:02:26.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:02:26.899+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:02:26.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:02:26.948+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:02:26.948+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:02:26.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.943 seconds
[2023-11-14T08:02:57.551+0000] {processor.py:157} INFO - Started process (PID=278) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:02:57.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:02:57.558+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:02:57.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:02:58.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:02:58.626+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:02:58.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:02:58.667+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:02:58.667+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:02:58.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.209 seconds
[2023-11-14T08:03:29.119+0000] {processor.py:157} INFO - Started process (PID=297) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:03:29.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:03:29.134+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:03:29.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:03:29.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:03:29.765+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:03:29.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:03:29.802+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:03:29.802+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:03:29.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.739 seconds
[2023-11-14T08:04:00.510+0000] {processor.py:157} INFO - Started process (PID=317) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:04:00.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:04:00.522+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:04:00.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:04:01.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:04:01.621+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:04:01.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:04:01.718+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:04:01.717+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:04:01.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.290 seconds
[2023-11-14T08:04:32.860+0000] {processor.py:157} INFO - Started process (PID=342) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:04:32.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:04:32.869+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:04:32.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:04:35.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:04:35.788+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:04:35.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:04:35.833+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:04:35.832+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:04:35.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.028 seconds
[2023-11-14T08:05:06.547+0000] {processor.py:157} INFO - Started process (PID=365) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:06.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:05:06.552+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:06.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:07.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:07.899+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:07.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:05:07.989+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:07.988+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:05:08.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.573 seconds
[2023-11-14T08:05:38.585+0000] {processor.py:157} INFO - Started process (PID=392) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:38.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:05:38.589+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:38.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:39.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:39.407+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:39.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:05:39.449+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:39.449+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:05:39.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.901 seconds
[2023-11-14T08:05:58.874+0000] {processor.py:157} INFO - Started process (PID=405) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:58.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:05:58.889+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:58.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:59.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:05:59.953+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:05:59.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:06:00.000+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:00.000+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:06:00.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.207 seconds
[2023-11-14T08:06:01.035+0000] {processor.py:157} INFO - Started process (PID=407) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:06:01.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:06:01.039+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:01.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:06:01.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:06:01.975+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:01.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:06:02.014+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:02.013+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:06:02.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.064 seconds
[2023-11-14T08:06:32.504+0000] {processor.py:157} INFO - Started process (PID=428) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:06:32.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:06:32.507+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:32.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:06:33.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:06:33.147+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:33.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:06:33.188+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:06:33.187+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:06:33.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.719 seconds
[2023-11-14T08:07:04.086+0000] {processor.py:157} INFO - Started process (PID=449) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:04.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:04.091+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:04.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:04.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:04.838+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:04.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:04.887+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:04.887+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:04.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.852 seconds
[2023-11-14T08:07:07.124+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:07.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:07.126+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:07.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:07.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:07.839+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:07.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:07.878+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:07.878+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:07.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.865 seconds
[2023-11-14T08:07:09.146+0000] {processor.py:157} INFO - Started process (PID=460) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:09.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:09.151+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:09.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:09.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:09.944+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:09.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:09.983+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:09.982+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:10.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.903 seconds
[2023-11-14T08:07:13.271+0000] {processor.py:157} INFO - Started process (PID=463) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:13.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:13.279+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:13.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:14.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:14.454+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:14.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:14.495+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:14.494+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:14.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.372 seconds
[2023-11-14T08:07:17.503+0000] {processor.py:157} INFO - Started process (PID=467) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:17.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:17.512+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:17.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:18.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:18.533+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:18.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:18.575+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:18.575+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:18.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.196 seconds
[2023-11-14T08:07:19.510+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:19.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:19.513+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:19.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:20.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:20.262+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:20.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:20.323+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:20.323+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:20.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.879 seconds
[2023-11-14T08:07:24.714+0000] {processor.py:157} INFO - Started process (PID=480) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:24.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:24.728+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:24.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:25.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:25.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:25.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:25.880+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:25.879+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.263 seconds
[2023-11-14T08:07:35.305+0000] {processor.py:157} INFO - Started process (PID=482) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:35.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:35.312+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:35.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:36.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:36.359+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:36.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:36.406+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:36.406+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:36.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.173 seconds
[2023-11-14T08:07:37.359+0000] {processor.py:157} INFO - Started process (PID=484) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:37.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:37.364+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:37.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:38.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:38.261+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:38.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:38.381+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:38.379+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:38.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.166 seconds
[2023-11-14T08:07:51.662+0000] {processor.py:157} INFO - Started process (PID=496) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:51.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:07:51.780+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:51.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:53.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:07:53.640+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:53.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:07:53.687+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:07:53.687+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:07:53.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.082 seconds
[2023-11-14T08:08:23.817+0000] {processor.py:157} INFO - Started process (PID=524) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:08:23.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:08:23.819+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:08:23.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:08:24.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:08:24.856+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:08:24.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:08:24.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:08:24.941+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:08:24.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.174 seconds
[2023-11-14T08:08:55.197+0000] {processor.py:157} INFO - Started process (PID=544) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:08:55.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:08:55.205+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:08:55.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:08:56.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:08:56.397+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:08:56.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:08:56.527+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:08:56.527+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:08:56.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.400 seconds
[2023-11-14T08:09:27.179+0000] {processor.py:157} INFO - Started process (PID=569) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:09:27.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:09:27.182+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:09:27.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:09:27.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:09:28.054+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:09:28.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:09:28.236+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:09:28.236+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:09:28.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.138 seconds
[2023-11-14T08:09:59.151+0000] {processor.py:157} INFO - Started process (PID=590) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:09:59.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:09:59.175+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:09:59.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:00.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:00.484+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:00.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:10:00.535+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:00.535+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:10:00.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.571 seconds
[2023-11-14T08:10:31.355+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:31.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:10:31.367+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:31.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:32.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:32.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:32.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:10:32.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:32.335+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:10:32.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.126 seconds
[2023-11-14T08:10:46.603+0000] {processor.py:157} INFO - Started process (PID=619) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:46.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:10:46.607+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:46.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:47.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:47.486+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:47.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:10:47.546+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:47.546+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:10:47.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.055 seconds
[2023-11-14T08:10:48.834+0000] {processor.py:157} INFO - Started process (PID=621) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:48.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:10:48.837+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:48.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:49.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:49.706+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:49.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:10:49.746+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:49.746+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:10:49.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.042 seconds
[2023-11-14T08:10:50.942+0000] {processor.py:157} INFO - Started process (PID=623) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:50.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:10:50.945+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:50.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:51.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:10:51.959+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:51.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:10:52.003+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:10:52.002+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:10:52.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.106 seconds
[2023-11-14T08:11:22.974+0000] {processor.py:157} INFO - Started process (PID=651) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:11:22.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:11:22.985+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:11:22.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:11:26.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:11:26.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:11:26.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:11:26.825+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:11:26.825+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:11:26.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.951 seconds
[2023-11-14T08:11:57.248+0000] {processor.py:157} INFO - Started process (PID=671) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:11:57.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:11:57.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:11:57.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:11:57.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:11:58.002+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:11:58.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:11:58.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:11:58.060+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:11:58.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.863 seconds
[2023-11-14T08:12:28.817+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:28.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:12:28.822+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:28.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:29.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:29.854+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:29.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:12:29.973+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:29.973+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:12:30.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.257 seconds
[2023-11-14T08:12:42.168+0000] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:42.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:12:42.171+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:42.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:43.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:43.292+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:43.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:12:43.410+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:43.410+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:12:43.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.423 seconds
[2023-11-14T08:12:44.462+0000] {processor.py:157} INFO - Started process (PID=706) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:44.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:12:44.474+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:44.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:45.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:45.903+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:45.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:12:45.951+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:45.950+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:12:46.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.559 seconds
[2023-11-14T08:12:47.208+0000] {processor.py:157} INFO - Started process (PID=708) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:47.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:12:47.212+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:47.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:48.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:12:49.005+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:49.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:12:49.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:12:49.066+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:12:49.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.913 seconds
[2023-11-14T08:13:19.371+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:13:19.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:13:19.380+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:13:19.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:13:20.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:13:20.823+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:13:20.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:13:20.887+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:13:20.886+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:13:20.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.592 seconds
[2023-11-14T08:13:51.477+0000] {processor.py:157} INFO - Started process (PID=756) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:13:51.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:13:51.487+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:13:51.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:13:52.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:13:53.037+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:13:53.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:13:53.076+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:13:53.076+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:13:53.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.708 seconds
[2023-11-14T08:14:18.386+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:14:18.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:14:18.398+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:14:18.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:14:19.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:14:19.601+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:14:19.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:14:19.651+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:14:19.651+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:14:19.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.375 seconds
[2023-11-14T08:14:50.195+0000] {processor.py:157} INFO - Started process (PID=798) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:14:50.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:14:50.198+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:14:50.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:14:50.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:14:50.930+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:14:50.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:14:50.964+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:14:50.964+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:14:51.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.876 seconds
[2023-11-14T08:15:18.681+0000] {processor.py:157} INFO - Started process (PID=818) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:15:18.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:15:18.688+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:15:18.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:15:19.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:15:19.209+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:15:19.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:15:19.247+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:15:19.247+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:15:21.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.970 seconds
[2023-11-14T08:15:28.907+0000] {processor.py:157} INFO - Started process (PID=828) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:15:28.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:15:28.911+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:15:28.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:15:30.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:15:30.134+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:15:30.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:15:30.164+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:15:30.164+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:15:30.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.293 seconds
[2023-11-14T08:16:00.484+0000] {processor.py:157} INFO - Started process (PID=857) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:16:00.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:16:00.489+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:16:00.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:16:01.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:16:01.218+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:16:01.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:16:01.260+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:16:01.260+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:16:01.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.860 seconds
[2023-11-14T08:16:31.698+0000] {processor.py:157} INFO - Started process (PID=878) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:16:31.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:16:31.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:16:31.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:16:32.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:16:32.135+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:16:32.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:16:32.160+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:16:32.160+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:16:32.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.488 seconds
[2023-11-14T08:17:02.507+0000] {processor.py:157} INFO - Started process (PID=908) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:02.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:02.511+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:02.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:02.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:02.974+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:02.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:03.003+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:03.003+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:03.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.524 seconds
[2023-11-14T08:17:17.790+0000] {processor.py:157} INFO - Started process (PID=920) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:17.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:17.793+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:17.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:18.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:18.417+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:18.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:18.446+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:18.445+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:18.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.708 seconds
[2023-11-14T08:17:20.272+0000] {processor.py:157} INFO - Started process (PID=922) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:20.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:20.275+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:20.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:20.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:20.788+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:20.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:20.818+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:20.818+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:20.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.598 seconds
[2023-11-14T08:17:22.613+0000] {processor.py:157} INFO - Started process (PID=924) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:22.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:22.615+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:22.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:23.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:23.273+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:23.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:23.319+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:23.318+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:24.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.453 seconds
[2023-11-14T08:17:34.064+0000] {processor.py:157} INFO - Started process (PID=935) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:34.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:34.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:34.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:34.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:34.748+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:34.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:34.786+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:34.786+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:34.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.762 seconds
[2023-11-14T08:17:41.317+0000] {processor.py:157} INFO - Started process (PID=945) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:41.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:41.320+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:41.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:41.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:41.883+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:41.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:41.911+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:41.911+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:41.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.624 seconds
[2023-11-14T08:17:46.055+0000] {processor.py:157} INFO - Started process (PID=949) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:46.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:46.058+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:46.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:46.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:46.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:46.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:46.777+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:46.776+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:46.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.765 seconds
[2023-11-14T08:17:58.999+0000] {processor.py:157} INFO - Started process (PID=959) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:59.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:17:59.003+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:59.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:59.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:17:59.519+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:59.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:17:59.559+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:17:59.558+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:17:59.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.610 seconds
[2023-11-14T08:18:01.682+0000] {processor.py:157} INFO - Started process (PID=961) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:01.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:18:01.685+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:01.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:02.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:02.275+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:02.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:18:02.306+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:02.305+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:18:02.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.833 seconds
[2023-11-14T08:18:04.230+0000] {processor.py:157} INFO - Started process (PID=963) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:04.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:18:04.232+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:04.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:04.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:04.917+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:04.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:18:05.096+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:05.096+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:18:05.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.911 seconds
[2023-11-14T08:18:11.267+0000] {processor.py:157} INFO - Started process (PID=972) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:11.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:18:11.269+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:11.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:11.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:11.890+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:11.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:18:11.924+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:11.924+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:18:11.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.694 seconds
[2023-11-14T08:18:42.379+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:42.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:18:42.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:42.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:43.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:43.226+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:43.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:18:43.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:43.285+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:18:43.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.011 seconds
[2023-11-14T08:18:51.560+0000] {processor.py:157} INFO - Started process (PID=1003) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:51.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:18:51.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:51.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:52.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:52.302+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:52.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:18:52.355+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:52.354+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:18:52.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.843 seconds
[2023-11-14T08:18:56.128+0000] {processor.py:157} INFO - Started process (PID=1005) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:56.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:18:56.131+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:56.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:57.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:18:57.243+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:57.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:18:57.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:18:57.304+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:18:57.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.694 seconds
[2023-11-14T08:19:28.669+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:19:28.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:19:28.673+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:19:28.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:19:29.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:19:29.563+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:19:29.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:19:29.606+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:19:29.606+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:19:29.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.978 seconds
[2023-11-14T08:19:59.953+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:19:59.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:19:59.955+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:19:59.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:20:00.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:20:00.405+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:20:00.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:20:00.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:20:00.435+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:20:00.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.526 seconds
[2023-11-14T08:20:30.885+0000] {processor.py:157} INFO - Started process (PID=1083) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:20:30.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:20:30.887+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:20:30.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:20:31.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:20:31.297+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:20:31.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:20:31.457+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:20:31.456+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:20:31.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.607 seconds
[2023-11-14T08:21:01.812+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:21:01.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:21:01.815+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:21:01.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:21:02.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:21:02.561+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:21:02.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:21:02.850+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:21:02.850+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:21:02.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.091 seconds
[2023-11-14T08:21:33.246+0000] {processor.py:157} INFO - Started process (PID=1134) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:21:33.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:21:33.248+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:21:33.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:21:33.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:21:33.713+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:21:33.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:21:33.741+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:21:33.741+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:21:33.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.538 seconds
[2023-11-14T08:22:04.142+0000] {processor.py:157} INFO - Started process (PID=1155) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:22:04.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:22:04.146+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:22:04.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:22:04.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:22:04.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:22:04.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:22:05.034+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:22:05.034+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:22:05.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.931 seconds
[2023-11-14T08:22:35.464+0000] {processor.py:157} INFO - Started process (PID=1182) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:22:35.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:22:35.467+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:22:35.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:22:36.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:22:36.095+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:22:36.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:22:36.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:22:36.364+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:22:36.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.938 seconds
[2023-11-14T08:23:07.251+0000] {processor.py:157} INFO - Started process (PID=1203) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:23:07.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:23:07.254+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:23:07.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:23:07.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:23:07.698+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:23:07.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:23:07.724+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:23:07.723+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:23:07.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.499 seconds
[2023-11-14T08:23:38.119+0000] {processor.py:157} INFO - Started process (PID=1230) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:23:38.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:23:38.121+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:23:38.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:23:38.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:23:38.560+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:23:38.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:23:38.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:23:38.727+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:23:38.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.635 seconds
[2023-11-14T08:24:09.127+0000] {processor.py:157} INFO - Started process (PID=1253) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:24:09.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:24:09.129+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:24:09.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:24:09.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:24:09.550+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:24:09.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:24:09.701+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:24:09.701+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:24:09.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.609 seconds
[2023-11-14T08:24:40.146+0000] {processor.py:157} INFO - Started process (PID=1273) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:24:40.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:24:40.148+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:24:40.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:24:40.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:24:40.571+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:24:40.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:24:40.597+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:24:40.596+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:24:40.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.477 seconds
[2023-11-14T08:25:10.998+0000] {processor.py:157} INFO - Started process (PID=1301) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:25:10.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:25:11.001+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:25:11.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:25:11.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:25:11.416+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:25:11.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:25:11.575+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:25:11.574+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:25:11.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.606 seconds
[2023-11-14T08:25:41.968+0000] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:25:41.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:25:41.971+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:25:41.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:25:42.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:25:42.565+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:25:42.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:25:42.602+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:25:42.602+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:25:42.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.666 seconds
[2023-11-14T08:26:12.982+0000] {processor.py:157} INFO - Started process (PID=1350) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:26:12.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:26:12.985+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:26:12.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:26:13.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:26:13.414+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:26:13.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:26:13.440+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:26:13.440+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:26:13.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.486 seconds
[2023-11-14T08:26:43.854+0000] {processor.py:157} INFO - Started process (PID=1370) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:26:43.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:26:43.856+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:26:43.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:26:44.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:26:44.284+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:26:44.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:26:44.443+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:26:44.443+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:26:44.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.627 seconds
[2023-11-14T08:27:14.757+0000] {processor.py:157} INFO - Started process (PID=1399) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:27:14.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:27:14.760+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:27:14.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:27:15.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:27:15.719+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:27:15.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:27:15.774+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:27:15.774+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:27:15.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.057 seconds
[2023-11-14T08:27:46.178+0000] {processor.py:157} INFO - Started process (PID=1420) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:27:46.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:27:46.180+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:27:46.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:27:46.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:27:46.591+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:27:46.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:27:46.617+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:27:46.616+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:27:46.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.482 seconds
[2023-11-14T08:28:17.567+0000] {processor.py:157} INFO - Started process (PID=1449) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:28:17.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:28:17.569+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:28:17.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:28:17.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:28:17.997+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:28:17.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:28:18.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:28:18.154+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:28:18.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.635 seconds
[2023-11-14T08:28:48.420+0000] {processor.py:157} INFO - Started process (PID=1471) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:28:48.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:28:48.422+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:28:48.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:28:48.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:28:48.969+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:28:48.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:28:48.996+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:28:48.996+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:28:49.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.603 seconds
[2023-11-14T08:29:19.085+0000] {processor.py:157} INFO - Started process (PID=1499) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:29:19.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:29:19.088+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:29:19.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:29:19.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:29:19.732+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:29:19.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:29:19.767+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:29:19.766+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:29:19.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.720 seconds
[2023-11-14T08:29:49.910+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:29:49.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:29:49.912+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:29:49.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:29:50.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:29:50.372+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:29:50.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:29:50.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:29:50.536+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:29:50.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.654 seconds
[2023-11-14T08:30:20.905+0000] {processor.py:157} INFO - Started process (PID=1547) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:30:20.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:30:20.907+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:30:20.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:30:21.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:30:21.560+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:30:21.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:30:21.585+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:30:21.585+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:30:21.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.706 seconds
[2023-11-14T08:30:51.939+0000] {processor.py:157} INFO - Started process (PID=1568) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:30:51.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:30:51.945+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:30:51.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:30:52.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:30:52.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:30:52.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:30:52.763+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:30:52.763+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:30:52.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.862 seconds
[2023-11-14T08:31:23.177+0000] {processor.py:157} INFO - Started process (PID=1588) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:31:23.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:31:23.180+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:31:23.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:31:23.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:31:23.635+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:31:23.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:31:23.783+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:31:23.783+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:31:23.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.633 seconds
[2023-11-14T08:31:54.111+0000] {processor.py:157} INFO - Started process (PID=1617) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:31:54.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:31:54.114+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:31:54.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:31:54.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:31:54.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:31:54.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:31:54.773+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:31:54.773+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:31:54.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.700 seconds
[2023-11-14T08:32:25.459+0000] {processor.py:157} INFO - Started process (PID=1637) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:32:25.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:32:25.461+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:32:25.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:32:26.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:32:26.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:32:26.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:32:26.085+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:32:26.085+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:32:26.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.653 seconds
[2023-11-14T08:32:56.464+0000] {processor.py:157} INFO - Started process (PID=1665) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:32:56.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:32:56.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:32:56.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:32:56.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:32:56.906+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:32:56.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:32:57.054+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:32:57.054+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:32:57.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.617 seconds
[2023-11-14T08:33:27.373+0000] {processor.py:157} INFO - Started process (PID=1686) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:33:27.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:33:27.375+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:33:27.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:33:27.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:33:27.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:33:27.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:33:27.977+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:33:27.977+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:33:28.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.633 seconds
[2023-11-14T08:33:58.296+0000] {processor.py:157} INFO - Started process (PID=1715) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:33:58.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:33:58.299+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:33:58.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:33:58.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:33:58.905+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:33:58.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:33:58.953+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:33:58.952+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:33:58.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.683 seconds
[2023-11-14T08:34:29.145+0000] {processor.py:157} INFO - Started process (PID=1736) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:34:29.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:34:29.148+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:34:29.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:34:29.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:34:29.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:34:29.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:34:29.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:34:29.726+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:34:29.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.609 seconds
[2023-11-14T08:35:00.095+0000] {processor.py:157} INFO - Started process (PID=1766) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:35:00.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:35:00.097+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:35:00.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:35:00.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:35:00.830+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:35:00.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:35:00.865+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:35:00.864+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:35:00.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.806 seconds
[2023-11-14T08:35:31.239+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:35:31.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:35:31.241+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:35:31.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:35:31.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:35:31.787+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:35:31.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:35:31.810+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:35:31.810+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:35:31.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.608 seconds
[2023-11-14T08:36:02.206+0000] {processor.py:157} INFO - Started process (PID=1815) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:36:02.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:36:02.208+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:36:02.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:36:02.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:36:02.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:36:02.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:36:02.883+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:36:02.883+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:36:02.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.711 seconds
[2023-11-14T08:36:33.293+0000] {processor.py:157} INFO - Started process (PID=1836) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:36:33.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:36:33.295+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:36:33.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:36:33.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:36:33.833+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:36:33.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:36:33.858+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:36:33.858+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:36:33.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.599 seconds
[2023-11-14T08:37:04.221+0000] {processor.py:157} INFO - Started process (PID=1865) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:37:04.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:37:04.223+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:37:04.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:37:04.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:37:04.795+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:37:04.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:37:04.819+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:37:04.819+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:37:04.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.623 seconds
[2023-11-14T08:37:35.172+0000] {processor.py:157} INFO - Started process (PID=1885) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:37:35.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:37:35.174+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:37:35.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:37:35.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:37:35.766+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:37:35.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:37:35.801+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:37:35.801+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:37:35.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.657 seconds
[2023-11-14T08:38:06.206+0000] {processor.py:157} INFO - Started process (PID=1905) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:38:06.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:38:06.208+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:38:06.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:38:06.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:38:06.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:38:06.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:38:06.770+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:38:06.770+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:38:06.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.596 seconds
[2023-11-14T08:38:37.172+0000] {processor.py:157} INFO - Started process (PID=1933) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:38:37.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:38:37.174+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:38:37.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:38:37.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:38:37.778+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:38:37.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:38:37.801+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:38:37.800+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:38:37.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.662 seconds
[2023-11-14T08:39:08.184+0000] {processor.py:157} INFO - Started process (PID=1953) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:39:08.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:39:08.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:39:08.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:39:08.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:39:08.730+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:39:08.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:39:08.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:39:08.755+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:39:08.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.606 seconds
[2023-11-14T08:39:39.105+0000] {processor.py:157} INFO - Started process (PID=1981) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:39:39.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:39:39.107+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:39:39.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:39:39.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:39:39.722+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:39:39.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:39:39.751+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:39:39.751+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:39:39.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.690 seconds
[2023-11-14T08:40:10.182+0000] {processor.py:157} INFO - Started process (PID=2002) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:40:10.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:40:10.184+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:40:10.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:40:10.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:40:10.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:40:10.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:40:10.748+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:40:10.748+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:40:10.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.604 seconds
[2023-11-14T08:40:41.121+0000] {processor.py:157} INFO - Started process (PID=2030) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:40:41.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:40:41.123+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:40:41.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:40:41.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:40:41.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:40:41.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:40:41.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:40:41.726+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:40:41.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.632 seconds
[2023-11-14T08:41:12.159+0000] {processor.py:157} INFO - Started process (PID=2052) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:41:12.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:41:12.161+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:41:12.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:41:12.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:41:12.720+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:41:12.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:41:12.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:41:12.746+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:41:12.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.625 seconds
[2023-11-14T08:41:43.152+0000] {processor.py:157} INFO - Started process (PID=2081) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:41:43.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:41:43.154+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:41:43.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:41:43.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:41:43.792+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:41:43.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:41:43.822+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:41:43.821+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:41:43.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.698 seconds
[2023-11-14T08:42:14.242+0000] {processor.py:157} INFO - Started process (PID=2102) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:42:14.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:42:14.244+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:42:14.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:42:14.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:42:14.854+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:42:14.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:42:14.882+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:42:14.882+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:42:14.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.669 seconds
[2023-11-14T08:42:45.178+0000] {processor.py:157} INFO - Started process (PID=2130) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:42:45.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:42:45.181+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:42:45.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:42:45.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:42:45.877+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:42:45.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:42:45.907+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:42:45.907+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:42:45.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.761 seconds
[2023-11-14T08:43:16.652+0000] {processor.py:157} INFO - Started process (PID=2152) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:43:16.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:43:16.655+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:43:16.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:43:17.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:43:17.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:43:17.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:43:17.281+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:43:17.281+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:43:17.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.676 seconds
[2023-11-14T08:43:47.729+0000] {processor.py:157} INFO - Started process (PID=2172) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:43:47.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:43:47.732+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:43:47.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:43:48.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:43:48.271+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:43:48.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:43:48.303+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:43:48.303+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:43:48.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.600 seconds
[2023-11-14T08:44:18.845+0000] {processor.py:157} INFO - Started process (PID=2201) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:44:18.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:44:18.848+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:44:18.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:44:19.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:44:19.378+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:44:19.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:44:19.401+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:44:19.401+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:44:19.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.591 seconds
[2023-11-14T08:44:49.839+0000] {processor.py:157} INFO - Started process (PID=2222) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:44:49.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:44:49.841+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:44:49.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:44:50.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:44:50.465+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:44:50.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:44:50.490+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:44:50.490+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:44:50.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.678 seconds
[2023-11-14T08:45:20.834+0000] {processor.py:157} INFO - Started process (PID=2251) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:45:20.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:45:20.836+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:45:20.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:45:21.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:45:21.434+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:45:21.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:45:21.465+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:45:21.465+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:45:21.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.657 seconds
[2023-11-14T08:45:51.877+0000] {processor.py:157} INFO - Started process (PID=2271) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:45:51.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:45:51.880+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:45:51.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:45:52.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:45:52.473+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:45:52.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:45:52.500+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:45:52.500+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:45:52.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.651 seconds
[2023-11-14T08:46:22.884+0000] {processor.py:157} INFO - Started process (PID=2301) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:46:22.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:46:22.888+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:46:22.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:46:23.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:46:23.501+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:46:23.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:46:23.526+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:46:23.525+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:46:23.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.684 seconds
[2023-11-14T08:46:53.887+0000] {processor.py:157} INFO - Started process (PID=2321) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:46:53.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:46:53.889+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:46:53.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:46:54.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:46:54.532+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:46:54.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:46:54.558+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:46:54.558+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:46:54.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.722 seconds
[2023-11-14T08:47:24.996+0000] {processor.py:157} INFO - Started process (PID=2349) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:47:24.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:47:24.998+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:47:24.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:47:25.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:47:25.629+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:47:25.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:47:25.659+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:47:25.659+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:47:25.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.721 seconds
[2023-11-14T08:47:56.306+0000] {processor.py:157} INFO - Started process (PID=2369) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:47:56.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:47:56.308+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:47:56.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:47:56.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:47:56.922+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:47:56.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:47:56.951+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:47:56.951+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:47:56.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.673 seconds
[2023-11-14T08:48:27.369+0000] {processor.py:157} INFO - Started process (PID=2397) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:48:27.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:48:27.372+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:48:27.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:48:28.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:48:28.295+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:48:28.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:48:28.376+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:48:28.376+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:48:28.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.060 seconds
[2023-11-14T08:48:59.110+0000] {processor.py:157} INFO - Started process (PID=2417) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:48:59.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:48:59.112+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:48:59.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:48:59.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:48:59.656+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:48:59.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:48:59.682+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:48:59.681+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:48:59.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.596 seconds
[2023-11-14T08:49:30.059+0000] {processor.py:157} INFO - Started process (PID=2439) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:49:30.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:49:30.061+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:49:30.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:49:30.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:49:30.609+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:49:30.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:49:30.633+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:49:30.633+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:49:30.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.602 seconds
[2023-11-14T08:50:00.768+0000] {processor.py:157} INFO - Started process (PID=2459) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:50:00.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:50:00.772+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:50:00.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:50:01.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:50:01.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:50:01.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:50:01.579+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:50:01.579+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:50:01.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.848 seconds
[2023-11-14T08:50:31.752+0000] {processor.py:157} INFO - Started process (PID=2488) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:50:31.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:50:31.754+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:50:31.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:50:32.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:50:32.425+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:50:32.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:50:32.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:50:32.460+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:50:32.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.745 seconds
[2023-11-14T08:51:02.654+0000] {processor.py:157} INFO - Started process (PID=2508) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:51:02.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:51:02.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:51:02.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:51:03.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:51:03.412+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:51:03.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:51:03.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:51:03.436+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:51:03.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.809 seconds
[2023-11-14T08:51:33.668+0000] {processor.py:157} INFO - Started process (PID=2529) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:51:33.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:51:33.671+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:51:33.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:51:34.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:51:34.249+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:51:34.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:51:34.278+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:51:34.277+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:51:34.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.652 seconds
[2023-11-14T08:52:04.410+0000] {processor.py:157} INFO - Started process (PID=2558) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:52:04.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:52:04.413+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:52:04.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:52:05.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:52:05.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:52:05.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:52:05.334+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:52:05.334+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:52:05.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.978 seconds
[2023-11-14T08:52:35.614+0000] {processor.py:157} INFO - Started process (PID=2579) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:52:35.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:52:35.618+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:52:35.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:52:37.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:52:37.099+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:52:37.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:52:37.143+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:52:37.143+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:52:37.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.588 seconds
[2023-11-14T08:53:07.550+0000] {processor.py:157} INFO - Started process (PID=2600) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:53:07.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:53:07.553+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:53:07.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:53:08.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:53:08.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:53:08.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:53:08.235+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:53:08.235+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:53:08.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.719 seconds
[2023-11-14T08:53:39.153+0000] {processor.py:157} INFO - Started process (PID=2629) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:53:39.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:53:39.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:53:39.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:53:39.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:53:39.861+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:53:39.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:53:39.885+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:53:39.885+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:53:39.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.759 seconds
[2023-11-14T08:54:10.008+0000] {processor.py:157} INFO - Started process (PID=2649) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:54:10.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:54:10.010+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:54:10.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:54:10.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:54:10.765+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:54:10.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:54:10.793+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:54:10.793+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:54:10.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.813 seconds
[2023-11-14T08:54:41.123+0000] {processor.py:157} INFO - Started process (PID=2676) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:54:41.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:54:41.125+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:54:41.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:54:41.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:54:41.677+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:54:41.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:54:41.702+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:54:41.702+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:54:41.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.608 seconds
[2023-11-14T08:55:12.406+0000] {processor.py:157} INFO - Started process (PID=2696) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:55:12.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:55:12.408+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:55:12.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:55:12.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:55:12.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:55:12.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:55:12.969+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:55:12.968+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:55:12.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.589 seconds
[2023-11-14T08:55:43.331+0000] {processor.py:157} INFO - Started process (PID=2724) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:55:43.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:55:43.333+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:55:43.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:55:43.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:55:43.909+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:55:43.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:55:43.935+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:55:43.935+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:55:43.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.631 seconds
[2023-11-14T08:56:14.261+0000] {processor.py:157} INFO - Started process (PID=2745) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:56:14.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:56:14.263+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:56:14.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:56:14.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:56:14.894+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:56:14.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:56:14.926+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:56:14.926+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:56:14.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.693 seconds
[2023-11-14T08:56:45.252+0000] {processor.py:157} INFO - Started process (PID=2774) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:56:45.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:56:45.254+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:56:45.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:56:45.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:56:45.812+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:56:45.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:56:45.837+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:56:45.837+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:56:45.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.612 seconds
[2023-11-14T08:57:16.058+0000] {processor.py:157} INFO - Started process (PID=2794) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:57:16.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:57:16.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:57:16.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:57:16.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:57:16.617+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:57:16.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:57:16.643+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:57:16.642+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:57:16.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.619 seconds
[2023-11-14T08:57:47.005+0000] {processor.py:157} INFO - Started process (PID=2824) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:57:47.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:57:47.007+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:57:47.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:57:47.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:57:47.546+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:57:47.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:57:47.571+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:57:47.571+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:57:47.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.597 seconds
[2023-11-14T08:58:17.974+0000] {processor.py:157} INFO - Started process (PID=2844) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:58:17.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:58:17.977+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:58:17.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:58:18.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:58:18.521+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:58:18.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:58:18.544+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:58:18.544+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:58:18.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.605 seconds
[2023-11-14T08:58:48.885+0000] {processor.py:157} INFO - Started process (PID=2871) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:58:48.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:58:48.887+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:58:48.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:58:49.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:58:49.537+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:58:49.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:58:49.562+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:58:49.562+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:58:49.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.702 seconds
[2023-11-14T08:59:20.150+0000] {processor.py:157} INFO - Started process (PID=2892) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:59:20.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:59:20.152+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:59:20.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:59:20.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:59:20.692+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:59:20.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:59:20.724+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:59:20.723+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:59:20.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.598 seconds
[2023-11-14T08:59:51.107+0000] {processor.py:157} INFO - Started process (PID=2921) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:59:51.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T08:59:51.109+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:59:51.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:59:51.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T08:59:51.642+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:59:51.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T08:59:51.668+0000] {logging_mixin.py:151} INFO - [2023-11-14T08:59:51.667+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T08:59:51.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.587 seconds
[2023-11-14T09:00:22.075+0000] {processor.py:157} INFO - Started process (PID=2941) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:00:22.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:00:22.078+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:00:22.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:00:22.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:00:22.879+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:00:22.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:00:22.924+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:00:22.924+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:00:22.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.900 seconds
[2023-11-14T09:00:53.327+0000] {processor.py:157} INFO - Started process (PID=2961) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:00:53.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:00:53.329+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:00:53.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:00:53.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:00:53.991+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:00:53.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:00:54.016+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:00:54.016+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:00:54.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.715 seconds
[2023-11-14T09:01:24.446+0000] {processor.py:157} INFO - Started process (PID=2990) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:01:24.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:01:24.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:01:24.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:01:24.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:01:25.010+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:01:25.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:01:25.035+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:01:25.034+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:01:25.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.624 seconds
[2023-11-14T09:01:55.429+0000] {processor.py:157} INFO - Started process (PID=3010) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:01:55.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:01:55.432+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:01:55.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:01:56.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:01:56.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:01:56.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:01:56.304+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:01:56.303+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:01:56.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.907 seconds
[2023-11-14T09:02:26.677+0000] {processor.py:157} INFO - Started process (PID=3038) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:02:26.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:02:26.679+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:02:26.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:02:27.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:02:27.327+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:02:27.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:02:27.353+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:02:27.353+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:02:27.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.707 seconds
[2023-11-14T09:02:57.647+0000] {processor.py:157} INFO - Started process (PID=3058) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:02:57.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:02:57.649+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:02:57.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:02:58.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:02:58.237+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:02:58.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:02:58.261+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:02:58.260+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:02:58.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.641 seconds
[2023-11-14T09:03:28.647+0000] {processor.py:157} INFO - Started process (PID=3087) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:03:28.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:03:28.649+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:03:28.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:03:29.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:03:29.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:03:29.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:03:29.233+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:03:29.233+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:03:29.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.612 seconds
[2023-11-14T09:03:59.584+0000] {processor.py:157} INFO - Started process (PID=3108) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:03:59.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:03:59.587+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:03:59.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:04:00.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:04:00.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:04:00.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:04:00.219+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:04:00.218+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:04:00.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.662 seconds
[2023-11-14T09:04:30.561+0000] {processor.py:157} INFO - Started process (PID=3130) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:04:30.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:04:30.563+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:04:30.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:04:31.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:04:31.197+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:04:31.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:04:31.221+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:04:31.221+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:04:31.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.690 seconds
[2023-11-14T09:05:01.499+0000] {processor.py:157} INFO - Started process (PID=3158) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:05:01.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:05:01.501+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:05:01.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:05:02.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:05:02.048+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:05:02.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:05:02.074+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:05:02.073+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:05:02.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.609 seconds
[2023-11-14T09:05:32.455+0000] {processor.py:157} INFO - Started process (PID=3178) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:05:32.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:05:32.458+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:05:32.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:05:32.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:05:32.983+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:05:32.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:05:33.006+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:05:33.006+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:05:33.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.586 seconds
[2023-11-14T09:06:03.393+0000] {processor.py:157} INFO - Started process (PID=3206) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:06:03.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:06:03.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:06:03.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:06:03.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:06:03.968+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:06:03.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:06:03.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:06:03.993+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:06:04.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.626 seconds
[2023-11-14T09:06:34.869+0000] {processor.py:157} INFO - Started process (PID=3227) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:06:34.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:06:34.872+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:06:34.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:06:35.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:06:35.396+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:06:35.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:06:35.422+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:06:35.421+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:06:35.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.580 seconds
[2023-11-14T09:07:05.793+0000] {processor.py:157} INFO - Started process (PID=3257) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:07:05.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:07:05.795+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:07:05.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:07:06.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:07:06.319+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:07:06.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:07:06.343+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:07:06.343+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:07:06.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.576 seconds
[2023-11-14T09:07:36.749+0000] {processor.py:157} INFO - Started process (PID=3279) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:07:36.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:07:36.751+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:07:36.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:07:37.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:07:37.307+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:07:37.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:07:37.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:07:37.337+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:07:37.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.617 seconds
[2023-11-14T09:08:07.708+0000] {processor.py:157} INFO - Started process (PID=3308) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:08:07.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:08:07.712+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:08:07.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:08:08.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:08:08.434+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:08:08.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:08:08.497+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:08:08.495+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:08:08.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.847 seconds
[2023-11-14T09:08:39.198+0000] {processor.py:157} INFO - Started process (PID=3329) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:08:39.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:08:39.200+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:08:39.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:08:39.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:08:40.011+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:08:40.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:08:40.048+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:08:40.047+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:08:40.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.884 seconds
[2023-11-14T09:09:10.409+0000] {processor.py:157} INFO - Started process (PID=3351) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:09:10.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:09:10.411+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:09:10.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:09:11.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:09:11.317+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:09:11.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:09:11.367+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:09:11.367+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:09:11.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.037 seconds
[2023-11-14T09:09:41.689+0000] {processor.py:157} INFO - Started process (PID=3380) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:09:41.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:09:41.691+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:09:41.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:09:42.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:09:42.294+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:09:42.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:09:42.319+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:09:42.319+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:09:42.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.658 seconds
[2023-11-14T09:10:12.678+0000] {processor.py:157} INFO - Started process (PID=3401) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:10:12.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:10:12.680+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:10:12.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:10:13.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:10:13.212+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:10:13.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:10:13.235+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:10:13.235+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:10:13.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.584 seconds
[2023-11-14T09:10:43.579+0000] {processor.py:157} INFO - Started process (PID=3430) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:10:43.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:10:43.581+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:10:43.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:10:44.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:10:44.150+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:10:44.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:10:44.175+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:10:44.175+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:10:44.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.626 seconds
[2023-11-14T09:11:14.469+0000] {processor.py:157} INFO - Started process (PID=3452) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:11:14.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:11:14.479+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:11:14.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:11:15.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:11:15.149+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:11:15.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:11:15.180+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:11:15.179+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:11:15.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.745 seconds
[2023-11-14T09:11:45.372+0000] {processor.py:157} INFO - Started process (PID=3480) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:11:45.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:11:45.374+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:11:45.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:11:45.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:11:45.945+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:11:45.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:11:45.971+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:11:45.971+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:11:45.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.626 seconds
[2023-11-14T09:12:16.341+0000] {processor.py:157} INFO - Started process (PID=3501) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:12:16.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:12:16.343+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:12:16.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:12:16.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:12:16.904+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:12:16.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:12:16.928+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:12:16.927+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:12:16.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.629 seconds
[2023-11-14T09:12:47.338+0000] {processor.py:157} INFO - Started process (PID=3523) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:12:47.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:12:47.340+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:12:47.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:12:47.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:12:47.887+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:12:47.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:12:47.912+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:12:47.911+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:12:47.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.600 seconds
[2023-11-14T09:13:18.289+0000] {processor.py:157} INFO - Started process (PID=3551) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:13:18.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:13:18.291+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:13:18.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:13:18.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:13:18.829+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:13:18.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:13:18.861+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:13:18.861+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:13:18.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.598 seconds
[2023-11-14T09:13:49.248+0000] {processor.py:157} INFO - Started process (PID=3572) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:13:49.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:13:49.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:13:49.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:13:49.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:13:49.847+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:13:49.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:13:49.871+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:13:49.870+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:13:49.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.654 seconds
[2023-11-14T09:14:20.079+0000] {processor.py:157} INFO - Started process (PID=3602) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:14:20.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:14:20.086+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:14:20.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:14:20.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:14:20.684+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:14:20.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:14:20.709+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:14:20.708+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:14:20.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.664 seconds
[2023-11-14T09:14:50.877+0000] {processor.py:157} INFO - Started process (PID=3624) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:14:50.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:14:50.880+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:14:50.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:14:51.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:14:51.418+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:14:51.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:14:51.441+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:14:51.441+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:14:51.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.599 seconds
[2023-11-14T09:15:22.200+0000] {processor.py:157} INFO - Started process (PID=3652) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:15:22.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:15:22.203+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:15:22.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:15:22.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:15:22.782+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:15:22.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:15:22.805+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:15:22.805+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:15:22.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.645 seconds
[2023-11-14T09:15:52.912+0000] {processor.py:157} INFO - Started process (PID=3673) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:15:52.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:15:52.915+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:15:52.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:15:53.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:15:53.668+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:15:53.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:15:53.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:15:53.715+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:15:53.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.838 seconds
[2023-11-14T09:16:24.121+0000] {processor.py:157} INFO - Started process (PID=3702) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:16:24.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:16:24.125+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:16:24.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:16:24.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:16:24.867+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:16:24.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:16:24.892+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:16:24.891+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:16:24.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.826 seconds
[2023-11-14T09:16:55.556+0000] {processor.py:157} INFO - Started process (PID=3723) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:16:55.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:16:55.558+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:16:55.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:16:56.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:16:56.099+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:16:56.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:16:56.122+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:16:56.122+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:16:56.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.594 seconds
[2023-11-14T09:17:26.495+0000] {processor.py:157} INFO - Started process (PID=3751) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:17:26.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:17:26.498+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:17:26.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:17:27.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:17:27.093+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:17:27.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:17:27.124+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:17:27.124+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:17:27.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.656 seconds
[2023-11-14T09:17:57.503+0000] {processor.py:157} INFO - Started process (PID=3772) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:17:57.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:17:57.505+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:17:57.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:17:58.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:17:58.056+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:17:58.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:17:58.080+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:17:58.080+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:17:58.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.606 seconds
[2023-11-14T09:18:28.487+0000] {processor.py:157} INFO - Started process (PID=3793) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:18:28.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:18:28.490+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:18:28.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:18:29.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:18:29.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:18:29.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:18:29.093+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:18:29.092+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:18:29.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.632 seconds
[2023-11-14T09:18:59.533+0000] {processor.py:157} INFO - Started process (PID=3821) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:18:59.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:18:59.535+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:18:59.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:19:00.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:19:00.112+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:19:00.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:19:00.140+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:19:00.140+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:19:00.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.638 seconds
[2023-11-14T09:19:30.545+0000] {processor.py:157} INFO - Started process (PID=3843) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:19:30.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:19:30.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:19:30.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:19:31.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:19:31.403+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:19:31.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:19:31.435+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:19:31.435+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:19:31.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.926 seconds
[2023-11-14T09:20:01.794+0000] {processor.py:157} INFO - Started process (PID=3873) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:20:01.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:20:01.796+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:20:01.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:20:02.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:20:02.343+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:20:02.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:20:02.366+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:20:02.366+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:20:02.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.599 seconds
[2023-11-14T09:20:32.760+0000] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:20:32.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:20:32.763+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:20:32.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:20:33.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:20:33.307+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:20:33.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:20:33.331+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:20:33.331+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:20:33.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.604 seconds
[2023-11-14T09:21:03.713+0000] {processor.py:157} INFO - Started process (PID=3925) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:21:03.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:21:03.715+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:21:03.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:21:04.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:21:04.276+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:21:04.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:21:04.299+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:21:04.299+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:21:04.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.620 seconds
[2023-11-14T09:21:34.801+0000] {processor.py:157} INFO - Started process (PID=3946) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:21:34.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:21:34.803+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:21:34.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:21:35.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:21:35.335+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:21:35.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:21:35.358+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:21:35.358+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:21:35.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.591 seconds
[2023-11-14T09:22:05.681+0000] {processor.py:157} INFO - Started process (PID=3975) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:22:05.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:22:05.683+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:22:05.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:22:06.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:22:06.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:22:06.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:22:06.250+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:22:06.250+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:22:06.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.595 seconds
[2023-11-14T09:22:36.456+0000] {processor.py:157} INFO - Started process (PID=3995) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:22:36.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:22:36.458+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:22:36.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:22:37.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:22:37.109+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:22:37.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:22:37.149+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:22:37.149+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:22:37.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.748 seconds
[2023-11-14T09:23:07.952+0000] {processor.py:157} INFO - Started process (PID=4023) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:23:07.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:23:07.955+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:23:07.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:23:08.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:23:08.580+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:23:08.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:23:08.606+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:23:08.606+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:23:08.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.686 seconds
[2023-11-14T09:23:39.027+0000] {processor.py:157} INFO - Started process (PID=4044) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:23:39.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:23:39.030+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:23:39.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:23:40.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:23:40.438+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:23:40.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:23:40.484+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:23:40.484+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:23:40.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.501 seconds
[2023-11-14T09:24:10.919+0000] {processor.py:157} INFO - Started process (PID=4063) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:24:10.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:24:10.921+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:24:10.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:24:11.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:24:11.487+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:24:11.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:24:11.513+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:24:11.513+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:24:11.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.622 seconds
[2023-11-14T09:24:41.766+0000] {processor.py:157} INFO - Started process (PID=4092) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:24:41.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:24:41.769+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:24:41.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:24:42.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:24:42.369+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:24:42.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:24:42.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:24:42.395+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:24:42.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.658 seconds
[2023-11-14T09:25:13.446+0000] {processor.py:157} INFO - Started process (PID=4112) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:25:13.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:25:13.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:25:13.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:25:13.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:25:14.022+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:25:14.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:25:14.046+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:25:14.045+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:25:14.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.626 seconds
[2023-11-14T09:25:44.821+0000] {processor.py:157} INFO - Started process (PID=4142) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:25:44.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:25:44.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:25:44.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:25:45.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:25:45.434+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:25:45.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:25:45.459+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:25:45.459+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:25:45.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.667 seconds
[2023-11-14T09:26:15.876+0000] {processor.py:157} INFO - Started process (PID=4162) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:26:15.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:26:15.878+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:26:15.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:26:16.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:26:16.413+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:26:16.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:26:16.437+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:26:16.437+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:26:16.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.601 seconds
[2023-11-14T09:26:46.965+0000] {processor.py:157} INFO - Started process (PID=4192) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:26:46.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:26:46.968+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:26:46.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:26:48.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:26:48.189+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:26:48.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:26:48.265+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:26:48.265+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:26:48.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.351 seconds
[2023-11-14T09:27:18.720+0000] {processor.py:157} INFO - Started process (PID=4213) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:27:18.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:27:18.723+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:27:18.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:27:19.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:27:19.281+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:27:19.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:27:19.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:27:19.305+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:27:19.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.612 seconds
[2023-11-14T09:27:49.806+0000] {processor.py:157} INFO - Started process (PID=4233) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:27:49.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:27:49.809+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:27:49.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:27:50.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:27:50.393+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:27:50.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:27:50.417+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:27:50.417+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:27:50.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.639 seconds
[2023-11-14T09:28:20.811+0000] {processor.py:157} INFO - Started process (PID=4261) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:28:20.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:28:20.814+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:28:20.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:28:21.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:28:21.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:28:21.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:28:21.389+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:28:21.389+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:28:21.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.603 seconds
[2023-11-14T09:28:51.825+0000] {processor.py:157} INFO - Started process (PID=4282) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:28:51.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:28:51.827+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:28:51.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:28:52.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:28:52.381+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:28:52.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:28:52.405+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:28:52.405+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:28:52.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.607 seconds
[2023-11-14T09:29:22.978+0000] {processor.py:157} INFO - Started process (PID=4310) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:29:22.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:29:22.981+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:29:22.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:29:23.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:29:23.519+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:29:23.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:29:23.545+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:29:23.545+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:29:23.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.592 seconds
[2023-11-14T09:29:54.023+0000] {processor.py:157} INFO - Started process (PID=4331) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:29:54.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:29:54.027+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:29:54.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:29:54.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:29:54.612+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:29:54.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:29:54.637+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:29:54.636+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:29:54.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.641 seconds
[2023-11-14T09:30:25.021+0000] {processor.py:157} INFO - Started process (PID=4360) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:30:25.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:30:25.023+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:30:25.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:30:25.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:30:25.593+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:30:25.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:30:25.617+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:30:25.617+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:30:25.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.622 seconds
[2023-11-14T09:30:56.062+0000] {processor.py:157} INFO - Started process (PID=4380) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:30:56.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:30:56.064+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:30:56.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:30:56.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:30:56.717+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:30:56.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:30:56.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:30:56.744+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:30:56.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.715 seconds
[2023-11-14T09:31:27.099+0000] {processor.py:157} INFO - Started process (PID=4409) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:31:27.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:31:27.112+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:31:27.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:31:27.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:31:27.676+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:31:27.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:31:27.717+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:31:27.716+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:31:27.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.661 seconds
[2023-11-14T09:31:58.102+0000] {processor.py:157} INFO - Started process (PID=4429) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:31:58.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:31:58.104+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:31:58.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:31:58.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:31:58.644+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:31:58.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:31:58.667+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:31:58.666+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:31:58.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.591 seconds
[2023-11-14T09:32:29.064+0000] {processor.py:157} INFO - Started process (PID=4457) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:32:29.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:32:29.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:32:29.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:32:29.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:32:29.734+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:32:29.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:32:29.768+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:32:29.768+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:32:29.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.734 seconds
[2023-11-14T09:33:00.145+0000] {processor.py:157} INFO - Started process (PID=4477) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:33:00.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:33:00.148+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:33:00.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:33:00.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:33:00.694+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:33:00.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:33:00.718+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:33:00.718+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:33:00.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.600 seconds
[2023-11-14T09:33:31.127+0000] {processor.py:157} INFO - Started process (PID=4506) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:33:31.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:33:31.129+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:33:31.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:33:31.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:33:31.668+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:33:31.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:33:31.711+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:33:31.711+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:33:31.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.639 seconds
[2023-11-14T09:34:02.187+0000] {processor.py:157} INFO - Started process (PID=4526) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:34:02.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:34:02.189+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:34:02.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:34:02.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:34:02.753+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:34:02.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:34:02.779+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:34:02.779+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:34:02.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.619 seconds
[2023-11-14T09:34:33.184+0000] {processor.py:157} INFO - Started process (PID=4547) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:34:33.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:34:33.187+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:34:33.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:34:33.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:34:33.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:34:33.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:34:33.749+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:34:33.749+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:34:33.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.590 seconds
[2023-11-14T09:35:04.157+0000] {processor.py:157} INFO - Started process (PID=4576) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:35:04.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:35:04.159+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:35:04.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:35:04.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:35:04.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:35:04.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:35:04.722+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:35:04.722+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:35:04.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.590 seconds
[2023-11-14T09:35:34.846+0000] {processor.py:157} INFO - Started process (PID=4597) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:35:34.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:35:34.849+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:35:34.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:35:35.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:35:35.455+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:35:35.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:35:35.480+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:35:35.480+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:35:35.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.660 seconds
[2023-11-14T09:36:05.606+0000] {processor.py:157} INFO - Started process (PID=4625) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:36:05.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:36:05.608+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:36:05.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:36:06.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:36:06.145+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:36:06.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:36:06.169+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:36:06.169+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:36:06.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.592 seconds
[2023-11-14T09:36:36.250+0000] {processor.py:157} INFO - Started process (PID=4645) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:36:36.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:36:36.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:36:36.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:36:36.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:36:36.800+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:36:36.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:36:36.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:36:36.824+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:36:36.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.600 seconds
[2023-11-14T09:37:07.204+0000] {processor.py:157} INFO - Started process (PID=4676) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:37:07.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:37:07.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:37:07.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:37:07.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:37:07.816+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:37:07.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:37:07.839+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:37:07.839+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:37:07.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.660 seconds
[2023-11-14T09:37:38.219+0000] {processor.py:157} INFO - Started process (PID=4696) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:37:38.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:37:38.221+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:37:38.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:37:38.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:37:38.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:37:38.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:37:38.767+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:37:38.766+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:37:38.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.587 seconds
[2023-11-14T09:38:09.198+0000] {processor.py:157} INFO - Started process (PID=4725) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:38:09.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:38:09.200+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:38:09.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:38:09.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:38:09.862+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:38:09.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:38:09.886+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:38:09.886+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:38:09.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.723 seconds
[2023-11-14T09:38:40.379+0000] {processor.py:157} INFO - Started process (PID=4746) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:38:40.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:38:40.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:38:40.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:38:41.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:38:41.154+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:38:41.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:38:41.178+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:38:41.177+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:38:41.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.824 seconds
[2023-11-14T09:39:11.952+0000] {processor.py:157} INFO - Started process (PID=4774) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:39:11.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:39:11.963+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:39:11.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:39:13.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:39:13.064+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:39:13.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:39:13.093+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:39:13.093+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:39:13.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.185 seconds
[2023-11-14T09:39:43.235+0000] {processor.py:157} INFO - Started process (PID=4795) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:39:43.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:39:43.237+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:39:43.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:39:43.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:39:43.784+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:39:43.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:39:43.807+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:39:43.806+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:39:43.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.597 seconds
[2023-11-14T09:40:13.954+0000] {processor.py:157} INFO - Started process (PID=4824) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:40:13.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:40:13.956+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:40:13.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:40:14.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:40:14.631+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:40:14.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:40:14.664+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:40:14.664+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:40:14.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.736 seconds
[2023-11-14T09:40:45.626+0000] {processor.py:157} INFO - Started process (PID=4845) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:40:45.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:40:45.628+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:40:45.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:40:46.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:40:46.148+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:40:46.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:40:46.171+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:40:46.170+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:40:46.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.578 seconds
[2023-11-14T09:41:16.674+0000] {processor.py:157} INFO - Started process (PID=4870) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:41:16.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:41:16.676+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:41:16.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:41:17.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:41:17.285+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:41:17.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:41:17.308+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:41:17.308+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:41:17.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.667 seconds
[2023-11-14T09:41:47.685+0000] {processor.py:157} INFO - Started process (PID=4892) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:41:47.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:41:47.687+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:41:47.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:41:48.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:41:48.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:41:48.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:41:48.265+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:41:48.265+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:41:48.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.607 seconds
[2023-11-14T09:42:18.725+0000] {processor.py:157} INFO - Started process (PID=4912) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:42:18.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:42:18.728+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:42:18.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:42:19.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:42:19.281+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:42:19.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:42:19.310+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:42:19.310+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:42:19.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.611 seconds
[2023-11-14T09:42:49.766+0000] {processor.py:157} INFO - Started process (PID=4939) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:42:49.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:42:49.768+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:42:49.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:42:50.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:42:50.294+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:42:50.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:42:50.317+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:42:50.317+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:42:50.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.586 seconds
[2023-11-14T09:43:20.717+0000] {processor.py:157} INFO - Started process (PID=4959) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:43:20.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:43:20.720+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:43:20.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:43:21.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:43:21.244+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:43:21.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:43:21.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:43:21.268+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:43:21.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.575 seconds
[2023-11-14T09:43:51.713+0000] {processor.py:157} INFO - Started process (PID=4987) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:43:51.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:43:51.715+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:43:51.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:43:52.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:43:52.237+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:43:52.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:43:52.265+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:43:52.265+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:43:52.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.587 seconds
[2023-11-14T09:44:22.921+0000] {processor.py:157} INFO - Started process (PID=5008) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:44:22.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:44:22.923+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:44:22.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:44:23.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:44:23.452+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:44:23.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:44:23.475+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:44:23.475+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:44:23.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.587 seconds
[2023-11-14T09:44:53.899+0000] {processor.py:157} INFO - Started process (PID=5036) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:44:53.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:44:53.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:44:53.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:44:54.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:44:54.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:44:54.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:44:54.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:44:54.448+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:44:54.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.583 seconds
[2023-11-14T09:45:24.909+0000] {processor.py:157} INFO - Started process (PID=5056) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:45:24.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:45:24.911+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:45:24.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:45:25.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:45:25.473+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:45:25.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:45:25.496+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:45:25.496+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:45:25.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.624 seconds
[2023-11-14T09:45:55.895+0000] {processor.py:157} INFO - Started process (PID=5085) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:45:55.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:45:55.897+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:45:55.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:45:56.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:45:56.432+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:45:56.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:45:56.455+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:45:56.455+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:45:56.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.588 seconds
[2023-11-14T09:46:26.863+0000] {processor.py:157} INFO - Started process (PID=5105) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:46:26.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:46:26.865+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:46:26.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:46:27.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:46:27.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:46:27.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:46:27.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:46:27.460+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:46:27.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.628 seconds
[2023-11-14T09:46:57.878+0000] {processor.py:157} INFO - Started process (PID=5133) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:46:57.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:46:57.880+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:46:57.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:46:58.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:46:58.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:46:58.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:46:58.474+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:46:58.473+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:46:58.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.648 seconds
[2023-11-14T09:47:28.904+0000] {processor.py:157} INFO - Started process (PID=5153) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:47:28.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:47:28.906+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:47:28.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:47:29.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:47:29.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:47:29.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:47:29.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:47:29.460+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:47:29.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.584 seconds
[2023-11-14T09:47:59.871+0000] {processor.py:157} INFO - Started process (PID=5181) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:47:59.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:47:59.873+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:47:59.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:48:00.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:48:00.485+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:48:00.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:48:00.513+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:48:00.512+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:48:00.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.669 seconds
[2023-11-14T09:48:31.009+0000] {processor.py:157} INFO - Started process (PID=5201) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:48:31.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:48:31.011+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:48:31.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:48:31.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:48:31.545+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:48:31.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:48:31.570+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:48:31.570+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:48:31.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.588 seconds
[2023-11-14T09:49:01.939+0000] {processor.py:157} INFO - Started process (PID=5229) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:49:01.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:49:01.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:49:01.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:49:02.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:49:02.497+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:49:02.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:49:02.521+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:49:02.521+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:49:02.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.608 seconds
[2023-11-14T09:49:32.617+0000] {processor.py:157} INFO - Started process (PID=5249) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:49:32.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:49:32.619+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:49:32.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:49:33.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:49:33.151+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:49:33.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:49:33.175+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:49:33.175+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:49:33.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.599 seconds
[2023-11-14T09:50:03.614+0000] {processor.py:157} INFO - Started process (PID=5276) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:50:03.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:50:03.616+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:50:03.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:50:04.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:50:04.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:50:04.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:50:04.179+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:50:04.179+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:50:04.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.591 seconds
[2023-11-14T09:50:34.508+0000] {processor.py:157} INFO - Started process (PID=5296) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:50:34.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:50:34.512+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:50:34.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:50:35.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:50:35.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:50:35.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:50:35.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:50:35.364+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:50:35.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.889 seconds
[2023-11-14T09:51:05.807+0000] {processor.py:157} INFO - Started process (PID=5316) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:51:05.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:51:05.809+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:51:05.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:51:06.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:51:06.535+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:51:06.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:51:06.562+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:51:06.562+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:51:06.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.783 seconds
[2023-11-14T09:51:36.663+0000] {processor.py:157} INFO - Started process (PID=5343) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:51:36.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:51:36.665+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:51:36.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:51:37.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:51:37.422+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:51:37.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:51:37.463+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:51:37.462+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:51:37.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.842 seconds
[2023-11-14T09:52:07.633+0000] {processor.py:157} INFO - Started process (PID=5363) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:52:07.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:52:07.636+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:52:07.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:52:08.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:52:08.287+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:52:08.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:52:08.321+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:52:08.320+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:52:08.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.725 seconds
[2023-11-14T09:52:38.459+0000] {processor.py:157} INFO - Started process (PID=5382) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:52:38.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:52:38.462+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:52:38.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:52:39.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:52:39.205+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:52:39.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:52:39.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:52:39.240+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:52:39.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.809 seconds
[2023-11-14T09:53:09.816+0000] {processor.py:157} INFO - Started process (PID=5403) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:53:09.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:53:09.839+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:53:09.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:53:10.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:53:10.846+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:53:10.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:53:10.900+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:53:10.900+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:53:10.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.149 seconds
[2023-11-14T09:53:41.356+0000] {processor.py:157} INFO - Started process (PID=5433) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:53:41.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:53:41.359+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:53:41.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:53:42.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:53:42.174+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:53:42.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:53:42.213+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:53:42.213+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:53:42.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.895 seconds
[2023-11-14T09:54:12.643+0000] {processor.py:157} INFO - Started process (PID=5453) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:54:12.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:54:12.645+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:54:12.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:54:13.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:54:13.390+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:54:13.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:54:13.424+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:54:13.424+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:54:13.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.816 seconds
[2023-11-14T09:54:43.722+0000] {processor.py:157} INFO - Started process (PID=5473) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:54:43.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:54:43.724+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:54:43.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:54:44.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:54:44.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:54:44.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:54:44.326+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:54:44.325+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:54:44.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.633 seconds
[2023-11-14T09:55:14.607+0000] {processor.py:157} INFO - Started process (PID=5501) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:55:14.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:55:14.609+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:55:14.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:55:15.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:55:15.512+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:55:15.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:55:15.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:55:15.564+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:55:15.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.999 seconds
[2023-11-14T09:55:45.712+0000] {processor.py:157} INFO - Started process (PID=5522) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:55:45.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:55:45.715+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:55:45.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:55:46.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:55:46.195+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:55:46.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:55:46.223+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:55:46.223+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:55:46.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.539 seconds
[2023-11-14T09:56:16.574+0000] {processor.py:157} INFO - Started process (PID=5543) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:56:16.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:56:16.576+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:56:16.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:56:16.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:56:16.996+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:56:16.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:56:17.024+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:56:17.024+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:56:17.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.478 seconds
[2023-11-14T09:56:47.576+0000] {processor.py:157} INFO - Started process (PID=5571) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:56:47.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:56:47.585+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:56:47.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:56:48.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:56:48.753+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:56:48.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:56:48.802+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:56:48.802+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:56:48.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.287 seconds
[2023-11-14T09:57:18.991+0000] {processor.py:157} INFO - Started process (PID=5590) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:57:18.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:57:18.995+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:57:18.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:57:19.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:57:19.427+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:57:19.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:57:19.452+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:57:19.452+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:57:19.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.490 seconds
[2023-11-14T09:57:49.853+0000] {processor.py:157} INFO - Started process (PID=5611) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:57:49.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:57:49.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:57:49.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:57:50.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:57:50.271+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:57:50.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:57:50.296+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:57:50.296+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:57:50.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.470 seconds
[2023-11-14T09:58:20.639+0000] {processor.py:157} INFO - Started process (PID=5639) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:58:20.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:58:20.641+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:58:20.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:58:21.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:58:21.047+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:58:21.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:58:21.076+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:58:21.076+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:58:21.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.465 seconds
[2023-11-14T09:58:51.466+0000] {processor.py:157} INFO - Started process (PID=5661) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:58:51.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:58:51.468+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:58:51.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:58:51.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:58:51.917+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:58:51.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:58:51.944+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:58:51.944+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:58:51.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.505 seconds
[2023-11-14T09:59:22.278+0000] {processor.py:157} INFO - Started process (PID=5690) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:59:22.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:59:22.280+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:59:22.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:59:22.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:59:22.708+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:59:22.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:59:22.734+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:59:22.734+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:59:22.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.483 seconds
[2023-11-14T09:59:53.586+0000] {processor.py:157} INFO - Started process (PID=5711) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:59:53.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T09:59:53.588+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:59:53.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:59:53.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T09:59:54.009+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:59:54.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T09:59:54.044+0000] {logging_mixin.py:151} INFO - [2023-11-14T09:59:54.044+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T09:59:54.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.485 seconds
[2023-11-14T10:00:24.403+0000] {processor.py:157} INFO - Started process (PID=5741) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:00:24.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:00:24.405+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:00:24.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:00:24.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:00:24.819+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:00:24.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:00:24.846+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:00:24.846+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:00:24.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.470 seconds
[2023-11-14T10:00:55.172+0000] {processor.py:157} INFO - Started process (PID=5762) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:00:55.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:00:55.174+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:00:55.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:00:55.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:00:55.688+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:00:55.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:00:55.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:00:55.716+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:00:55.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.573 seconds
[2023-11-14T10:01:26.076+0000] {processor.py:157} INFO - Started process (PID=5782) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:01:26.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:01:26.078+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:01:26.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:01:26.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:01:26.605+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:01:26.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:01:26.644+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:01:26.644+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:01:26.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.603 seconds
[2023-11-14T10:01:57.028+0000] {processor.py:157} INFO - Started process (PID=5812) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:01:57.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:01:57.030+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:01:57.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:01:57.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:01:57.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:01:57.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:01:57.480+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:01:57.480+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:01:57.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.478 seconds
[2023-11-14T10:02:27.792+0000] {processor.py:157} INFO - Started process (PID=5832) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:02:27.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:02:27.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:02:27.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:02:28.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:02:28.867+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:02:28.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:02:28.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:02:28.941+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:02:28.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.202 seconds
[2023-11-14T10:02:59.365+0000] {processor.py:157} INFO - Started process (PID=5852) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:02:59.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:02:59.367+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:02:59.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:02:59.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:02:59.825+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:02:59.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:02:59.853+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:02:59.853+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:02:59.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.517 seconds
[2023-11-14T10:03:30.737+0000] {processor.py:157} INFO - Started process (PID=5882) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:03:30.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:03:30.739+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:03:30.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:03:31.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:03:31.204+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:03:31.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:03:31.230+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:03:31.230+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:03:31.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.520 seconds
[2023-11-14T10:04:01.591+0000] {processor.py:157} INFO - Started process (PID=5903) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:04:01.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:04:01.601+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:04:01.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:04:02.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:04:02.048+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:04:02.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:04:02.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:04:02.075+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:04:02.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.520 seconds
[2023-11-14T10:04:32.628+0000] {processor.py:157} INFO - Started process (PID=5931) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:04:32.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:04:32.630+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:04:32.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:04:33.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:04:33.053+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:04:33.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:04:33.081+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:04:33.081+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:04:33.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.480 seconds
[2023-11-14T10:05:03.470+0000] {processor.py:157} INFO - Started process (PID=5950) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:05:03.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:05:03.472+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:05:03.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:05:03.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:05:03.958+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:05:03.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:05:03.985+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:05:03.985+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:05:04.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T10:05:34.796+0000] {processor.py:157} INFO - Started process (PID=5978) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:05:34.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:05:34.798+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:05:34.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:05:35.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:05:35.274+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:05:35.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:05:35.299+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:05:35.299+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:05:35.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.529 seconds
[2023-11-14T10:06:05.726+0000] {processor.py:157} INFO - Started process (PID=5998) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:06:05.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:06:05.729+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:06:05.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:06:06.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:06:06.343+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:06:06.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:06:06.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:06:06.381+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:06:06.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.687 seconds
[2023-11-14T10:06:36.740+0000] {processor.py:157} INFO - Started process (PID=6018) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:06:36.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:06:36.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:06:36.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:06:37.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:06:37.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:06:37.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:06:37.284+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:06:37.283+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:06:37.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.571 seconds
[2023-11-14T10:07:07.652+0000] {processor.py:157} INFO - Started process (PID=6045) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:07:07.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:07:07.654+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:07:07.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:07:08.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:07:08.114+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:07:08.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:07:08.139+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:07:08.139+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:07:08.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.516 seconds
[2023-11-14T10:07:38.505+0000] {processor.py:157} INFO - Started process (PID=6065) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:07:38.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:07:38.507+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:07:38.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:07:38.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:07:38.949+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:07:38.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:07:38.992+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:07:38.992+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:07:39.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.516 seconds
[2023-11-14T10:08:09.556+0000] {processor.py:157} INFO - Started process (PID=6093) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:08:09.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:08:09.561+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:08:09.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:08:10.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:08:10.986+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:08:10.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:08:11.025+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:08:11.025+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:08:11.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.517 seconds
[2023-11-14T10:08:41.396+0000] {processor.py:157} INFO - Started process (PID=6114) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:08:41.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:08:41.398+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:08:41.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:08:41.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:08:41.820+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:08:41.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:08:41.846+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:08:41.846+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:08:41.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.479 seconds
[2023-11-14T10:09:12.235+0000] {processor.py:157} INFO - Started process (PID=6135) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:09:12.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:09:12.237+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:09:12.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:09:12.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:09:12.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:09:12.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:09:12.733+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:09:12.732+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:09:12.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.524 seconds
[2023-11-14T10:09:43.202+0000] {processor.py:157} INFO - Started process (PID=6166) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:09:43.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:09:43.206+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:09:43.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:09:43.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:09:43.689+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:09:43.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:09:43.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:09:43.746+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:09:43.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.577 seconds
[2023-11-14T10:10:14.158+0000] {processor.py:157} INFO - Started process (PID=6187) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:10:14.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:10:14.160+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:10:14.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:10:14.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:10:14.622+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:10:14.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:10:14.648+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:10:14.648+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:10:14.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.519 seconds
[2023-11-14T10:10:45.027+0000] {processor.py:157} INFO - Started process (PID=6217) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:10:45.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:10:45.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:10:45.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:10:45.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:10:45.447+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:10:45.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:10:45.474+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:10:45.474+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:10:45.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.474 seconds
[2023-11-14T10:11:15.845+0000] {processor.py:157} INFO - Started process (PID=6238) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:11:15.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:11:15.848+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:11:15.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:11:16.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:11:16.280+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:11:16.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:11:16.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:11:16.305+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:11:16.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.486 seconds
[2023-11-14T10:11:46.678+0000] {processor.py:157} INFO - Started process (PID=6260) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:11:46.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:11:46.680+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:11:46.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:11:47.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:11:47.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:11:47.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:11:47.265+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:11:47.265+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:11:47.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.615 seconds
[2023-11-14T10:12:17.640+0000] {processor.py:157} INFO - Started process (PID=6289) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:12:17.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:12:17.642+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:12:17.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:12:18.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:12:18.149+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:12:18.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:12:18.179+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:12:18.179+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:12:18.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.572 seconds
[2023-11-14T10:12:48.545+0000] {processor.py:157} INFO - Started process (PID=6310) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:12:48.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:12:48.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:12:48.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:12:48.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:12:48.968+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:12:48.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:12:48.995+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:12:48.995+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:12:49.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.488 seconds
[2023-11-14T10:13:19.380+0000] {processor.py:157} INFO - Started process (PID=6340) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:13:19.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:13:19.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:13:19.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:13:19.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:13:19.909+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:13:19.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:13:19.939+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:13:19.939+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:13:19.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.589 seconds
[2023-11-14T10:13:50.709+0000] {processor.py:157} INFO - Started process (PID=6361) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:13:50.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:13:50.712+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:13:50.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:13:51.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:13:51.232+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:13:51.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:13:51.264+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:13:51.264+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:13:51.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.590 seconds
[2023-11-14T10:14:21.655+0000] {processor.py:157} INFO - Started process (PID=6390) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:14:21.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:14:21.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:14:21.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:14:22.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:14:22.084+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:14:22.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:14:22.114+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:14:22.114+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:14:22.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.491 seconds
[2023-11-14T10:14:52.444+0000] {processor.py:157} INFO - Started process (PID=6411) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:14:52.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:14:52.447+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:14:52.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:14:53.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:14:53.208+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:14:53.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:14:53.244+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:14:53.243+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:14:53.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.836 seconds
[2023-11-14T10:15:23.647+0000] {processor.py:157} INFO - Started process (PID=6431) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:15:23.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:15:23.649+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:15:23.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:15:24.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:15:24.061+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:15:24.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:15:24.088+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:15:24.087+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:15:24.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.466 seconds
[2023-11-14T10:15:54.420+0000] {processor.py:157} INFO - Started process (PID=6460) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:15:54.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:15:54.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:15:54.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:15:54.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:15:54.886+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:15:54.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:15:54.920+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:15:54.919+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:15:54.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.542 seconds
[2023-11-14T10:16:25.277+0000] {processor.py:157} INFO - Started process (PID=6481) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:16:25.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:16:25.279+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:16:25.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:16:25.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:16:25.690+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:16:25.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:16:25.715+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:16:25.715+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:16:25.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.465 seconds
[2023-11-14T10:16:56.142+0000] {processor.py:157} INFO - Started process (PID=6511) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:16:56.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:16:56.144+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:16:56.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:16:56.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:16:56.677+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:16:56.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:16:56.707+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:16:56.707+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:16:56.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.595 seconds
[2023-11-14T10:17:27.052+0000] {processor.py:157} INFO - Started process (PID=6531) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:17:27.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:17:27.055+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:17:27.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:17:27.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:17:27.585+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:17:27.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:17:27.611+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:17:27.611+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:17:27.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.589 seconds
[2023-11-14T10:17:57.952+0000] {processor.py:157} INFO - Started process (PID=6559) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:17:57.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:17:57.954+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:17:57.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:17:58.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:17:58.433+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:17:58.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:17:58.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:17:58.460+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:17:58.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.534 seconds
[2023-11-14T10:18:28.848+0000] {processor.py:157} INFO - Started process (PID=6581) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:18:28.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:18:28.850+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:18:28.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:18:29.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:18:29.414+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:18:29.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:18:29.443+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:18:29.443+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:18:29.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.620 seconds
[2023-11-14T10:18:59.721+0000] {processor.py:157} INFO - Started process (PID=6602) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:18:59.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:18:59.723+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:18:59.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:19:00.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:19:00.179+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:19:00.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:19:00.204+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:19:00.204+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:19:00.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.509 seconds
[2023-11-14T10:19:30.343+0000] {processor.py:157} INFO - Started process (PID=6632) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:19:30.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:19:30.345+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:19:30.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:19:30.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:19:30.792+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:19:30.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:19:30.821+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:19:30.821+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:19:30.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.507 seconds
[2023-11-14T10:20:01.214+0000] {processor.py:157} INFO - Started process (PID=6652) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:20:01.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:20:01.216+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:20:01.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:20:01.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:20:01.697+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:20:01.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:20:01.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:20:01.726+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:20:01.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.546 seconds
[2023-11-14T10:20:32.070+0000] {processor.py:157} INFO - Started process (PID=6681) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:20:32.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:20:32.072+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:20:32.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:20:32.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:20:32.495+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:20:32.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:20:32.521+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:20:32.521+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:20:32.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.486 seconds
[2023-11-14T10:21:03.447+0000] {processor.py:157} INFO - Started process (PID=6700) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:21:03.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:21:03.449+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:21:03.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:21:03.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:21:03.925+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:21:03.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:21:03.951+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:21:03.951+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:21:03.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.533 seconds
[2023-11-14T10:21:34.348+0000] {processor.py:157} INFO - Started process (PID=6721) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:21:34.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:21:34.351+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:21:34.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:21:34.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:21:34.823+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:21:34.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:21:34.857+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:21:34.856+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:21:34.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.548 seconds
[2023-11-14T10:22:05.269+0000] {processor.py:157} INFO - Started process (PID=6749) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:22:05.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:22:05.271+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:22:05.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:22:05.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:22:05.689+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:22:05.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:22:05.714+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:22:05.714+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:22:05.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.482 seconds
[2023-11-14T10:22:36.099+0000] {processor.py:157} INFO - Started process (PID=6769) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:22:36.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:22:36.101+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:22:36.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:22:36.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:22:36.518+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:22:36.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:22:36.552+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:22:36.552+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:22:36.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.482 seconds
[2023-11-14T10:23:06.987+0000] {processor.py:157} INFO - Started process (PID=6798) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:23:06.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:23:06.989+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:23:06.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:23:07.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:23:07.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:23:07.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:23:07.491+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:23:07.490+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:23:07.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.532 seconds
[2023-11-14T10:23:37.925+0000] {processor.py:157} INFO - Started process (PID=6819) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:23:37.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:23:37.927+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:23:37.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:23:38.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:23:38.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:23:38.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:23:38.364+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:23:38.364+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:23:38.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.473 seconds
[2023-11-14T10:24:08.744+0000] {processor.py:157} INFO - Started process (PID=6848) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:24:08.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:24:08.746+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:24:08.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:24:09.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:24:09.157+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:24:09.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:24:09.182+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:24:09.182+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:24:09.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.466 seconds
[2023-11-14T10:24:39.724+0000] {processor.py:157} INFO - Started process (PID=6868) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:24:39.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:24:39.729+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:24:39.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:24:40.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:24:40.270+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:24:40.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:24:40.302+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:24:40.302+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:24:40.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.613 seconds
[2023-11-14T10:25:10.678+0000] {processor.py:157} INFO - Started process (PID=6896) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:25:10.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:25:10.681+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:25:10.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:25:11.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:25:11.271+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:25:11.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:25:11.322+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:25:11.321+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:25:11.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.674 seconds
[2023-11-14T10:25:41.582+0000] {processor.py:157} INFO - Started process (PID=6917) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:25:41.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:25:41.584+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:25:41.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:25:41.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:25:42.020+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:25:42.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:25:42.049+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:25:42.049+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:25:42.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.497 seconds
[2023-11-14T10:26:12.384+0000] {processor.py:157} INFO - Started process (PID=6937) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:26:12.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:26:12.387+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:26:12.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:26:12.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:26:12.794+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:26:12.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:26:12.820+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:26:12.820+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:26:12.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.463 seconds
[2023-11-14T10:26:43.199+0000] {processor.py:157} INFO - Started process (PID=6967) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:26:43.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:26:43.200+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:26:43.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:26:43.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:26:43.603+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:26:43.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:26:43.629+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:26:43.629+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:26:43.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.474 seconds
[2023-11-14T10:27:14.068+0000] {processor.py:157} INFO - Started process (PID=6988) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:27:14.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:27:14.070+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:27:14.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:27:14.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:27:14.490+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:27:14.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:27:14.516+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:27:14.516+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:27:14.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.491 seconds
[2023-11-14T10:27:44.948+0000] {processor.py:157} INFO - Started process (PID=7017) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:27:44.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:27:44.950+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:27:44.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:27:45.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:27:45.357+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:27:45.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:27:45.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:27:45.395+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:27:45.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.473 seconds
[2023-11-14T10:28:15.795+0000] {processor.py:157} INFO - Started process (PID=7037) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:28:15.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:28:15.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:28:15.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:28:16.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:28:16.218+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:28:16.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:28:16.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:28:16.251+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:28:16.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.484 seconds
[2023-11-14T10:28:46.655+0000] {processor.py:157} INFO - Started process (PID=7065) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:28:46.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:28:46.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:28:46.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:28:47.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:28:47.153+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:28:47.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:28:47.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:28:47.186+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:28:47.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.559 seconds
[2023-11-14T10:29:18.031+0000] {processor.py:157} INFO - Started process (PID=7086) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:29:18.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:29:18.033+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:29:18.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:29:18.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:29:18.441+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:29:18.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:29:18.468+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:29:18.467+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:29:18.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.472 seconds
[2023-11-14T10:29:48.964+0000] {processor.py:157} INFO - Started process (PID=7115) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:29:48.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:29:48.967+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:29:48.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:29:49.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:29:49.498+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:29:49.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:29:49.527+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:29:49.527+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:29:49.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.599 seconds
[2023-11-14T10:30:19.923+0000] {processor.py:157} INFO - Started process (PID=7136) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:30:19.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:30:19.926+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:30:19.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:30:20.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:30:20.601+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:30:20.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:30:20.642+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:30:20.642+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:30:20.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.759 seconds
[2023-11-14T10:30:51.041+0000] {processor.py:157} INFO - Started process (PID=7165) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:30:51.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:30:51.043+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:30:51.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:30:51.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:30:51.498+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:30:51.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:30:51.538+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:30:51.538+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:30:51.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.531 seconds
[2023-11-14T10:31:21.928+0000] {processor.py:157} INFO - Started process (PID=7186) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:31:21.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:31:21.931+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:31:21.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:31:22.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:31:22.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:31:22.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:31:22.450+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:31:22.450+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:31:22.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.550 seconds
[2023-11-14T10:31:52.802+0000] {processor.py:157} INFO - Started process (PID=7207) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:31:52.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:31:52.804+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:31:52.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:31:53.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:31:53.213+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:31:53.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:31:53.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:31:53.240+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:31:53.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.466 seconds
[2023-11-14T10:32:23.594+0000] {processor.py:157} INFO - Started process (PID=7237) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:32:23.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:32:23.596+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:32:23.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:32:24.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:32:24.094+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:32:24.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:32:24.123+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:32:24.123+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:32:24.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.562 seconds
[2023-11-14T10:32:54.478+0000] {processor.py:157} INFO - Started process (PID=7257) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:32:54.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:32:54.480+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:32:54.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:32:54.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:32:54.915+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:32:54.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:32:54.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:32:54.941+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:32:54.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.489 seconds
[2023-11-14T10:33:25.362+0000] {processor.py:157} INFO - Started process (PID=7285) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:33:25.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:33:25.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:33:25.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:33:25.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:33:26.014+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:33:26.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:33:26.049+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:33:26.048+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:33:26.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.728 seconds
[2023-11-14T10:33:56.386+0000] {processor.py:157} INFO - Started process (PID=7305) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:33:56.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:33:56.388+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:33:56.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:33:56.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:33:56.821+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:33:56.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:33:56.848+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:33:56.848+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:33:56.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.497 seconds
[2023-11-14T10:34:27.188+0000] {processor.py:157} INFO - Started process (PID=7333) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:34:27.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:34:27.190+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:34:27.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:34:27.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:34:27.610+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:34:27.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:34:27.638+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:34:27.637+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:34:27.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.476 seconds
[2023-11-14T10:34:58.517+0000] {processor.py:157} INFO - Started process (PID=7353) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:34:58.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:34:58.519+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:34:58.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:34:58.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:34:59.025+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:34:59.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:34:59.073+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:34:59.073+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:34:59.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.588 seconds
[2023-11-14T10:35:29.470+0000] {processor.py:157} INFO - Started process (PID=7373) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:35:29.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:35:29.473+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:35:29.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:35:29.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:35:29.946+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:35:29.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:35:29.974+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:35:29.974+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:35:30.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.534 seconds
[2023-11-14T10:36:00.333+0000] {processor.py:157} INFO - Started process (PID=7403) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:36:00.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:36:00.335+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:36:00.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:36:00.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:36:00.800+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:36:00.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:36:00.847+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:36:00.847+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:36:00.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T10:36:31.229+0000] {processor.py:157} INFO - Started process (PID=7424) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:36:31.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:36:31.232+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:36:31.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:36:31.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:36:31.706+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:36:31.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:36:31.751+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:36:31.751+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:36:31.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.568 seconds
[2023-11-14T10:37:02.164+0000] {processor.py:157} INFO - Started process (PID=7452) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:37:02.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:37:02.166+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:37:02.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:37:02.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:37:02.591+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:37:02.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:37:02.617+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:37:02.617+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:37:02.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.489 seconds
[2023-11-14T10:37:32.994+0000] {processor.py:157} INFO - Started process (PID=7472) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:37:32.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:37:32.996+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:37:32.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:37:33.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:37:33.413+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:37:33.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:37:33.438+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:37:33.438+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:37:33.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.471 seconds
[2023-11-14T10:38:03.829+0000] {processor.py:157} INFO - Started process (PID=7501) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:38:03.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:38:03.831+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:38:03.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:38:04.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:38:04.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:38:04.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:38:04.281+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:38:04.281+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:38:04.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.479 seconds
[2023-11-14T10:38:34.609+0000] {processor.py:157} INFO - Started process (PID=7521) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:38:34.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:38:34.611+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:38:34.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:38:35.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:38:35.040+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:38:35.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:38:35.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:38:35.066+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:38:35.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.483 seconds
[2023-11-14T10:39:05.471+0000] {processor.py:157} INFO - Started process (PID=7542) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:39:05.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:39:05.474+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:39:05.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:39:05.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:39:05.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:39:05.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:39:05.916+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:39:05.916+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:39:05.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.470 seconds
[2023-11-14T10:39:36.363+0000] {processor.py:157} INFO - Started process (PID=7573) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:39:36.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:39:36.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:39:36.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:39:36.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:39:36.806+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:39:36.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:39:36.833+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:39:36.833+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:39:36.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.510 seconds
[2023-11-14T10:40:07.209+0000] {processor.py:157} INFO - Started process (PID=7595) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:40:07.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:40:07.211+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:40:07.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:40:07.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:40:07.680+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:40:07.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:40:07.707+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:40:07.707+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:40:07.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.533 seconds
[2023-11-14T10:40:38.533+0000] {processor.py:157} INFO - Started process (PID=7624) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:40:38.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:40:38.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:40:38.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:40:39.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:40:39.034+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:40:39.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:40:39.059+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:40:39.059+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:40:39.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.563 seconds
[2023-11-14T10:41:09.421+0000] {processor.py:157} INFO - Started process (PID=7645) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:41:09.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:41:09.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:41:09.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:41:09.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:41:09.953+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:41:09.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:41:09.983+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:41:09.983+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:41:10.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.603 seconds
[2023-11-14T10:41:40.335+0000] {processor.py:157} INFO - Started process (PID=7674) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:41:40.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:41:40.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:41:40.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:41:40.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:41:40.776+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:41:40.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:41:40.803+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:41:40.803+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:41:40.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.504 seconds
[2023-11-14T10:42:11.186+0000] {processor.py:157} INFO - Started process (PID=7695) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:42:11.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:42:11.190+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:42:11.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:42:11.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:42:11.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:42:11.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:42:11.742+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:42:11.741+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:42:11.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.590 seconds
[2023-11-14T10:42:42.182+0000] {processor.py:157} INFO - Started process (PID=7715) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:42:42.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:42:42.185+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:42:42.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:42:42.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:42:42.611+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:42:42.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:42:42.638+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:42:42.638+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:42:42.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.488 seconds
[2023-11-14T10:43:13.045+0000] {processor.py:157} INFO - Started process (PID=7745) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:43:13.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:43:13.047+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:43:13.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:43:13.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:43:13.459+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:43:13.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:43:13.485+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:43:13.485+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:43:13.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.476 seconds
[2023-11-14T10:43:43.912+0000] {processor.py:157} INFO - Started process (PID=7765) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:43:43.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:43:43.914+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:43:43.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:43:44.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:43:44.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:43:44.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:43:44.438+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:43:44.438+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:43:44.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.577 seconds
[2023-11-14T10:44:14.815+0000] {processor.py:157} INFO - Started process (PID=7794) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:44:14.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:44:14.817+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:44:14.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:44:15.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:44:15.279+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:44:15.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:44:15.311+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:44:15.310+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:44:15.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.526 seconds
[2023-11-14T10:44:45.645+0000] {processor.py:157} INFO - Started process (PID=7814) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:44:45.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:44:45.648+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:44:45.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:44:46.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:44:46.074+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:44:46.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:44:46.100+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:44:46.100+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:44:46.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.481 seconds
[2023-11-14T10:45:16.928+0000] {processor.py:157} INFO - Started process (PID=7842) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:45:16.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:45:16.931+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:45:16.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:45:17.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:45:17.392+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:45:17.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:45:17.419+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:45:17.418+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:45:17.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.520 seconds
[2023-11-14T10:45:47.787+0000] {processor.py:157} INFO - Started process (PID=7862) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:45:47.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:45:47.789+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:45:47.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:45:48.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:45:48.218+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:45:48.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:45:48.244+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:45:48.243+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:45:48.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.485 seconds
[2023-11-14T10:46:18.622+0000] {processor.py:157} INFO - Started process (PID=7892) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:46:18.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:46:18.624+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:46:18.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:46:19.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:46:19.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:46:19.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:46:19.113+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:46:19.112+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:46:19.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.526 seconds
[2023-11-14T10:46:49.453+0000] {processor.py:157} INFO - Started process (PID=7913) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:46:49.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:46:49.455+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:46:49.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:46:49.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:46:49.926+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:46:49.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:46:49.962+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:46:49.962+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:46:50.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.550 seconds
[2023-11-14T10:47:20.354+0000] {processor.py:157} INFO - Started process (PID=7934) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:47:20.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:47:20.356+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:47:20.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:47:20.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:47:20.856+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:47:20.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:47:20.885+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:47:20.884+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:47:20.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.560 seconds
[2023-11-14T10:47:51.184+0000] {processor.py:157} INFO - Started process (PID=7962) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:47:51.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:47:51.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:47:51.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:47:51.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:47:51.670+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:47:51.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:47:51.696+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:47:51.696+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:47:51.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.539 seconds
[2023-11-14T10:48:22.070+0000] {processor.py:157} INFO - Started process (PID=7982) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:48:22.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:48:22.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:48:22.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:48:22.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:48:22.557+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:48:22.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:48:22.596+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:48:22.596+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:48:22.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.566 seconds
[2023-11-14T10:48:52.957+0000] {processor.py:157} INFO - Started process (PID=8013) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:48:52.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:48:52.959+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:48:52.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:48:53.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:48:53.603+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:48:53.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:48:53.636+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:48:53.636+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:48:53.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.712 seconds
[2023-11-14T10:49:24.047+0000] {processor.py:157} INFO - Started process (PID=8034) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:49:24.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:49:24.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:49:24.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:49:24.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:49:24.709+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:49:24.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:49:24.756+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:49:24.755+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:49:24.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.759 seconds
[2023-11-14T10:49:54.911+0000] {processor.py:157} INFO - Started process (PID=8054) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:49:54.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:49:54.917+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:49:54.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:49:55.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:49:55.442+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:49:55.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:49:55.468+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:49:55.468+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:49:55.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.593 seconds
[2023-11-14T10:50:25.820+0000] {processor.py:157} INFO - Started process (PID=8084) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:50:25.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:50:25.823+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:50:25.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:50:26.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:50:26.464+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:50:26.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:50:26.505+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:50:26.504+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:50:26.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.743 seconds
[2023-11-14T10:50:56.983+0000] {processor.py:157} INFO - Started process (PID=8104) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:50:56.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:50:56.985+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:50:56.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:50:57.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:50:57.484+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:50:57.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:50:57.517+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:50:57.516+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:50:57.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.573 seconds
[2023-11-14T10:51:27.845+0000] {processor.py:157} INFO - Started process (PID=8131) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:51:27.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:51:27.847+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:51:27.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:51:28.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:51:28.312+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:51:28.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:51:28.338+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:51:28.338+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:51:28.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.521 seconds
[2023-11-14T10:51:58.697+0000] {processor.py:157} INFO - Started process (PID=8152) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:51:58.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:51:58.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:51:58.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:51:59.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:51:59.180+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:51:59.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:51:59.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:51:59.207+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:51:59.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.538 seconds
[2023-11-14T10:52:29.599+0000] {processor.py:157} INFO - Started process (PID=8182) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:52:29.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:52:29.601+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:52:29.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:52:30.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:52:30.048+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:52:30.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:52:30.079+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:52:30.079+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:52:30.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.511 seconds
[2023-11-14T10:53:00.484+0000] {processor.py:157} INFO - Started process (PID=8202) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:53:00.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:53:00.486+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:53:00.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:53:00.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:53:00.973+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:53:00.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:53:01.003+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:53:01.003+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:53:01.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.559 seconds
[2023-11-14T10:53:31.110+0000] {processor.py:157} INFO - Started process (PID=8223) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:53:31.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T10:53:31.113+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:53:31.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:53:31.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T10:53:31.569+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:53:31.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T10:53:31.598+0000] {logging_mixin.py:151} INFO - [2023-11-14T10:53:31.598+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T10:53:31.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.517 seconds
[2023-11-14T11:44:21.450+0000] {processor.py:157} INFO - Started process (PID=8233) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:44:21.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:44:21.482+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:44:21.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:44:23.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:44:24.087+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:44:24.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:44:24.243+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:44:24.243+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:44:24.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.234 seconds
[2023-11-14T11:44:54.469+0000] {processor.py:157} INFO - Started process (PID=8253) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:44:54.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:44:54.472+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:44:54.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:44:54.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:44:54.961+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:44:54.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:44:54.988+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:44:54.988+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:44:55.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.548 seconds
[2023-11-14T11:45:25.584+0000] {processor.py:157} INFO - Started process (PID=8282) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:45:25.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:45:25.586+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:45:25.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:45:26.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:45:26.049+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:45:26.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:45:26.084+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:45:26.084+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:45:26.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T11:45:56.687+0000] {processor.py:157} INFO - Started process (PID=8302) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:45:56.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:45:56.696+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:45:56.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:45:57.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:45:57.492+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:45:57.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:45:57.530+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:45:57.529+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:45:57.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.906 seconds
[2023-11-14T11:46:28.267+0000] {processor.py:157} INFO - Started process (PID=8323) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:46:28.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:46:28.274+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:46:28.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:46:28.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:46:29.044+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:46:29.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:46:29.128+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:46:29.128+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:46:29.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.947 seconds
[2023-11-14T11:46:59.589+0000] {processor.py:157} INFO - Started process (PID=8350) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:46:59.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:46:59.592+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:46:59.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:47:00.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:47:00.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:47:00.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:47:00.457+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:47:00.457+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:47:00.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.949 seconds
[2023-11-14T11:47:30.967+0000] {processor.py:157} INFO - Started process (PID=8371) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:47:30.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:47:30.971+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:47:30.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:47:31.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:47:31.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:47:31.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:47:31.781+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:47:31.781+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:47:31.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.856 seconds
[2023-11-14T11:48:02.283+0000] {processor.py:157} INFO - Started process (PID=8393) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:48:02.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:48:02.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:48:02.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:48:03.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:48:03.229+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:48:03.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:48:03.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:48:03.268+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:48:03.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.036 seconds
[2023-11-14T11:48:33.966+0000] {processor.py:157} INFO - Started process (PID=8413) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:48:33.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:48:33.976+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:48:33.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:48:34.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:48:34.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:48:34.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:48:34.865+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:48:34.864+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:48:34.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.995 seconds
[2023-11-14T11:49:05.583+0000] {processor.py:157} INFO - Started process (PID=8433) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:49:05.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:49:05.591+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:49:05.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:49:06.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:49:06.437+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:49:06.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:49:06.530+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:49:06.529+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:49:06.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.019 seconds
[2023-11-14T11:49:36.668+0000] {processor.py:157} INFO - Started process (PID=8461) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:49:36.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:49:36.671+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:49:36.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:49:37.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:49:37.487+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:49:37.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:49:37.532+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:49:37.532+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:49:37.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.910 seconds
[2023-11-14T11:50:08.032+0000] {processor.py:157} INFO - Started process (PID=8481) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:50:08.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:50:08.035+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:50:08.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:50:08.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:50:08.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:50:08.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:50:08.769+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:50:08.769+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:50:10.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.234 seconds
[2023-11-14T11:50:40.604+0000] {processor.py:157} INFO - Started process (PID=8501) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:50:40.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:50:40.607+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:50:40.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:50:41.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:50:41.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:50:41.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:50:41.289+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:50:41.288+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:50:41.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.835 seconds
[2023-11-14T11:51:12.166+0000] {processor.py:157} INFO - Started process (PID=8521) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:51:12.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:51:12.185+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:51:12.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:51:12.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:51:12.973+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:51:12.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:51:13.010+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:51:13.010+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:51:13.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.954 seconds
[2023-11-14T11:51:43.699+0000] {processor.py:157} INFO - Started process (PID=8550) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:51:43.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:51:43.715+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:51:43.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:51:44.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:51:44.629+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:51:44.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:51:44.677+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:51:44.677+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:51:44.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.044 seconds
[2023-11-14T11:52:15.351+0000] {processor.py:157} INFO - Started process (PID=8571) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:52:15.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:52:15.359+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:52:15.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:52:16.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:52:16.074+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:52:16.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:52:16.151+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:52:16.150+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:52:16.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.852 seconds
[2023-11-14T11:52:47.082+0000] {processor.py:157} INFO - Started process (PID=8590) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:52:47.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:52:47.089+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:52:47.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:52:48.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:52:48.199+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:52:48.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:52:48.670+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:52:48.669+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:52:48.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.646 seconds
[2023-11-14T11:53:19.576+0000] {processor.py:157} INFO - Started process (PID=8609) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:53:19.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:53:19.581+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:53:19.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:53:20.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:53:20.870+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:53:20.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:53:21.160+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:53:21.159+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:53:21.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.107 seconds
[2023-11-14T11:53:52.476+0000] {processor.py:157} INFO - Started process (PID=8636) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:53:52.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:53:52.482+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:53:52.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:53:53.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:53:53.900+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:53:53.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:53:53.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:53:53.943+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:53:54.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.619 seconds
[2023-11-14T11:54:24.441+0000] {processor.py:157} INFO - Started process (PID=8658) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:54:24.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:54:24.458+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:54:24.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:54:25.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:54:25.366+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:54:25.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:54:25.404+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:54:25.404+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:54:25.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.040 seconds
[2023-11-14T11:54:56.038+0000] {processor.py:157} INFO - Started process (PID=8679) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:54:56.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:54:56.041+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:54:56.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:54:56.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:54:56.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:54:56.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:54:56.759+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:54:56.759+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:54:56.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.775 seconds
[2023-11-14T11:55:27.465+0000] {processor.py:157} INFO - Started process (PID=8700) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:55:27.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:55:27.469+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:55:27.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:55:28.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:55:28.101+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:55:28.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:55:28.322+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:55:28.322+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:55:28.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.949 seconds
[2023-11-14T11:55:58.974+0000] {processor.py:157} INFO - Started process (PID=8722) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:55:58.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:55:58.977+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:55:58.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:55:59.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:55:59.638+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:55:59.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:55:59.693+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:55:59.692+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:55:59.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.767 seconds
[2023-11-14T11:56:30.283+0000] {processor.py:157} INFO - Started process (PID=8750) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:56:30.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:56:30.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:56:30.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:56:30.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:56:31.005+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:56:31.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:56:31.224+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:56:31.224+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:56:31.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.988 seconds
[2023-11-14T11:57:01.831+0000] {processor.py:157} INFO - Started process (PID=8770) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:57:01.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:57:01.837+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:57:01.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:57:02.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:57:02.542+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:57:02.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:57:02.583+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:57:02.583+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:57:02.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.856 seconds
[2023-11-14T11:57:33.809+0000] {processor.py:157} INFO - Started process (PID=8790) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:57:33.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:57:33.829+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:57:33.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:57:52.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:57:52.652+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:57:52.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:57:52.801+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:57:52.796+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:57:53.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 19.634 seconds
[2023-11-14T11:58:24.872+0000] {processor.py:157} INFO - Started process (PID=8810) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:58:24.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:58:24.879+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:58:24.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:58:46.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:58:46.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:58:46.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T11:58:51.470+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:58:51.464+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T11:58:54.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 29.551 seconds
[2023-11-14T11:59:26.263+0000] {processor.py:157} INFO - Started process (PID=8836) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:59:26.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T11:59:26.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:59:26.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:59:56.549+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:59:56.424+0000] {timeout.py:68} ERROR - Process timed out, PID: 8836
[2023-11-14T11:59:56.910+0000] {logging_mixin.py:151} INFO - [2023-11-14T11:59:56.566+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 364, in <module>
    wrangle_population_data_task = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 835, in __init__
    self.start_date = timezone.convert_to_utc(start_date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 101, in convert_to_utc
    return pendulum.instance(value.astimezone(utc))
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/datetime.py", line 1466, in astimezone
    def astimezone(self, tz=None):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 8836
[2023-11-14T11:59:56.928+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T11:59:57.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 31.094 seconds
[2023-11-14T12:00:31.241+0000] {processor.py:157} INFO - Started process (PID=8864) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:00:31.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:00:31.370+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:00:31.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:00:52.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:01:49.514+0000] {processor.py:157} INFO - Started process (PID=8893) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:01:49.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:01:49.519+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:01:49.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:01:52.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:01:53.702+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:01:53.692+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T12:01:53.708+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:01:53.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:01:55.849+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:01:55.832+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:01:58.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 8.873 seconds
[2023-11-14T12:02:30.645+0000] {processor.py:157} INFO - Started process (PID=8911) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:02:30.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:02:30.650+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:02:30.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:03:01.143+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:03:01.009+0000] {timeout.py:68} ERROR - Process timed out, PID: 8911
[2023-11-14T12:03:02.381+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:03:01.207+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 971, in get_code
  File "<frozen importlib._bootstrap_external>", line 640, in _compile_bytecode
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 8911
[2023-11-14T12:03:02.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:03:03.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 32.849 seconds
[2023-11-14T12:03:41.287+0000] {processor.py:157} INFO - Started process (PID=8937) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:03:41.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:03:42.972+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:03:42.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:04:07.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:04:11.007+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:04:11.006+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T12:04:11.034+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:04:11.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:04:11.296+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:04:11.296+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:04:11.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 32.872 seconds
[2023-11-14T12:04:42.105+0000] {processor.py:157} INFO - Started process (PID=8969) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:04:42.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:04:42.108+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:04:42.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:04:42.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:04:42.996+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:04:42.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:04:43.250+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:04:43.249+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:04:43.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.185 seconds
[2023-11-14T12:05:13.770+0000] {processor.py:157} INFO - Started process (PID=8989) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:05:13.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:05:13.773+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:05:13.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:05:15.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:05:15.356+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:05:15.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:05:15.411+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:05:15.410+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:05:15.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.814 seconds
[2023-11-14T12:05:46.314+0000] {processor.py:157} INFO - Started process (PID=9009) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:05:46.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:05:46.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:05:46.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:05:47.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:05:47.990+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:05:47.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:05:48.676+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:05:48.675+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:05:48.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.445 seconds
[2023-11-14T12:06:19.233+0000] {processor.py:157} INFO - Started process (PID=9029) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:06:19.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:06:19.236+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:06:19.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:06:19.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:06:20.215+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:06:20.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:06:20.299+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:06:20.299+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:06:20.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.158 seconds
[2023-11-14T12:06:51.123+0000] {processor.py:157} INFO - Started process (PID=9050) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:06:51.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:06:51.127+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:06:51.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:06:52.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:06:52.243+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:06:52.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:06:52.375+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:06:52.373+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:06:52.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.440 seconds
[2023-11-14T12:07:23.908+0000] {processor.py:157} INFO - Started process (PID=9071) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:07:23.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:07:24.078+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:07:24.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:07:46.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:07:48.183+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:07:48.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:07:53.441+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:07:53.421+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:07:54.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 30.513 seconds
[2023-11-14T12:08:25.655+0000] {processor.py:157} INFO - Started process (PID=9099) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:08:25.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:08:25.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:08:25.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:08:56.442+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:08:56.108+0000] {timeout.py:68} ERROR - Process timed out, PID: 9099
[2023-11-14T12:08:56.761+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:08:56.495+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 27, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/array.py", line 77, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 324, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 321, in _make_global_functions
    g[cpp_name] = g[name] = _wrap_function(name, func)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 296, in _wrap_function
    return _decorate_compute_function(wrapper, name, func, options_class)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 145, in _decorate_compute_function
    doc_pieces.append(dedent("""\
  File "/usr/local/lib/python3.8/textwrap.py", line 461, in dedent
    text = re.sub(r'(?m)^' + margin, '', text)
  File "/usr/local/lib/python3.8/re.py", line 210, in sub
    return _compile(pattern, flags).sub(repl, string, count)
  File "/usr/local/lib/python3.8/re.py", line 291, in _compile
    if isinstance(flags, RegexFlag):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9099
[2023-11-14T12:08:56.940+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:08:58.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 32.818 seconds
[2023-11-14T12:09:34.867+0000] {processor.py:157} INFO - Started process (PID=9123) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:09:34.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:09:35.085+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:09:35.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:10:06.178+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:10:05.843+0000] {timeout.py:68} ERROR - Process timed out, PID: 9123
[2023-11-14T12:10:06.726+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:10:06.193+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 27, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/array.py", line 77, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 324, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 315, in _make_global_functions
    func = reg.get_function(cpp_name)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9123
[2023-11-14T12:10:06.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:10:10.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 36.255 seconds
[2023-11-14T12:10:43.148+0000] {processor.py:157} INFO - Started process (PID=9151) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:10:43.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:10:43.959+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:10:43.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:11:16.184+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:11:15.350+0000] {timeout.py:68} ERROR - Process timed out, PID: 9151
[2023-11-14T12:11:17.769+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:11:16.553+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 27, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/array.py", line 77, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 96, in <module>
    from pyarrow.vendored import docscrape
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/vendored/docscrape.py", line 13, in <module>
    import pydoc
  File "/usr/local/lib/python3.8/pydoc.py", line 366, in <module>
    class Doc:
  File "/usr/local/lib/python3.8/pydoc.py", line 396, in Doc
    def getdocloc(self, object, basedir=sysconfig.get_path('stdlib')):
  File "/usr/local/lib/python3.8/sysconfig.py", line 526, in get_path
    return get_paths(scheme, vars, expand)[name]
  File "/usr/local/lib/python3.8/sysconfig.py", line 516, in get_paths
    return _expand_vars(scheme, vars)
  File "/usr/local/lib/python3.8/sysconfig.py", line 177, in _expand_vars
    _extend_dict(vars, get_config_vars())
  File "/usr/local/lib/python3.8/sysconfig.py", line 564, in get_config_vars
    _init_posix(_CONFIG_VARS)
  File "/usr/local/lib/python3.8/sysconfig.py", line 432, in _init_posix
    _temp = __import__(name, globals(), locals(), ['build_time_vars'], 0)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9151
[2023-11-14T12:11:17.776+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:11:21.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 38.397 seconds
[2023-11-14T12:12:10.489+0000] {processor.py:157} INFO - Started process (PID=9187) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:12:10.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:12:10.851+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:12:10.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:13:41.758+0000] {processor.py:157} INFO - Started process (PID=9218) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:13:42.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:13:42.398+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:13:42.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:14:14.721+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:14:14.720+0000] {timeout.py:68} ERROR - Process timed out, PID: 9218
[2023-11-14T12:14:20.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:14:15.053+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import is_numpy_dev as _is_numpy_dev  # pyright: ignore # noqa:F401
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/compat/__init__.py", line 25, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/compat/numpy/__init__.py", line 4, in <module>
    from pandas.util.version import Version
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/util/__init__.py", line 2, in <module>
    from pandas.util._decorators import (  # noqa:F401
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/interval.pyx", line 1, in init pandas._libs.interval
  File "pandas/_libs/hashtable.pyx", line 1, in init pandas._libs.hashtable
  File "pandas/_libs/missing.pyx", line 1, in init pandas._libs.missing
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/_libs/tslibs/__init__.py", line 39, in <module>
    from pandas._libs.tslibs.conversion import localize_pydatetime
  File "pandas/_libs/tslibs/conversion.pyx", line 1, in init pandas._libs.tslibs.conversion
  File "pandas/_libs/tslibs/parsing.pyx", line 76, in init pandas._libs.tslibs.parsing
  File "pandas/_libs/tslibs/strptime.pyx", line 1, in init pandas._libs.tslibs.strptime
  File "<frozen importlib._bootstrap>", line 200, in _lock_unlock_module
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9218
[2023-11-14T12:14:21.976+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:14:29.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 48.881 seconds
[2023-11-14T12:15:25.497+0000] {processor.py:157} INFO - Started process (PID=9252) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:15:25.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:15:25.534+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:15:25.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:16:04.332+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:16:04.259+0000] {timeout.py:68} ERROR - Process timed out, PID: 9252
[2023-11-14T12:16:04.964+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:16:04.357+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 27, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/array.py", line 77, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 96, in <module>
    from pyarrow.vendored import docscrape
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/vendored/docscrape.py", line 13, in <module>
    import pydoc
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9252
[2023-11-14T12:16:05.339+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:16:50.210+0000] {processor.py:157} INFO - Started process (PID=9291) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:16:50.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:16:50.777+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:16:50.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:17:22.203+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:17:21.838+0000] {timeout.py:68} ERROR - Process timed out, PID: 9291
[2023-11-14T12:17:22.453+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:17:22.306+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 48, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/api.py", line 27, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/arrays/arrow/array.py", line 77, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/compute.py", line 96, in <module>
    from pyarrow.vendored import docscrape
  File "/home/airflow/.local/lib/python3.8/site-packages/pyarrow/vendored/docscrape.py", line 13, in <module>
    import pydoc
  File "/usr/local/lib/python3.8/pydoc.py", line 366, in <module>
    class Doc:
  File "/usr/local/lib/python3.8/pydoc.py", line 396, in Doc
    def getdocloc(self, object, basedir=sysconfig.get_path('stdlib')):
  File "/usr/local/lib/python3.8/sysconfig.py", line 526, in get_path
    return get_paths(scheme, vars, expand)[name]
  File "/usr/local/lib/python3.8/sysconfig.py", line 516, in get_paths
    return _expand_vars(scheme, vars)
  File "/usr/local/lib/python3.8/sysconfig.py", line 177, in _expand_vars
    _extend_dict(vars, get_config_vars())
  File "/usr/local/lib/python3.8/sysconfig.py", line 564, in get_config_vars
    _init_posix(_CONFIG_VARS)
  File "/usr/local/lib/python3.8/sysconfig.py", line 432, in _init_posix
    _temp = __import__(name, globals(), locals(), ['build_time_vars'], 0)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9291
[2023-11-14T12:17:22.517+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:17:22.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 33.640 seconds
[2023-11-14T12:17:54.499+0000] {processor.py:157} INFO - Started process (PID=9323) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:17:54.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:17:54.575+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:17:54.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:19:18.246+0000] {processor.py:157} INFO - Started process (PID=9359) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:19:18.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:19:18.690+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:19:18.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:19:48.836+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:19:48.797+0000] {timeout.py:68} ERROR - Process timed out, PID: 9359
[2023-11-14T12:19:48.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:19:48.864+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 141, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/api.py", line 14, in <module>
    from pandas.io.json import read_json
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/json/__init__.py", line 1, in <module>
    from pandas.io.json._json import (
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 960, in _find_and_load_unlocked
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9359
[2023-11-14T12:19:48.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:19:49.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 31.468 seconds
[2023-11-14T12:20:21.089+0000] {processor.py:157} INFO - Started process (PID=9388) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:20:21.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:20:21.159+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:20:21.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:20:53.881+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:20:53.880+0000] {timeout.py:68} ERROR - Process timed out, PID: 9388
[2023-11-14T12:20:53.904+0000] {logging_mixin.py:151} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7fa4c93b5310>
[2023-11-14T12:20:53.914+0000] {logging_mixin.py:151} WARNING - Traceback (most recent call last):
[2023-11-14T12:20:53.915+0000] {logging_mixin.py:151} WARNING -   File "/usr/local/lib/python3.8/weakref.py", line 345, in remove
[2023-11-14T12:20:53.916+0000] {logging_mixin.py:151} WARNING -     def remove(k, selfref=ref(self)):
[2023-11-14T12:20:53.924+0000] {logging_mixin.py:151} WARNING -   File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2023-11-14T12:20:53.934+0000] {logging_mixin.py:151} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-11-14T12:20:53.936+0000] {logging_mixin.py:151} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 9388
[2023-11-14T12:20:54.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:20:55.945+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:20:55.944+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T12:20:55.952+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:20:55.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:20:56.153+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:20:56.153+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:20:56.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 35.473 seconds
[2023-11-14T12:21:27.081+0000] {processor.py:157} INFO - Started process (PID=9416) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:21:27.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:21:27.087+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:21:27.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:21:27.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:21:27.929+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:21:27.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:21:27.971+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:21:27.971+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:21:28.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.997 seconds
[2023-11-14T12:22:00.174+0000] {processor.py:157} INFO - Started process (PID=9436) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:22:00.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:22:00.185+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:22:00.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:22:14.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:22:15.131+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:22:15.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:22:15.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:22:15.654+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:22:16.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 16.184 seconds
[2023-11-14T12:22:47.543+0000] {processor.py:157} INFO - Started process (PID=9456) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:22:47.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:22:47.619+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:22:47.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:23:17.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:23:20.097+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:23:20.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:23:21.687+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:23:21.684+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:23:23.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 36.624 seconds
[2023-11-14T12:23:55.247+0000] {processor.py:157} INFO - Started process (PID=9494) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:23:55.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:23:55.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:23:55.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:23:56.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:23:56.877+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:23:56.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:23:57.051+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:23:57.050+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:23:57.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.937 seconds
[2023-11-14T12:24:28.300+0000] {processor.py:157} INFO - Started process (PID=9515) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:24:28.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:24:28.303+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:24:28.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:24:29.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:24:29.276+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:24:29.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:24:29.315+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:24:29.314+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:24:29.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.049 seconds
[2023-11-14T12:24:59.898+0000] {processor.py:157} INFO - Started process (PID=9535) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:24:59.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:24:59.906+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:24:59.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:25:00.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:25:01.056+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:25:01.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:25:01.109+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:25:01.109+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:25:01.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.259 seconds
[2023-11-14T12:25:31.786+0000] {processor.py:157} INFO - Started process (PID=9556) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:25:31.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:25:31.796+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:25:31.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:25:32.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:25:32.785+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:25:32.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:25:32.820+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:25:32.820+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:25:32.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.087 seconds
[2023-11-14T12:26:03.416+0000] {processor.py:157} INFO - Started process (PID=9577) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:26:03.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:26:03.419+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:26:03.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:26:04.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:26:04.278+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:26:04.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:26:04.315+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:26:04.315+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:26:04.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.938 seconds
[2023-11-14T12:26:35.185+0000] {processor.py:157} INFO - Started process (PID=9598) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:26:35.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:26:35.193+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:26:35.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:26:36.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:26:36.212+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:26:36.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:26:36.250+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:26:36.250+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:26:36.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.196 seconds
[2023-11-14T12:27:06.718+0000] {processor.py:157} INFO - Started process (PID=9627) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:27:06.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:27:06.720+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:27:06.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:27:07.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:27:07.801+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:27:07.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:27:07.836+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:27:07.835+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:27:07.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.214 seconds
[2023-11-14T12:27:38.597+0000] {processor.py:157} INFO - Started process (PID=9647) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:27:38.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:27:38.606+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:27:38.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:27:39.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:27:39.648+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:27:39.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:27:39.682+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:27:39.682+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:27:39.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.132 seconds
[2023-11-14T12:28:10.383+0000] {processor.py:157} INFO - Started process (PID=9667) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:28:10.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:28:10.390+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:28:10.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:28:11.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:28:11.323+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:28:11.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:28:11.370+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:28:11.369+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:28:11.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.091 seconds
[2023-11-14T12:28:44.308+0000] {processor.py:157} INFO - Started process (PID=9687) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:28:44.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:28:44.492+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:28:44.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:28:50.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:28:50.795+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:28:50.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:28:50.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:28:50.991+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:28:51.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 7.266 seconds
[2023-11-14T12:29:23.781+0000] {processor.py:157} INFO - Started process (PID=9706) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:29:23.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:29:23.827+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:29:23.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:29:44.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:29:45.765+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:29:45.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:29:46.927+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:29:46.924+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:29:48.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 24.672 seconds
[2023-11-14T12:30:19.185+0000] {processor.py:157} INFO - Started process (PID=9734) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:30:19.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:30:19.243+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:30:19.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:30:23.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:30:23.552+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:30:23.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:30:23.740+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:30:23.739+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:30:23.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.723 seconds
[2023-11-14T12:30:54.458+0000] {processor.py:157} INFO - Started process (PID=9748) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:30:54.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:30:54.513+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:30:54.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:30:56.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:30:56.137+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:30:56.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:30:56.223+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:30:56.222+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:30:56.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.931 seconds
[2023-11-14T12:31:27.412+0000] {processor.py:157} INFO - Started process (PID=9767) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:31:27.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:31:27.418+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:31:27.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:31:29.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:31:29.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:31:29.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:31:29.422+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:31:29.422+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:31:29.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.093 seconds
[2023-11-14T12:32:00.281+0000] {processor.py:157} INFO - Started process (PID=9787) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:32:00.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:32:00.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:32:00.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:32:01.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:32:01.998+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:32:01.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:32:02.091+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:32:02.090+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:32:02.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.907 seconds
[2023-11-14T12:32:33.106+0000] {processor.py:157} INFO - Started process (PID=9806) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:32:33.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:32:33.126+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:32:33.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:32:35.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:32:35.386+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:32:35.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:32:35.477+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:32:35.477+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:32:35.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.478 seconds
[2023-11-14T12:33:06.036+0000] {processor.py:157} INFO - Started process (PID=9825) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:33:06.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:33:06.042+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:33:06.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:33:07.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:33:08.025+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:33:08.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:33:08.099+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:33:08.098+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:33:08.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.159 seconds
[2023-11-14T12:33:39.043+0000] {processor.py:157} INFO - Started process (PID=9838) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:33:39.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:33:39.051+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:33:39.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:33:40.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:33:40.828+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:33:40.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:33:40.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:33:40.933+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:33:41.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.044 seconds
[2023-11-14T12:34:11.987+0000] {processor.py:157} INFO - Started process (PID=9858) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:34:11.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:34:11.999+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:34:11.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:34:13.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:34:13.840+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:34:13.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:34:13.915+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:34:13.914+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:34:14.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.043 seconds
[2023-11-14T12:34:44.317+0000] {processor.py:157} INFO - Started process (PID=9878) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:34:44.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:34:44.324+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:34:44.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:34:46.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:34:46.241+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:34:46.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:34:46.347+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:34:46.347+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:34:46.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.207 seconds
[2023-11-14T12:35:16.768+0000] {processor.py:157} INFO - Started process (PID=9898) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:35:16.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:35:16.776+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:35:16.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:35:18.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:35:18.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:35:18.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:35:18.821+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:35:18.821+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:35:18.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.168 seconds
[2023-11-14T12:35:49.682+0000] {processor.py:157} INFO - Started process (PID=9910) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:35:49.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:35:49.689+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:35:49.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:35:51.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:35:51.599+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:35:51.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:35:51.767+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:35:51.762+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:35:52.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.457 seconds
[2023-11-14T12:36:22.426+0000] {processor.py:157} INFO - Started process (PID=9931) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:36:22.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:36:22.435+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:36:22.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:36:24.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:36:24.327+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:36:24.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:36:24.447+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:36:24.446+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:36:24.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.121 seconds
[2023-11-14T12:36:55.235+0000] {processor.py:157} INFO - Started process (PID=9950) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:36:55.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:36:55.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:36:55.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:36:57.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:36:57.147+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:36:57.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:36:57.231+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:36:57.230+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:36:57.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.153 seconds
[2023-11-14T12:37:27.942+0000] {processor.py:157} INFO - Started process (PID=9971) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:37:27.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:37:27.953+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:37:27.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:37:29.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:37:30.025+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:37:30.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:37:30.116+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:37:30.115+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:37:30.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.317 seconds
[2023-11-14T12:38:00.896+0000] {processor.py:157} INFO - Started process (PID=9991) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:38:00.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:38:00.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:38:00.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:38:02.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:38:02.531+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:38:02.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:38:02.616+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:38:02.615+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:38:02.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.864 seconds
[2023-11-14T12:38:33.520+0000] {processor.py:157} INFO - Started process (PID=10012) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:38:33.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:38:33.526+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:38:33.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:38:35.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:38:35.243+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:38:35.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:38:35.302+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:38:35.301+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:38:35.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.849 seconds
[2023-11-14T12:39:06.092+0000] {processor.py:157} INFO - Started process (PID=10031) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:39:06.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:39:06.096+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:39:06.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:39:08.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:39:08.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:39:08.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:39:08.503+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:39:08.503+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:39:08.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.543 seconds
[2023-11-14T12:39:39.508+0000] {processor.py:157} INFO - Started process (PID=10049) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:39:39.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:39:39.515+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:39:39.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:39:40.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:39:41.076+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:39:41.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:39:41.173+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:39:41.173+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:39:41.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.795 seconds
[2023-11-14T12:40:12.283+0000] {processor.py:157} INFO - Started process (PID=10061) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:40:12.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:40:12.290+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:40:12.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:40:14.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:40:14.117+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:40:14.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:40:14.189+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:40:14.189+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:40:14.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.005 seconds
[2023-11-14T12:40:44.644+0000] {processor.py:157} INFO - Started process (PID=10081) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:40:44.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:40:44.650+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:40:44.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:40:46.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:40:46.551+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:40:46.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:40:46.613+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:40:46.613+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:40:46.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.102 seconds
[2023-11-14T12:41:17.406+0000] {processor.py:157} INFO - Started process (PID=10101) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:41:17.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:41:17.462+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:41:17.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:41:19.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:41:19.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:41:19.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:41:19.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:41:19.447+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:41:19.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.259 seconds
[2023-11-14T12:41:50.295+0000] {processor.py:157} INFO - Started process (PID=10121) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:41:50.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:41:50.302+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:41:50.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:41:51.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:41:51.900+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:41:51.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:41:51.979+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:41:51.978+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:41:52.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.773 seconds
[2023-11-14T12:42:22.854+0000] {processor.py:157} INFO - Started process (PID=10142) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:42:22.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:42:22.863+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:42:22.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:42:24.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:42:24.601+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:42:24.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:42:24.682+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:42:24.681+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:42:24.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.960 seconds
[2023-11-14T12:42:55.569+0000] {processor.py:157} INFO - Started process (PID=10162) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:42:55.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:42:55.576+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:42:55.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:42:56.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:42:57.081+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:42:57.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:42:57.163+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:42:57.162+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:42:57.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.748 seconds
[2023-11-14T12:43:28.038+0000] {processor.py:157} INFO - Started process (PID=10181) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:43:28.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:43:28.047+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:43:28.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:43:29.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:43:29.889+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:43:29.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:43:29.969+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:43:29.968+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:43:30.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.072 seconds
[2023-11-14T12:44:00.678+0000] {processor.py:157} INFO - Started process (PID=10201) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:44:00.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:44:00.684+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:44:00.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:44:02.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:44:02.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:44:02.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:44:02.342+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:44:02.341+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:44:02.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.793 seconds
[2023-11-14T12:44:32.987+0000] {processor.py:157} INFO - Started process (PID=10224) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:44:32.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:44:32.994+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:44:32.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:44:34.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:44:35.027+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:44:35.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:44:35.113+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:44:35.112+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:44:35.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.216 seconds
[2023-11-14T12:45:05.801+0000] {processor.py:157} INFO - Started process (PID=10243) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:45:05.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:45:05.808+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:45:05.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:45:07.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:45:07.475+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:45:07.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:45:07.561+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:45:07.559+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:45:07.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.896 seconds
[2023-11-14T12:45:38.411+0000] {processor.py:157} INFO - Started process (PID=10255) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:45:38.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T12:45:38.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:45:38.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:45:40.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T12:45:40.346+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:45:40.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T12:45:40.372+0000] {logging_mixin.py:151} INFO - [2023-11-14T12:45:40.372+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T12:45:40.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.001 seconds
[2023-11-14T13:22:10.311+0000] {processor.py:157} INFO - Started process (PID=10265) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:22:10.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:22:10.333+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:22:10.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:22:19.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:22:19.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:22:19.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:22:19.860+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:22:19.859+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:22:19.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 9.659 seconds
[2023-11-14T13:22:50.532+0000] {processor.py:157} INFO - Started process (PID=10285) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:22:50.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:22:50.544+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:22:50.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:22:53.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:22:53.989+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:22:53.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:22:54.067+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:22:54.066+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:22:54.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.634 seconds
[2023-11-14T13:23:24.834+0000] {processor.py:157} INFO - Started process (PID=10304) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:23:24.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:23:24.854+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:23:24.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:23:29.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:23:30.050+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:23:30.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:23:30.294+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:23:30.294+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:23:30.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 5.622 seconds
[2023-11-14T13:24:01.001+0000] {processor.py:157} INFO - Started process (PID=10323) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:24:01.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:24:01.017+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:24:01.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:24:04.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:24:05.919+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:24:05.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:24:06.124+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:24:06.124+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:24:06.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 5.224 seconds
[2023-11-14T13:24:37.064+0000] {processor.py:157} INFO - Started process (PID=10334) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:24:37.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:24:37.070+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:24:37.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:24:37.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:24:37.999+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:24:37.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:24:38.081+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:24:38.081+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:24:38.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.084 seconds
[2023-11-14T13:25:08.543+0000] {processor.py:157} INFO - Started process (PID=10354) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:25:08.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:25:08.546+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:25:08.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:25:09.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:25:09.775+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:25:09.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:25:09.858+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:25:09.858+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:25:09.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.381 seconds
[2023-11-14T13:25:40.248+0000] {processor.py:157} INFO - Started process (PID=10382) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:25:40.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:25:40.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:25:40.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:25:41.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:25:41.210+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:25:41.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:25:41.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:25:41.250+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:25:41.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.046 seconds
[2023-11-14T13:26:11.562+0000] {processor.py:157} INFO - Started process (PID=10401) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:26:11.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:26:11.565+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:26:11.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:26:12.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:26:12.227+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:26:12.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:26:12.263+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:26:12.262+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:26:12.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.751 seconds
[2023-11-14T13:26:42.907+0000] {processor.py:157} INFO - Started process (PID=10429) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:26:42.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:26:42.909+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:26:42.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:26:43.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:26:43.553+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:26:43.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:26:43.598+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:26:43.598+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:26:43.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.733 seconds
[2023-11-14T13:27:13.910+0000] {processor.py:157} INFO - Started process (PID=10452) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:27:13.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:27:13.913+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:27:13.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:27:14.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:27:14.597+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:27:14.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:27:14.624+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:27:14.623+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:27:14.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.744 seconds
[2023-11-14T13:27:45.025+0000] {processor.py:157} INFO - Started process (PID=10473) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:27:45.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:27:45.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:27:45.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:27:46.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:27:46.127+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:27:46.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:27:46.212+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:27:46.212+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:27:46.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.223 seconds
[2023-11-14T13:28:16.578+0000] {processor.py:157} INFO - Started process (PID=10502) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:28:16.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:28:16.584+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:28:16.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:28:17.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:28:17.150+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:28:17.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:28:17.173+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:28:17.173+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:28:17.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.623 seconds
[2023-11-14T13:28:47.669+0000] {processor.py:157} INFO - Started process (PID=10521) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:28:47.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:28:47.673+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:28:47.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:28:48.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:28:48.295+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:28:48.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:28:48.321+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:28:48.321+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:28:48.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.682 seconds
[2023-11-14T13:29:18.718+0000] {processor.py:157} INFO - Started process (PID=10549) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:29:18.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:29:18.720+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:29:18.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:29:19.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:29:19.300+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:29:19.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:29:19.323+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:29:19.323+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:29:19.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.629 seconds
[2023-11-14T13:29:49.709+0000] {processor.py:157} INFO - Started process (PID=10569) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:29:49.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:29:49.712+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:29:49.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:29:50.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:29:50.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:29:50.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:29:50.367+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:29:50.366+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:29:50.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.694 seconds
[2023-11-14T13:30:20.801+0000] {processor.py:157} INFO - Started process (PID=10597) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:30:20.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:30:20.806+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:30:20.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:30:22.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:30:22.123+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:30:22.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:30:22.175+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:30:22.175+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:30:22.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.415 seconds
[2023-11-14T13:30:52.517+0000] {processor.py:157} INFO - Started process (PID=10616) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:30:52.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:30:52.520+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:30:52.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:30:53.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:30:53.151+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:30:53.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:30:53.191+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:30:53.190+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:30:53.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.713 seconds
[2023-11-14T13:31:23.791+0000] {processor.py:157} INFO - Started process (PID=10645) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:31:23.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:31:23.796+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:31:23.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:31:24.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:31:24.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:31:24.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:31:24.610+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:31:24.610+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:31:24.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.904 seconds
[2023-11-14T13:31:55.038+0000] {processor.py:157} INFO - Started process (PID=10666) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:31:55.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:31:55.043+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:31:55.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:31:55.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:31:55.702+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:31:55.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:31:55.726+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:31:55.726+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:31:55.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.719 seconds
[2023-11-14T13:32:26.079+0000] {processor.py:157} INFO - Started process (PID=10695) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:32:26.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:32:26.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:32:26.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:32:26.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:32:26.696+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:32:26.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:32:26.723+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:32:26.722+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:32:26.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.670 seconds
[2023-11-14T13:32:57.139+0000] {processor.py:157} INFO - Started process (PID=10716) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:32:57.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:32:57.141+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:32:57.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:32:57.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:32:57.745+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:32:57.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:32:57.770+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:32:57.770+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:32:57.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.658 seconds
[2023-11-14T13:33:28.164+0000] {processor.py:157} INFO - Started process (PID=10746) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:33:28.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:33:28.168+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:33:28.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:33:29.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:33:29.201+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:33:29.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:33:29.226+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:33:29.226+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:33:29.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.095 seconds
[2023-11-14T13:33:59.584+0000] {processor.py:157} INFO - Started process (PID=10766) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:33:59.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:33:59.587+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:33:59.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:34:00.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:34:00.157+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:34:00.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:34:00.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:34:00.185+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:34:00.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.630 seconds
[2023-11-14T13:34:30.621+0000] {processor.py:157} INFO - Started process (PID=10786) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:34:30.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:34:30.624+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:34:30.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:34:31.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:34:31.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:34:31.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:34:31.418+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:34:31.417+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:34:31.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.821 seconds
[2023-11-14T13:35:01.803+0000] {processor.py:157} INFO - Started process (PID=10813) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:35:01.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:35:01.806+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:35:01.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:35:02.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:35:02.457+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:35:02.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:35:02.482+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:35:02.482+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:35:02.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.704 seconds
[2023-11-14T13:35:32.881+0000] {processor.py:157} INFO - Started process (PID=10833) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:35:32.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:35:32.885+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:35:32.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:35:33.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:35:33.577+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:35:33.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:35:33.610+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:35:33.609+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:35:33.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.774 seconds
[2023-11-14T13:36:04.042+0000] {processor.py:157} INFO - Started process (PID=10863) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:36:04.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:36:04.044+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:36:04.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:36:04.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:36:04.630+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:36:04.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:36:04.659+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:36:04.658+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:36:04.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.670 seconds
[2023-11-14T13:36:35.239+0000] {processor.py:157} INFO - Started process (PID=10884) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:36:35.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:36:35.243+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:36:35.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:36:35.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:36:35.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:36:35.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:36:35.965+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:36:35.964+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:36:35.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.752 seconds
[2023-11-14T13:37:06.376+0000] {processor.py:157} INFO - Started process (PID=10913) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:37:06.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:37:06.378+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:37:06.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:37:06.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:37:06.950+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:37:06.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:37:06.973+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:37:06.973+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:37:06.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.624 seconds
[2023-11-14T13:37:37.362+0000] {processor.py:157} INFO - Started process (PID=10933) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:37:37.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:37:37.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:37:37.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:37:38.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:37:38.136+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:37:38.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:37:38.161+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:37:38.161+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:37:38.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.824 seconds
[2023-11-14T13:38:08.540+0000] {processor.py:157} INFO - Started process (PID=10962) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:38:08.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:38:08.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:38:08.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:38:09.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:38:09.468+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:38:09.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:38:09.503+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:38:09.503+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:38:09.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.996 seconds
[2023-11-14T13:38:39.952+0000] {processor.py:157} INFO - Started process (PID=10983) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:38:39.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:38:39.954+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:38:39.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:38:40.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:38:40.636+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:38:40.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:38:40.673+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:38:40.672+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:38:40.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.765 seconds
[2023-11-14T13:39:11.037+0000] {processor.py:157} INFO - Started process (PID=11012) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:39:11.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:39:11.041+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:39:11.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:39:11.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:39:11.676+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:39:11.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:39:11.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:39:11.700+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:39:11.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.690 seconds
[2023-11-14T13:39:42.091+0000] {processor.py:157} INFO - Started process (PID=11032) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:39:42.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:39:42.095+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:39:42.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:39:42.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:39:42.743+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:39:42.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:39:42.766+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:39:42.766+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:39:42.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.703 seconds
[2023-11-14T13:40:13.204+0000] {processor.py:157} INFO - Started process (PID=11061) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:40:13.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:40:13.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:40:13.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:40:13.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:40:13.827+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:40:13.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:40:13.851+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:40:13.851+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:40:13.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.682 seconds
[2023-11-14T13:40:44.285+0000] {processor.py:157} INFO - Started process (PID=11081) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:40:44.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:40:44.288+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:40:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:40:44.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:40:44.882+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:40:44.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:40:44.910+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:40:44.910+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:40:44.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.661 seconds
[2023-11-14T13:41:15.400+0000] {processor.py:157} INFO - Started process (PID=11109) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:41:15.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:41:15.402+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:41:15.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:41:16.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:41:16.117+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:41:16.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:41:16.151+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:41:16.150+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:41:16.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.791 seconds
[2023-11-14T13:41:46.710+0000] {processor.py:157} INFO - Started process (PID=11131) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:41:46.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:41:46.713+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:41:46.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:41:47.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:41:47.446+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:41:47.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:41:47.470+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:41:47.469+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:41:47.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.806 seconds
[2023-11-14T13:42:17.936+0000] {processor.py:157} INFO - Started process (PID=11158) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:42:17.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:42:17.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:42:17.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:42:18.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:42:18.754+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:42:18.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:42:18.781+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:42:18.781+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:42:18.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.883 seconds
[2023-11-14T13:42:49.265+0000] {processor.py:157} INFO - Started process (PID=11180) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:42:49.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:42:49.267+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:42:49.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:42:49.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:42:49.849+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:42:49.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:42:49.872+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:42:49.871+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:42:49.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.635 seconds
[2023-11-14T13:43:20.278+0000] {processor.py:157} INFO - Started process (PID=11207) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:43:20.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:43:20.280+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:43:20.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:43:20.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:43:20.860+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:43:20.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:43:20.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:43:20.900+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:43:20.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.658 seconds
[2023-11-14T13:43:51.274+0000] {processor.py:157} INFO - Started process (PID=11228) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:43:51.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:43:51.278+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:43:51.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:43:51.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:43:51.834+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:43:51.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:43:51.859+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:43:51.859+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:43:51.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.620 seconds
[2023-11-14T13:44:22.368+0000] {processor.py:157} INFO - Started process (PID=11250) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:44:22.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:44:22.378+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:44:22.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:44:23.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:44:23.508+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:44:23.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:44:23.532+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:44:23.532+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:44:23.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.195 seconds
[2023-11-14T13:44:53.954+0000] {processor.py:157} INFO - Started process (PID=11277) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:44:53.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:44:53.957+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:44:53.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:44:54.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:44:54.528+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:44:54.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:44:54.554+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:44:54.554+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:44:54.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.628 seconds
[2023-11-14T13:45:24.994+0000] {processor.py:157} INFO - Started process (PID=11298) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:45:24.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:45:24.996+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:45:24.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:45:25.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:45:25.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:45:25.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:45:25.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:45:25.743+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:45:25.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.781 seconds
[2023-11-14T13:45:56.153+0000] {processor.py:157} INFO - Started process (PID=11328) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:45:56.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:45:56.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:45:56.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:45:56.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:45:56.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:45:56.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:45:56.924+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:45:56.924+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:45:56.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.801 seconds
[2023-11-14T13:46:27.546+0000] {processor.py:157} INFO - Started process (PID=11348) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:46:27.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:46:27.548+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:46:27.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:46:28.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:46:28.187+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:46:28.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:46:28.212+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:46:28.212+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:46:28.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.692 seconds
[2023-11-14T13:46:58.622+0000] {processor.py:157} INFO - Started process (PID=11377) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:46:58.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:46:58.625+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:46:58.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:46:59.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:46:59.175+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:46:59.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:46:59.198+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:46:59.198+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:46:59.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.610 seconds
[2023-11-14T13:47:29.620+0000] {processor.py:157} INFO - Started process (PID=11397) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:47:29.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:47:29.622+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:47:29.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:47:30.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:47:30.241+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:47:30.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:47:30.269+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:47:30.269+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:47:30.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.679 seconds
[2023-11-14T13:48:00.696+0000] {processor.py:157} INFO - Started process (PID=11427) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:48:00.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:48:00.701+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:48:00.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:48:01.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:48:01.312+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:48:01.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:48:01.341+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:48:01.341+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:48:01.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.669 seconds
[2023-11-14T13:48:31.775+0000] {processor.py:157} INFO - Started process (PID=11447) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:48:31.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:48:31.778+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:48:31.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:48:32.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:48:32.385+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:48:32.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:48:32.414+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:48:32.414+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:48:32.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.676 seconds
[2023-11-14T13:49:02.786+0000] {processor.py:157} INFO - Started process (PID=11477) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:49:02.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:49:02.790+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:49:02.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:49:03.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:49:03.361+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:49:03.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:49:03.385+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:49:03.385+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:49:03.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.633 seconds
[2023-11-14T13:49:33.753+0000] {processor.py:157} INFO - Started process (PID=11498) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:49:33.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:49:33.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:49:33.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:49:34.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:49:34.378+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:49:34.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:49:34.406+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:49:34.405+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:49:34.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.681 seconds
[2023-11-14T13:50:04.742+0000] {processor.py:157} INFO - Started process (PID=11527) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:50:04.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:50:04.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:50:04.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:50:05.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:50:05.336+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:50:05.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:50:05.367+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:50:05.366+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:50:05.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.658 seconds
[2023-11-14T13:50:35.815+0000] {processor.py:157} INFO - Started process (PID=11548) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:50:35.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:50:35.818+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:50:35.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:50:36.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:50:36.397+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:50:36.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:50:36.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:50:36.423+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:50:36.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.644 seconds
[2023-11-14T13:51:06.849+0000] {processor.py:157} INFO - Started process (PID=11575) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:51:06.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:51:06.854+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:51:06.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:51:07.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:51:07.401+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:51:07.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:51:07.427+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:51:07.427+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:51:07.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.610 seconds
[2023-11-14T13:51:38.129+0000] {processor.py:157} INFO - Started process (PID=11596) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:51:38.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:51:38.134+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:51:38.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:51:38.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:51:39.015+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:51:39.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:51:39.055+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:51:39.055+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:51:39.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.959 seconds
[2023-11-14T13:52:09.439+0000] {processor.py:157} INFO - Started process (PID=11625) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:52:09.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:52:09.443+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:52:09.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:52:10.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:52:10.132+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:52:10.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:52:10.187+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:52:10.187+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:52:10.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.782 seconds
[2023-11-14T13:52:40.534+0000] {processor.py:157} INFO - Started process (PID=11645) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:52:40.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:52:40.537+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:52:40.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:52:40.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:52:41.004+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:52:41.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:52:41.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:52:41.029+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:52:41.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.522 seconds
[2023-11-14T13:53:11.363+0000] {processor.py:157} INFO - Started process (PID=11664) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:53:11.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:53:11.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:53:11.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:53:11.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:53:11.775+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:53:11.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:53:11.802+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:53:11.802+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:53:11.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.474 seconds
[2023-11-14T13:53:42.226+0000] {processor.py:157} INFO - Started process (PID=11693) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:53:42.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:53:42.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:53:42.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:53:42.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:53:42.654+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:53:42.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:53:42.683+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:53:42.682+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:53:42.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.486 seconds
[2023-11-14T13:54:13.090+0000] {processor.py:157} INFO - Started process (PID=11713) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:54:13.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:54:13.092+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:54:13.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:54:13.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:54:13.530+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:54:13.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:54:13.557+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:54:13.557+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:54:13.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.493 seconds
[2023-11-14T13:54:44.010+0000] {processor.py:157} INFO - Started process (PID=11741) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:54:44.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:54:44.013+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:54:44.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:54:44.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:54:44.592+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:54:44.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:54:44.634+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:54:44.634+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:54:44.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.669 seconds
[2023-11-14T13:55:15.057+0000] {processor.py:157} INFO - Started process (PID=11762) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:55:15.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:55:15.059+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:55:15.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:55:15.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:55:15.766+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:55:15.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:55:15.815+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:55:15.814+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:55:15.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.826 seconds
[2023-11-14T13:55:46.247+0000] {processor.py:157} INFO - Started process (PID=11791) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:55:46.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:55:46.249+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:55:46.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:55:46.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:55:46.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:55:46.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:55:46.751+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:55:46.751+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:55:46.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.549 seconds
[2023-11-14T13:56:17.162+0000] {processor.py:157} INFO - Started process (PID=11812) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:56:17.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:56:17.165+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:56:17.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:56:17.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:56:17.665+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:56:17.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:56:17.698+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:56:17.698+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:56:17.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.568 seconds
[2023-11-14T13:56:48.220+0000] {processor.py:157} INFO - Started process (PID=11841) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:56:48.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:56:48.223+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:56:48.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:56:48.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:56:48.726+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:56:48.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:56:48.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:56:48.754+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:56:48.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.561 seconds
[2023-11-14T13:57:19.175+0000] {processor.py:157} INFO - Started process (PID=11862) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:57:19.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:57:19.178+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:57:19.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:57:19.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:57:19.662+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:57:19.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:57:19.692+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:57:19.692+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:57:19.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T13:57:50.080+0000] {processor.py:157} INFO - Started process (PID=11882) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:57:50.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:57:50.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:57:50.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:57:50.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:57:50.881+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:57:50.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:57:50.916+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:57:50.916+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:57:50.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.872 seconds
[2023-11-14T13:58:21.225+0000] {processor.py:157} INFO - Started process (PID=11910) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:58:21.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:58:21.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:58:21.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:58:21.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:58:21.651+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:58:21.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:58:21.679+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:58:21.679+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:58:21.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.482 seconds
[2023-11-14T13:58:52.158+0000] {processor.py:157} INFO - Started process (PID=11931) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:58:52.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:58:52.161+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:58:52.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:58:52.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:58:52.580+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:58:52.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:58:52.607+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:58:52.606+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:58:52.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.478 seconds
[2023-11-14T13:59:23.043+0000] {processor.py:157} INFO - Started process (PID=11959) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:59:23.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:59:23.046+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:59:23.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:59:23.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:59:23.541+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:59:23.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:59:23.580+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:59:23.580+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:59:23.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.567 seconds
[2023-11-14T13:59:54.016+0000] {processor.py:157} INFO - Started process (PID=11980) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:59:54.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T13:59:54.018+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:59:54.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:59:54.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T13:59:54.467+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:59:54.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T13:59:54.496+0000] {logging_mixin.py:151} INFO - [2023-11-14T13:59:54.496+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T13:59:54.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.529 seconds
[2023-11-14T14:00:24.940+0000] {processor.py:157} INFO - Started process (PID=12008) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:00:24.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:00:24.942+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:00:24.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:00:25.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:00:25.368+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:00:25.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:00:25.404+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:00:25.404+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:00:25.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.502 seconds
[2023-11-14T14:00:55.750+0000] {processor.py:157} INFO - Started process (PID=12030) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:00:55.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:00:55.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:00:55.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:00:56.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:00:56.246+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:00:56.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:00:56.272+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:00:56.272+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:00:56.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.552 seconds
[2023-11-14T14:01:26.817+0000] {processor.py:157} INFO - Started process (PID=12059) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:01:26.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:01:26.820+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:01:26.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:01:27.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:01:27.246+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:01:27.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:01:27.276+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:01:27.276+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:01:27.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.501 seconds
[2023-11-14T14:01:57.773+0000] {processor.py:157} INFO - Started process (PID=12080) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:01:57.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:01:57.783+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:01:57.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:01:58.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:01:58.423+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:01:58.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:01:58.454+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:01:58.454+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:01:58.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.732 seconds
[2023-11-14T14:02:28.870+0000] {processor.py:157} INFO - Started process (PID=12108) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:02:28.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:02:28.874+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:02:28.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:02:29.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:02:29.503+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:02:29.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:02:29.551+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:02:29.551+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:02:29.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.722 seconds
[2023-11-14T14:02:59.936+0000] {processor.py:157} INFO - Started process (PID=12128) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:02:59.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:02:59.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:02:59.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:03:00.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:03:00.746+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:03:00.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:03:00.784+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:03:00.783+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:03:00.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.884 seconds
[2023-11-14T14:03:31.186+0000] {processor.py:157} INFO - Started process (PID=12149) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:03:31.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:03:31.189+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:03:31.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:03:31.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:03:31.624+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:03:31.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:03:31.651+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:03:31.651+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:03:31.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.492 seconds
[2023-11-14T14:04:02.015+0000] {processor.py:157} INFO - Started process (PID=12178) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:04:02.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:04:02.017+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:04:02.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:04:02.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:04:02.441+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:04:02.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:04:02.467+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:04:02.467+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:04:02.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.479 seconds
[2023-11-14T14:04:32.833+0000] {processor.py:157} INFO - Started process (PID=12199) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:04:32.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:04:32.835+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:04:32.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:04:33.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:04:33.463+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:04:33.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:04:33.502+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:04:33.502+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:04:33.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.700 seconds
[2023-11-14T14:05:03.939+0000] {processor.py:157} INFO - Started process (PID=12229) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:05:03.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:05:03.942+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:05:03.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:05:04.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:05:04.410+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:05:04.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:05:04.439+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:05:04.439+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:05:04.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.535 seconds
[2023-11-14T14:05:34.850+0000] {processor.py:157} INFO - Started process (PID=12250) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:05:34.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:05:34.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:05:34.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:05:35.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:05:35.457+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:05:35.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:05:35.518+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:05:35.518+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:05:35.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.697 seconds
[2023-11-14T14:06:05.850+0000] {processor.py:157} INFO - Started process (PID=12280) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:06:05.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:06:05.852+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:06:05.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:06:06.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:06:06.428+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:06:06.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:06:06.471+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:06:06.471+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:06:06.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.690 seconds
[2023-11-14T14:06:37.020+0000] {processor.py:157} INFO - Started process (PID=12301) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:06:37.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:06:37.022+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:06:37.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:06:37.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:06:37.538+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:06:37.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:06:37.566+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:06:37.566+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:06:37.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.571 seconds
[2023-11-14T14:07:07.931+0000] {processor.py:157} INFO - Started process (PID=12330) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:07:07.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:07:07.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:07:07.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:07:08.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:07:08.467+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:07:08.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:07:08.497+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:07:08.497+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:07:08.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.604 seconds
[2023-11-14T14:07:38.915+0000] {processor.py:157} INFO - Started process (PID=12350) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:07:38.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:07:38.918+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:07:38.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:07:39.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:07:39.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:07:39.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:07:39.379+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:07:39.378+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:07:39.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.490 seconds
[2023-11-14T14:08:09.619+0000] {processor.py:157} INFO - Started process (PID=12378) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:08:09.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:08:09.621+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:08:09.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:08:10.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:08:10.118+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:08:10.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:08:10.146+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:08:10.146+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:08:10.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.553 seconds
[2023-11-14T14:08:40.654+0000] {processor.py:157} INFO - Started process (PID=12399) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:08:40.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:08:40.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:08:40.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:08:41.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:08:41.168+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:08:41.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:08:41.202+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:08:41.202+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:08:41.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.574 seconds
[2023-11-14T14:09:11.543+0000] {processor.py:157} INFO - Started process (PID=12420) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:09:11.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:09:11.548+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:09:11.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:09:11.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:09:11.963+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:09:11.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:09:11.989+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:09:11.988+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:09:12.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.478 seconds
[2023-11-14T14:09:42.333+0000] {processor.py:157} INFO - Started process (PID=12451) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:09:42.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:09:42.335+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:09:42.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:09:42.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:09:42.746+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:09:42.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:09:42.782+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:09:42.782+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:09:42.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.482 seconds
[2023-11-14T14:10:13.196+0000] {processor.py:157} INFO - Started process (PID=12472) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:10:13.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:10:13.198+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:10:13.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:10:13.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:10:13.649+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:10:13.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:10:13.683+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:10:13.683+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:10:13.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.517 seconds
[2023-11-14T14:10:44.159+0000] {processor.py:157} INFO - Started process (PID=12502) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:10:44.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:10:44.162+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:10:44.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:10:44.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:10:44.696+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:10:44.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:10:44.730+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:10:44.730+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:10:44.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.614 seconds
[2023-11-14T14:11:15.090+0000] {processor.py:157} INFO - Started process (PID=12522) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:11:15.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:11:15.093+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:11:15.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:11:15.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:11:15.545+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:11:15.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:11:15.571+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:11:15.571+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:11:15.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.510 seconds
[2023-11-14T14:11:46.201+0000] {processor.py:157} INFO - Started process (PID=12552) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:11:46.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:11:46.204+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:11:46.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:11:46.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:11:46.743+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:11:46.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:11:46.771+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:11:46.771+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:11:46.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.602 seconds
[2023-11-14T14:12:17.191+0000] {processor.py:157} INFO - Started process (PID=12573) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:12:17.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:12:17.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:12:17.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:12:17.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:12:17.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:12:17.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:12:17.757+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:12:17.756+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:12:17.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.603 seconds
[2023-11-14T14:12:48.224+0000] {processor.py:157} INFO - Started process (PID=12593) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:12:48.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:12:48.230+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:12:48.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:12:48.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:12:48.673+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:12:48.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:12:48.704+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:12:48.703+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:12:48.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.514 seconds
[2023-11-14T14:13:19.070+0000] {processor.py:157} INFO - Started process (PID=12622) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:13:19.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:13:19.072+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:13:19.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:13:19.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:13:19.534+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:13:19.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:13:19.563+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:13:19.563+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:13:19.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.546 seconds
[2023-11-14T14:13:49.971+0000] {processor.py:157} INFO - Started process (PID=12642) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:13:49.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:13:49.978+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:13:49.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:13:50.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:13:50.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:13:50.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:13:50.507+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:13:50.507+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:13:50.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.579 seconds
[2023-11-14T14:14:20.907+0000] {processor.py:157} INFO - Started process (PID=12672) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:14:20.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:14:20.910+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:14:20.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:14:21.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:14:21.442+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:14:21.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:14:21.484+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:14:21.482+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:14:21.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.615 seconds
[2023-11-14T14:14:51.951+0000] {processor.py:157} INFO - Started process (PID=12694) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:14:51.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:14:51.954+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:14:51.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:14:52.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:14:52.366+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:14:52.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:14:52.392+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:14:52.391+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:14:52.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.469 seconds
[2023-11-14T14:15:22.824+0000] {processor.py:157} INFO - Started process (PID=12724) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:15:22.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:15:22.829+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:15:22.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:15:23.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:15:23.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:15:23.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:15:23.278+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:15:23.278+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:15:23.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.479 seconds
[2023-11-14T14:15:53.720+0000] {processor.py:157} INFO - Started process (PID=12746) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:15:53.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:15:53.723+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:15:53.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:15:55.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:15:55.525+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:15:55.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:15:55.585+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:15:55.585+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:15:55.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.997 seconds
[2023-11-14T14:16:26.151+0000] {processor.py:157} INFO - Started process (PID=12774) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:16:26.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:16:26.154+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:16:26.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:16:26.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:16:26.612+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:16:26.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:16:26.644+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:16:26.644+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:16:26.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.536 seconds
[2023-11-14T14:16:57.134+0000] {processor.py:157} INFO - Started process (PID=12793) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:16:57.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:16:57.140+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:16:57.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:16:57.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:16:57.800+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:16:57.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:16:57.838+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:16:57.838+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:16:57.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.789 seconds
[2023-11-14T14:17:28.250+0000] {processor.py:157} INFO - Started process (PID=12813) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:17:28.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:17:28.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:17:28.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:17:28.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:17:28.699+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:17:28.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:17:28.726+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:17:28.726+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:17:28.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.508 seconds
[2023-11-14T14:17:59.115+0000] {processor.py:157} INFO - Started process (PID=12843) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:17:59.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:17:59.118+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:17:59.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:17:59.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:17:59.576+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:17:59.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:17:59.602+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:17:59.602+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:17:59.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.511 seconds
[2023-11-14T14:18:30.020+0000] {processor.py:157} INFO - Started process (PID=12863) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:18:30.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:18:30.032+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:18:30.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:18:31.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:18:31.443+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:18:31.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:18:31.723+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:18:31.714+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:18:31.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.845 seconds
[2023-11-14T14:19:02.229+0000] {processor.py:157} INFO - Started process (PID=12886) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:19:02.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:19:02.232+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:19:02.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:19:02.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:19:02.753+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:19:02.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:19:02.787+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:19:02.786+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:19:02.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.587 seconds
[2023-11-14T14:19:33.126+0000] {processor.py:157} INFO - Started process (PID=12906) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:19:33.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:19:33.129+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:19:33.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:19:33.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:19:33.708+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:19:33.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:19:33.735+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:19:33.735+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:19:33.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.640 seconds
[2023-11-14T14:20:04.368+0000] {processor.py:157} INFO - Started process (PID=12933) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:20:04.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:20:04.383+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:20:04.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:20:07.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:20:07.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:20:07.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:20:07.999+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:20:07.998+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:20:08.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.854 seconds
[2023-11-14T14:20:38.606+0000] {processor.py:157} INFO - Started process (PID=12954) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:20:38.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:20:38.608+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:20:38.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:20:39.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:20:39.192+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:20:39.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:20:39.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:20:39.228+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:20:39.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.654 seconds
[2023-11-14T14:21:09.882+0000] {processor.py:157} INFO - Started process (PID=12974) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:21:09.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:21:09.885+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:21:09.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:21:10.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:21:10.336+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:21:10.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:21:10.383+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:21:10.383+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:21:10.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.533 seconds
[2023-11-14T14:21:40.761+0000] {processor.py:157} INFO - Started process (PID=12994) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:21:40.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:21:40.764+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:21:40.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:21:41.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:21:41.235+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:21:41.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:21:41.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:21:41.267+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:21:41.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.540 seconds
[2023-11-14T14:22:11.591+0000] {processor.py:157} INFO - Started process (PID=13024) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:22:11.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:22:11.594+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:22:11.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:22:12.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:22:12.189+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:22:12.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:22:12.226+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:22:12.226+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:22:12.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.669 seconds
[2023-11-14T14:22:42.600+0000] {processor.py:157} INFO - Started process (PID=13045) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:22:42.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:22:42.605+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:22:42.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:22:43.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:22:43.188+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:22:43.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:22:43.226+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:22:43.226+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:22:43.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.662 seconds
[2023-11-14T14:23:13.544+0000] {processor.py:157} INFO - Started process (PID=13065) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:23:13.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:23:13.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:23:13.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:23:13.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:23:13.983+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:23:13.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:23:14.010+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:23:14.010+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:23:14.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.496 seconds
[2023-11-14T14:23:44.350+0000] {processor.py:157} INFO - Started process (PID=13095) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:23:44.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:23:44.352+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:23:44.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:23:44.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:23:44.841+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:23:44.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:23:44.886+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:23:44.886+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:23:44.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.576 seconds
[2023-11-14T14:24:15.626+0000] {processor.py:157} INFO - Started process (PID=13115) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:24:15.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:24:15.629+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:24:15.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:24:16.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:24:16.283+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:24:16.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:24:16.311+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:24:16.311+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:24:16.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.714 seconds
[2023-11-14T14:24:46.570+0000] {processor.py:157} INFO - Started process (PID=13142) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:24:46.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:24:46.575+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:24:46.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:24:47.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:24:47.113+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:24:47.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:24:47.146+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:24:47.145+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:24:47.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.607 seconds
[2023-11-14T14:25:17.460+0000] {processor.py:157} INFO - Started process (PID=13162) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:25:17.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:25:17.462+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:25:17.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:25:17.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:25:17.925+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:25:17.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:25:17.952+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:25:17.952+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:25:17.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.521 seconds
[2023-11-14T14:25:48.254+0000] {processor.py:157} INFO - Started process (PID=13190) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:25:48.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:25:48.256+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:25:48.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:25:48.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:25:48.672+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:25:48.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:25:48.701+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:25:48.701+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:25:48.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.472 seconds
[2023-11-14T14:26:19.536+0000] {processor.py:157} INFO - Started process (PID=13209) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:26:19.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:26:19.538+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:26:19.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:26:19.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:26:19.962+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:26:19.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:26:19.987+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:26:19.987+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:26:20.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.481 seconds
[2023-11-14T14:26:50.356+0000] {processor.py:157} INFO - Started process (PID=13230) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:26:50.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:26:50.358+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:26:50.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:26:50.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:26:50.801+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:26:50.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:26:50.832+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:26:50.832+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:26:50.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.507 seconds
[2023-11-14T14:27:21.166+0000] {processor.py:157} INFO - Started process (PID=13259) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:27:21.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:27:21.168+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:27:21.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:27:21.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:27:21.631+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:27:21.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:27:21.664+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:27:21.664+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:27:21.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.525 seconds
[2023-11-14T14:27:52.066+0000] {processor.py:157} INFO - Started process (PID=13279) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:27:52.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:27:52.070+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:27:52.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:27:52.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:27:52.738+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:27:52.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:27:52.788+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:27:52.787+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:27:52.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.767 seconds
[2023-11-14T14:28:23.189+0000] {processor.py:157} INFO - Started process (PID=13301) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:28:23.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:28:23.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:28:23.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:28:23.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:28:23.965+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:28:23.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:28:24.001+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:28:24.001+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:28:24.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.849 seconds
[2023-11-14T14:28:54.312+0000] {processor.py:157} INFO - Started process (PID=13331) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:28:54.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:28:54.314+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:28:54.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:28:54.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:28:54.779+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:28:54.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:28:54.805+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:28:54.805+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:28:54.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.521 seconds
[2023-11-14T14:29:25.108+0000] {processor.py:157} INFO - Started process (PID=13352) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:29:25.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:29:25.110+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:29:25.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:29:25.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:29:25.581+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:29:25.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:29:25.615+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:29:25.614+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:29:25.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.537 seconds
[2023-11-14T14:29:55.921+0000] {processor.py:157} INFO - Started process (PID=13380) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:29:55.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:29:55.924+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:29:55.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:29:56.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:29:56.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:29:56.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:29:56.497+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:29:56.496+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:29:56.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.619 seconds
[2023-11-14T14:30:26.867+0000] {processor.py:157} INFO - Started process (PID=13399) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:30:26.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:30:26.869+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:30:26.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:30:27.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:30:27.705+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:30:27.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:30:27.752+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:30:27.752+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:30:27.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.925 seconds
[2023-11-14T14:30:58.126+0000] {processor.py:157} INFO - Started process (PID=13420) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:30:58.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:30:58.128+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:30:58.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:30:58.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:30:58.616+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:30:58.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:30:58.646+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:30:58.645+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:30:58.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.550 seconds
[2023-11-14T14:31:29.015+0000] {processor.py:157} INFO - Started process (PID=13448) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:31:29.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:31:29.017+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:31:29.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:31:29.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:31:29.474+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:31:29.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:31:29.500+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:31:29.500+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:31:29.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.512 seconds
[2023-11-14T14:31:59.856+0000] {processor.py:157} INFO - Started process (PID=13469) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:31:59.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:31:59.858+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:31:59.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:32:00.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:32:00.362+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:32:00.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:32:00.390+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:32:00.390+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:32:00.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.569 seconds
[2023-11-14T14:32:30.781+0000] {processor.py:157} INFO - Started process (PID=13498) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:32:30.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:32:30.783+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:32:30.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:32:31.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:32:31.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:32:31.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:32:31.221+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:32:31.221+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:32:31.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.484 seconds
[2023-11-14T14:33:01.357+0000] {processor.py:157} INFO - Started process (PID=13516) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:33:01.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:33:01.359+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:33:01.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:33:01.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:33:01.798+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:33:01.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:33:01.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:33:01.824+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:33:01.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.494 seconds
[2023-11-14T14:33:32.228+0000] {processor.py:157} INFO - Started process (PID=13546) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:33:32.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:33:32.231+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:33:32.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:33:32.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:33:32.705+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:33:32.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:33:32.732+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:33:32.732+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:33:32.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.535 seconds
[2023-11-14T14:34:03.129+0000] {processor.py:157} INFO - Started process (PID=13567) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:34:03.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:34:03.132+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:34:03.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:34:03.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:34:03.587+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:34:03.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:34:03.613+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:34:03.613+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:34:03.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.511 seconds
[2023-11-14T14:34:34.439+0000] {processor.py:157} INFO - Started process (PID=13597) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:34:34.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:34:34.441+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:34:34.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:34:35.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:34:35.513+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:34:35.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:34:35.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:34:35.547+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:34:35.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.136 seconds
[2023-11-14T14:35:05.929+0000] {processor.py:157} INFO - Started process (PID=13616) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:35:05.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:35:05.931+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:35:05.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:35:06.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:35:06.430+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:35:06.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:35:06.455+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:35:06.455+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:35:06.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.554 seconds
[2023-11-14T14:35:36.584+0000] {processor.py:157} INFO - Started process (PID=13637) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:35:36.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:35:36.586+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:35:36.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:35:36.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:35:36.996+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:35:36.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:35:37.028+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:35:37.027+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:35:37.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.476 seconds
[2023-11-14T14:36:07.386+0000] {processor.py:157} INFO - Started process (PID=13666) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:36:07.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:36:07.388+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:36:07.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:36:07.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:36:07.895+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:36:07.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:36:07.926+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:36:07.926+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:36:07.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.573 seconds
[2023-11-14T14:36:38.437+0000] {processor.py:157} INFO - Started process (PID=13687) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:36:38.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:36:38.439+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:36:38.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:36:38.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:36:38.850+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:36:38.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:36:38.876+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:36:38.876+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:36:38.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.468 seconds
[2023-11-14T14:37:09.264+0000] {processor.py:157} INFO - Started process (PID=13716) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:37:09.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:37:09.266+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:37:09.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:37:09.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:37:09.717+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:37:09.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:37:09.745+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:37:09.745+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:37:09.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.509 seconds
[2023-11-14T14:37:40.139+0000] {processor.py:157} INFO - Started process (PID=13737) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:37:40.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:37:40.141+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:37:40.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:37:40.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:37:40.599+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:37:40.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:37:40.626+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:37:40.626+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:37:40.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.524 seconds
[2023-11-14T14:38:11.030+0000] {processor.py:157} INFO - Started process (PID=13766) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:38:11.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:38:11.032+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:38:11.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:38:11.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:38:11.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:38:11.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:38:11.462+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:38:11.462+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:38:12.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.626 seconds
[2023-11-14T14:38:43.049+0000] {processor.py:157} INFO - Started process (PID=13787) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:38:43.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:38:43.051+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:38:43.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:38:43.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:38:43.456+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:38:43.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:38:43.481+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:38:43.481+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:38:43.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.469 seconds
[2023-11-14T14:39:13.879+0000] {processor.py:157} INFO - Started process (PID=13815) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:39:13.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:39:13.881+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:39:13.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:39:14.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:39:14.291+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:39:14.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:39:14.316+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:39:14.316+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:39:14.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.465 seconds
[2023-11-14T14:39:44.690+0000] {processor.py:157} INFO - Started process (PID=13835) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:39:44.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:39:44.692+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:39:44.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:39:45.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:39:45.125+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:39:45.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:39:45.153+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:39:45.153+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:39:45.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.499 seconds
[2023-11-14T14:40:16.026+0000] {processor.py:157} INFO - Started process (PID=13864) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:40:16.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:40:16.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:40:16.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:40:16.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:40:16.472+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:40:16.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:40:16.510+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:40:16.509+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:40:16.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.517 seconds
[2023-11-14T14:40:46.870+0000] {processor.py:157} INFO - Started process (PID=13884) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:40:46.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:40:46.872+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:40:46.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:40:47.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:40:47.290+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:40:47.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:40:47.469+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:40:47.469+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:40:47.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.628 seconds
[2023-11-14T14:41:17.844+0000] {processor.py:157} INFO - Started process (PID=13912) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:41:17.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:41:17.846+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:41:17.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:41:18.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:41:18.322+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:41:18.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:41:18.349+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:41:18.349+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:41:18.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.533 seconds
[2023-11-14T14:41:48.659+0000] {processor.py:157} INFO - Started process (PID=13933) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:41:48.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:41:48.661+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:41:48.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:41:49.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:41:49.071+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:41:49.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:41:49.097+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:41:49.097+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:41:49.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.476 seconds
[2023-11-14T14:42:19.490+0000] {processor.py:157} INFO - Started process (PID=13962) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:42:19.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:42:19.492+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:42:19.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:42:19.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:42:19.906+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:42:19.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:42:19.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:42:19.933+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:42:19.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.478 seconds
[2023-11-14T14:42:50.269+0000] {processor.py:157} INFO - Started process (PID=13984) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:42:50.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:42:50.272+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:42:50.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:42:50.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:42:50.730+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:42:50.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:42:50.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:42:50.755+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:42:50.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.516 seconds
[2023-11-14T14:43:21.184+0000] {processor.py:157} INFO - Started process (PID=14011) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:43:21.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:43:21.188+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:43:21.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:43:21.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:43:21.755+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:43:21.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:43:22.034+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:43:22.034+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:43:22.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.884 seconds
[2023-11-14T14:43:52.411+0000] {processor.py:157} INFO - Started process (PID=14034) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:43:52.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:43:52.413+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:43:52.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:43:52.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:43:52.931+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:43:52.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:43:52.958+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:43:52.958+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:43:52.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.574 seconds
[2023-11-14T14:44:23.332+0000] {processor.py:157} INFO - Started process (PID=14054) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:44:23.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:44:23.334+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:44:23.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:44:23.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:44:23.741+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:44:23.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:44:23.769+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:44:23.769+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:44:23.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.590 seconds
[2023-11-14T14:44:54.281+0000] {processor.py:157} INFO - Started process (PID=14084) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:44:54.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:44:54.283+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:44:54.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:44:54.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:44:54.728+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:44:54.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:44:54.927+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:44:54.926+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:44:54.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.690 seconds
[2023-11-14T14:45:25.298+0000] {processor.py:157} INFO - Started process (PID=14106) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:45:25.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:45:25.302+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:45:25.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:45:25.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:45:25.723+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:45:25.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:45:25.750+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:45:25.749+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:45:25.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.481 seconds
[2023-11-14T14:45:56.109+0000] {processor.py:157} INFO - Started process (PID=14134) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:45:56.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:45:56.111+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:45:56.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:45:56.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:45:56.553+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:45:56.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:45:56.711+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:45:56.711+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:45:56.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.642 seconds
[2023-11-14T14:46:26.950+0000] {processor.py:157} INFO - Started process (PID=14155) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:46:26.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:46:26.952+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:46:26.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:46:27.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:46:27.358+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:46:27.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:46:27.391+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:46:27.390+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:46:27.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.476 seconds
[2023-11-14T14:46:57.802+0000] {processor.py:157} INFO - Started process (PID=14184) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:46:57.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:46:57.804+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:46:57.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:46:58.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:46:58.271+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:46:58.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:46:58.424+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:46:58.424+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:46:58.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.649 seconds
[2023-11-14T14:47:28.880+0000] {processor.py:157} INFO - Started process (PID=14204) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:47:28.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:47:28.882+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:47:28.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:47:29.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:47:29.509+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:47:29.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:47:29.553+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:47:29.553+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:47:29.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.711 seconds
[2023-11-14T14:47:59.858+0000] {processor.py:157} INFO - Started process (PID=14234) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:47:59.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:47:59.863+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:47:59.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:48:00.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:48:00.550+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:48:00.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:48:00.597+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:48:00.596+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:48:00.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.792 seconds
[2023-11-14T14:48:30.733+0000] {processor.py:157} INFO - Started process (PID=14254) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:48:30.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:48:30.740+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:48:30.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:48:31.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:48:31.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:48:31.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:48:31.517+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:48:31.517+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:48:31.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.831 seconds
[2023-11-14T14:49:01.888+0000] {processor.py:157} INFO - Started process (PID=14274) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:49:01.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:49:01.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:49:01.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:49:02.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:49:02.369+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:49:02.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:49:02.416+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:49:02.416+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:49:02.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.576 seconds
[2023-11-14T14:49:32.878+0000] {processor.py:157} INFO - Started process (PID=14303) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:49:32.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:49:32.881+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:49:32.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:49:33.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:49:33.416+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:49:33.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:49:33.594+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:49:33.593+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:49:33.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.754 seconds
[2023-11-14T14:50:03.981+0000] {processor.py:157} INFO - Started process (PID=14324) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:50:03.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:50:03.984+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:50:03.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:50:04.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:50:04.566+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:50:04.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:50:04.591+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:50:04.591+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:50:04.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.650 seconds
[2023-11-14T14:50:34.962+0000] {processor.py:157} INFO - Started process (PID=14351) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:50:34.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:50:34.964+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:50:34.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:50:35.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:50:35.578+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:50:35.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:50:35.607+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:50:35.607+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:50:35.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.678 seconds
[2023-11-14T14:51:03.832+0000] {processor.py:157} INFO - Started process (PID=14370) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:03.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:03.844+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:03.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:04.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:04.570+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:04.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:04.604+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:04.603+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:04.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.816 seconds
[2023-11-14T14:51:06.256+0000] {processor.py:157} INFO - Started process (PID=14374) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:06.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:06.261+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:06.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:07.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:07.959+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:07.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:08.024+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:08.024+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:08.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.831 seconds
[2023-11-14T14:51:10.932+0000] {processor.py:157} INFO - Started process (PID=14376) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:10.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:10.939+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:10.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:12.032+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:12.016+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [download]
NameError: name 'download' is not defined
[2023-11-14T14:51:12.035+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:12.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.162 seconds
[2023-11-14T14:51:17.055+0000] {processor.py:157} INFO - Started process (PID=14387) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:17.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:17.058+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:17.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:18.605+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:18.571+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wr]
NameError: name 'wr' is not defined
[2023-11-14T14:51:18.619+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:18.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.618 seconds
[2023-11-14T14:51:25.476+0000] {processor.py:157} INFO - Started process (PID=14389) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:25.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:25.479+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:25.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:26.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:26.093+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:26.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:26.117+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:26.117+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:26.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.681 seconds
[2023-11-14T14:51:28.282+0000] {processor.py:157} INFO - Started process (PID=14391) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:28.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:28.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:28.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:29.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:29.202+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:29.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:29.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:29.228+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:29.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.983 seconds
[2023-11-14T14:51:34.335+0000] {processor.py:157} INFO - Started process (PID=14401) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:34.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:34.337+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:34.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:35.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:35.043+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:35.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:35.072+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:35.072+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:35.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.773 seconds
[2023-11-14T14:51:37.396+0000] {processor.py:157} INFO - Started process (PID=14405) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:37.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:37.399+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:37.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:38.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:38.703+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:38.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:38.787+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:38.787+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:38.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.474 seconds
[2023-11-14T14:51:40.034+0000] {processor.py:157} INFO - Started process (PID=14407) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:40.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:40.040+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:40.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:40.074+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:40.072+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task]]
                                                                                            ^
SyntaxError: unmatched ']'
[2023-11-14T14:51:40.075+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:40.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.086 seconds
[2023-11-14T14:51:41.037+0000] {processor.py:157} INFO - Started process (PID=14408) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:41.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:41.039+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:41.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:41.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:41.653+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:41.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T14:51:41.690+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:41.690+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T14:51:41.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.710 seconds
[2023-11-14T14:51:48.238+0000] {processor.py:157} INFO - Started process (PID=14418) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:48.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:51:48.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:48.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:48.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:51:48.267+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >>
                                                                                               ^
SyntaxError: invalid syntax
[2023-11-14T14:51:48.269+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:51:48.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.066 seconds
[2023-11-14T14:52:18.454+0000] {processor.py:157} INFO - Started process (PID=14437) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:18.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:52:18.464+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:18.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:18.562+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:18.560+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >>
                                                                                               ^
SyntaxError: invalid syntax
[2023-11-14T14:52:18.564+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:18.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.232 seconds
[2023-11-14T14:52:25.800+0000] {processor.py:157} INFO - Started process (PID=14446) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:25.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:52:25.809+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:25.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:27.348+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:27.343+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> join
NameError: name 'join' is not defined
[2023-11-14T14:52:27.350+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:27.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.588 seconds
[2023-11-14T14:52:42.131+0000] {processor.py:157} INFO - Started process (PID=14459) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:42.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:52:42.133+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:42.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:42.674+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:42.667+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> join_wrangled_data_task
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:52:42.677+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:42.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.567 seconds
[2023-11-14T14:52:44.256+0000] {processor.py:157} INFO - Started process (PID=14461) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:44.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:52:44.259+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:44.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:44.863+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:44.853+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> join_wrangled_data_task
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:52:44.867+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:44.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.635 seconds
[2023-11-14T14:52:54.907+0000] {processor.py:157} INFO - Started process (PID=14472) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:54.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:52:54.910+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:54.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:55.462+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:52:55.456+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> join_wrangled_data_task
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:52:55.463+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:52:55.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.580 seconds
[2023-11-14T14:53:01.103+0000] {processor.py:157} INFO - Started process (PID=14483) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:01.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:53:01.106+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:01.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:01.136+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:01.135+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442
    join_wrangled_data_task >> create_cases_deaths_table
    ^
SyntaxError: invalid syntax
[2023-11-14T14:53:01.137+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:01.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.065 seconds
[2023-11-14T14:53:13.357+0000] {processor.py:157} INFO - Started process (PID=14495) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:13.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:53:13.359+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:13.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:13.394+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:13.393+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445
    
    ^
SyntaxError: unexpected EOF while parsing
[2023-11-14T14:53:13.396+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:13.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.072 seconds
[2023-11-14T14:53:35.634+0000] {processor.py:157} INFO - Started process (PID=14504) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:35.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:53:35.638+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:35.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:35.677+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:35.674+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442
    join_wrangled_data_task >> create_cases_deaths_table
    ^
SyntaxError: invalid syntax
[2023-11-14T14:53:35.680+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:35.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.114 seconds
[2023-11-14T14:53:54.527+0000] {processor.py:157} INFO - Started process (PID=14523) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:54.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:53:54.529+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:54.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:54.554+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:54.553+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442
    join_wrangled_data_task >> create_cases_deaths_table
    ^
SyntaxError: invalid syntax
[2023-11-14T14:53:54.555+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:54.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.059 seconds
[2023-11-14T14:53:57.584+0000] {processor.py:157} INFO - Started process (PID=14524) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:57.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:53:57.586+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:57.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:58.184+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:53:58.179+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:53:58.185+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:53:58.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.623 seconds
[2023-11-14T14:54:00.742+0000] {processor.py:157} INFO - Started process (PID=14526) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:00.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:54:00.749+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:00.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:01.640+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:01.632+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, cre]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:54:01.642+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:01.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.929 seconds
[2023-11-14T14:54:03.349+0000] {processor.py:157} INFO - Started process (PID=14536) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:03.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:54:03.354+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:03.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:04.168+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:04.162+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:54:04.170+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:04.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.851 seconds
[2023-11-14T14:54:05.797+0000] {processor.py:157} INFO - Started process (PID=14538) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:05.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:54:05.802+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:05.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:06.643+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:06.635+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_country_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:54:06.646+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:06.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.881 seconds
[2023-11-14T14:54:12.341+0000] {processor.py:157} INFO - Started process (PID=14540) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:12.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:54:12.344+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:12.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:12.966+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:12.961+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:54:12.968+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:12.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.653 seconds
[2023-11-14T14:54:43.341+0000] {processor.py:157} INFO - Started process (PID=14569) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:43.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:54:43.343+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:43.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:44.032+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:54:44.027+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:54:44.034+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:54:44.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.715 seconds
[2023-11-14T14:55:14.384+0000] {processor.py:157} INFO - Started process (PID=14591) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:55:14.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:55:14.387+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:55:14.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:55:15.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:55:15.053+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:55:15.061+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:55:15.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.701 seconds
[2023-11-14T14:55:45.387+0000] {processor.py:157} INFO - Started process (PID=14612) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:55:45.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:55:45.390+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:55:45.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:55:46.091+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:55:46.085+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:55:46.093+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:55:46.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.741 seconds
[2023-11-14T14:56:16.427+0000] {processor.py:157} INFO - Started process (PID=14640) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:56:16.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:56:16.429+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:56:16.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:56:17.852+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:56:17.843+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:56:17.855+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:56:17.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.477 seconds
[2023-11-14T14:56:48.238+0000] {processor.py:157} INFO - Started process (PID=14661) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:56:48.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:56:48.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:56:48.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:56:48.916+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:56:48.910+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:56:48.918+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:56:48.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.706 seconds
[2023-11-14T14:57:19.140+0000] {processor.py:157} INFO - Started process (PID=14681) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:57:19.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:57:19.145+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:57:19.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:57:19.928+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:57:19.919+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:57:19.930+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:57:19.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.822 seconds
[2023-11-14T14:57:50.078+0000] {processor.py:157} INFO - Started process (PID=14709) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:57:50.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:57:50.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:57:50.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:57:51.090+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:57:51.082+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:57:51.092+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:57:51.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.054 seconds
[2023-11-14T14:58:21.365+0000] {processor.py:157} INFO - Started process (PID=14731) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:58:21.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:58:21.369+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:58:21.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:58:22.011+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:58:22.004+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:58:22.014+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:58:22.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.674 seconds
[2023-11-14T14:58:52.420+0000] {processor.py:157} INFO - Started process (PID=14751) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:58:52.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:58:52.422+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:58:52.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:58:53.009+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:58:53.003+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:58:53.011+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:58:53.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.614 seconds
[2023-11-14T14:59:23.356+0000] {processor.py:157} INFO - Started process (PID=14779) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:59:23.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:59:23.359+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:59:23.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:59:24.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:59:24.924+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:59:24.971+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:59:25.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.679 seconds
[2023-11-14T14:59:55.675+0000] {processor.py:157} INFO - Started process (PID=14799) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:59:55.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T14:59:55.678+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:59:55.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:59:56.439+0000] {logging_mixin.py:151} INFO - [2023-11-14T14:59:56.432+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T14:59:56.442+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T14:59:56.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.804 seconds
[2023-11-14T15:00:27.164+0000] {processor.py:157} INFO - Started process (PID=14820) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:00:27.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:00:27.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:00:27.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:00:31.185+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:00:31.142+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:00:31.206+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:00:31.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.236 seconds
[2023-11-14T15:01:02.245+0000] {processor.py:157} INFO - Started process (PID=14841) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:01:02.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:01:02.249+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:01:02.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:01:02.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:01:02.924+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:01:02.935+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:01:02.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.717 seconds
[2023-11-14T15:01:33.762+0000] {processor.py:157} INFO - Started process (PID=14862) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:01:33.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:01:33.764+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:01:33.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:01:34.590+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:01:34.582+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:01:34.592+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:01:34.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.865 seconds
[2023-11-14T15:02:05.166+0000] {processor.py:157} INFO - Started process (PID=14881) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:02:05.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:02:05.170+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:02:05.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:02:06.399+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:02:06.387+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:02:06.404+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:02:06.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.282 seconds
[2023-11-14T15:02:36.934+0000] {processor.py:157} INFO - Started process (PID=14902) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:02:36.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:02:36.936+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:02:36.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:02:37.651+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:02:37.637+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:02:37.654+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:02:37.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.756 seconds
[2023-11-14T15:03:08.020+0000] {processor.py:157} INFO - Started process (PID=14922) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:03:08.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:03:08.024+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:03:08.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:03:09.464+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:03:09.455+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:03:09.467+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:03:09.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.520 seconds
[2023-11-14T15:03:39.963+0000] {processor.py:157} INFO - Started process (PID=14951) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:03:39.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:03:39.967+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:03:39.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:03:41.015+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:03:41.009+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:03:41.017+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:03:41.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.086 seconds
[2023-11-14T15:04:11.360+0000] {processor.py:157} INFO - Started process (PID=14972) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:04:11.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:04:11.364+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:04:11.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:04:12.062+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:04:12.055+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:04:12.065+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:04:12.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.742 seconds
[2023-11-14T15:04:42.466+0000] {processor.py:157} INFO - Started process (PID=14992) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:04:42.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:04:42.469+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:04:42.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:04:43.451+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:04:43.438+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:04:43.454+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:04:43.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.024 seconds
[2023-11-14T15:05:13.819+0000] {processor.py:157} INFO - Started process (PID=15011) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:05:13.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:05:13.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:05:13.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:05:14.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:05:14.937+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:05:14.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:05:14.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.159 seconds
[2023-11-14T15:05:45.577+0000] {processor.py:157} INFO - Started process (PID=15038) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:05:45.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:05:45.590+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:05:45.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:05:46.878+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:05:46.863+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:05:46.881+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:05:46.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.381 seconds
[2023-11-14T15:06:17.340+0000] {processor.py:157} INFO - Started process (PID=15058) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:06:17.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:06:17.345+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:06:17.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:06:18.525+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:06:18.514+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:06:18.528+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:06:18.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.230 seconds
[2023-11-14T15:06:49.260+0000] {processor.py:157} INFO - Started process (PID=15077) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:06:49.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:06:49.267+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:06:49.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:06:49.907+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:06:49.900+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:06:49.909+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:06:49.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.677 seconds
[2023-11-14T15:07:20.667+0000] {processor.py:157} INFO - Started process (PID=15097) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:07:20.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:07:20.669+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:07:20.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:07:21.425+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:07:21.418+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:07:21.430+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:07:21.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.807 seconds
[2023-11-14T15:07:52.023+0000] {processor.py:157} INFO - Started process (PID=15118) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:07:52.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:07:52.026+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:07:52.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:07:53.180+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:07:53.161+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:07:53.182+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:07:53.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.239 seconds
[2023-11-14T15:08:23.557+0000] {processor.py:157} INFO - Started process (PID=15146) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:08:23.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:08:23.565+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:08:23.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:08:24.939+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:08:24.927+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:08:24.941+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:08:24.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.456 seconds
[2023-11-14T15:08:55.339+0000] {processor.py:157} INFO - Started process (PID=15166) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:08:55.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:08:55.342+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:08:55.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:08:56.030+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:08:56.022+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:08:56.036+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:08:56.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.737 seconds
[2023-11-14T15:09:27.001+0000] {processor.py:157} INFO - Started process (PID=15187) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:09:27.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:09:27.003+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:09:27.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:09:27.925+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:09:27.919+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:09:27.929+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:09:27.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.958 seconds
[2023-11-14T15:09:58.318+0000] {processor.py:157} INFO - Started process (PID=15208) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:09:58.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:09:58.322+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:09:58.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:09:59.018+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:09:59.013+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:09:59.020+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:09:59.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.733 seconds
[2023-11-14T15:10:29.322+0000] {processor.py:157} INFO - Started process (PID=15237) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:10:29.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:10:29.324+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:10:29.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:10:30.342+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:10:30.332+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:10:30.347+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:10:30.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.087 seconds
[2023-11-14T15:11:00.534+0000] {processor.py:157} INFO - Started process (PID=15259) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:11:00.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:11:00.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:11:00.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:11:01.148+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:11:01.140+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:11:01.150+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:11:01.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.647 seconds
[2023-11-14T15:11:31.819+0000] {processor.py:157} INFO - Started process (PID=15279) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:11:31.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:11:31.822+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:11:31.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:11:32.604+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:11:32.597+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:11:32.606+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:11:32.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.817 seconds
[2023-11-14T15:12:03.126+0000] {processor.py:157} INFO - Started process (PID=15309) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:12:03.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:12:03.128+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:12:03.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:12:03.968+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:12:03.960+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:12:03.970+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:12:04.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.893 seconds
[2023-11-14T15:12:34.350+0000] {processor.py:157} INFO - Started process (PID=15330) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:12:34.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:12:34.355+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:12:34.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:12:35.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:12:35.069+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:12:35.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:12:35.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.764 seconds
[2023-11-14T15:13:05.507+0000] {processor.py:157} INFO - Started process (PID=15350) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:13:05.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:13:05.510+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:13:05.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:13:06.162+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:13:06.156+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:13:06.164+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:13:06.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.688 seconds
[2023-11-14T15:13:37.041+0000] {processor.py:157} INFO - Started process (PID=15370) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:13:37.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:13:37.050+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:13:37.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:13:38.990+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:13:38.982+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:13:38.996+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:13:39.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.017 seconds
[2023-11-14T15:14:09.600+0000] {processor.py:157} INFO - Started process (PID=15392) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:09.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:14:09.602+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:14:09.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:10.819+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:14:10.810+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:14:10.823+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:10.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.258 seconds
[2023-11-14T15:14:42.508+0000] {processor.py:157} INFO - Started process (PID=15421) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:42.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:14:42.549+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:14:42.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:46.134+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:14:46.095+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:14:46.137+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:46.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.789 seconds
[2023-11-14T15:14:55.961+0000] {processor.py:157} INFO - Started process (PID=15425) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:55.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:14:55.968+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:14:55.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:58.345+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:14:58.315+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:14:58.348+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:14:58.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.453 seconds
[2023-11-14T15:15:01.721+0000] {processor.py:157} INFO - Started process (PID=15436) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:01.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:01.726+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:01.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:04.331+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:04.255+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    country
NameError: name 'country' is not defined
[2023-11-14T15:15:04.360+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:04.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.743 seconds
[2023-11-14T15:15:05.684+0000] {processor.py:157} INFO - Started process (PID=15438) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:05.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:05.688+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:05.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:07.352+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:07.344+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    country_region
NameError: name 'country_region' is not defined
[2023-11-14T15:15:07.364+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:07.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.742 seconds
[2023-11-14T15:15:09.547+0000] {processor.py:157} INFO - Started process (PID=15440) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:09.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:09.556+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:09.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:10.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:10.374+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    country_regions
NameError: name 'country_regions' is not defined
[2023-11-14T15:15:10.384+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:10.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.873 seconds
[2023-11-14T15:15:17.278+0000] {processor.py:157} INFO - Started process (PID=15442) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:17.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:17.286+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:17.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:18.907+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:18.894+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    location
NameError: name 'location' is not defined
[2023-11-14T15:15:18.912+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:18.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.705 seconds
[2023-11-14T15:15:20.169+0000] {processor.py:157} INFO - Started process (PID=15452) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:20.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:20.172+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:20.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:20.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:20.211+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 446
    location_table = """CREATE TABLE IF NOT EXISTS location (
population_data='https://api.worldbank.org/v2/en/indicator/SP.POP.TOTL?downloadformat=csv'
cases_deaths='https://covid19.who.int/WHO-COVID-19-global-data.csv'
vaccinations='https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv'
government_measures='https://raw.githubusercontent.com/OxCGRT/covid-policy-dataset/main/data/OxCGRT_compact_national_v1.csv'


default_args = {
    'start_date': airflow.utils.dates.days_ago(0),
    'concurrency': 1,
    'schedule_interval': None,
    'retries': 1,
    'retry_delay': datetime.timedelta(seconds=10),
    'catchup': False,
    "depends_on_past": False,
}

dag = DAG('covid_data_dag_postgres', start_date=airflow.utils.dates.days_ago(0), default_args=default_args, schedule_interval='@daily')

def download_cases_deaths():
    response = requests.get(cases_deaths)
    with open('/opt/airflow/dags/postgres/cases_deaths.csv', 'wb') as f:
        f.write(response.content)

def download_vaccinations():
    response = requests.get(vaccinations)
    with open('/opt/airflow/dags/postgres/vaccinations.csv', 'wb') as f:
        f.write(response.content)

def download_government_measures():
    response = requests.get(government_measures)
    with open('/opt/airflow/dags/postgres/government_measures.csv', 'wb') as f:
        f.write(response.content)
        
# Population data from the World Bank API, used to calculate the per capita metrics 
# for every table (e.g. total_vaccinations_per_hundred, people_vaccinated_per_hundred, etc.)         
def download_population_data():
    data = wb.data.DataFrame('SP.POP.TOTL', labels=True, time=range(2019, 2023))
    
    #Manually add the population for 2023 and set it equal to the population of 2022
    data["YR2023"] = data["YR2022"]
    
    data_reshaped = pd.melt(data, id_vars=['Country'], var_name='Year', value_name='population')
    data_reshaped['Year'] = data_reshaped['Year'].apply(lambda year: int(year[2:]))
    
    data_reshaped.to_csv('/opt/airflow/dags/postgres/population_data.csv', index=False)

def format_date(df: pd.DataFrame) -> pd.DataFrame:
    print("Formatting date")
    df["Date_reported"] = pd.to_datetime(df["Date_reported"], format="%Y-%m-%d")
    return df

def discard_rows(df):
    print("Discarding rows")
    # For all rows where new_cases or new_deaths is negative, we keep the cumulative value but set
    # the daily change to NA. This also sets the 7-day rolling average to NA for the next 7 days.
    df.loc[df.New_cases < 0, "New_cases"] = np.nan
    df.loc[df.New_deaths < 0, "New_deaths"] = np.nan
    return df

def _inject_growth(df, prefix, periods):
    cases_colname = "%s_cases" % prefix
    deaths_colname = "%s_deaths" % prefix
    cases_growth_colname = "%s_pct_growth_cases" % prefix
    deaths_growth_colname = "%s_pct_growth_deaths" % prefix

    df[[cases_colname, deaths_colname]] = (
        df[["Country", "New_cases", "New_deaths"]]
        .groupby("Country")[["New_cases", "New_deaths"]]
        .rolling(window=periods, min_periods=periods - 1, center=False)
        .sum()
        .reset_index(level=0, drop=True)
    )
    df[[cases_growth_colname, deaths_growth_colname]] = (
        df[["Country", cases_colname, deaths_colname]]
        .groupby("Country")[[cases_colname, deaths_colname]]
        .pct_change(periods=periods, fill_method=None)
        .round(3)
        .replace([np.inf, -np.inf], pd.NA)
        * 100
    )
    
    return df
    
def _inject_population(df):
    'dags\postgres\population_data.csv'
    df_population = pd.read_csv('/opt/airflow/dags/postgres/population_data.csv')
    # Extract year from Date_reported column and create a new column Year
    df['Year'] = pd.DatetimeIndex(df['Date_reported']).year
    # 
    # Merge the two dataframes based on Country and Year columns
    df_merged = pd.merge(df, df_population, how='left', on=['Country', 'Year'])
    df_merged.drop('Year', axis=1, inplace=True)
    
    return df_merged

def _per_capita(df, measures):
    for measure in measures:
        pop_measure = measure + "_per_million"
        series = df[measure] / (df["population"] / 1e6)
        df[pop_measure] = series.round(decimals=3)
    #df = drop_population(df)
    return df

def wrangle_cases_deaths():
    df = pd.read_csv('/opt/airflow/dags/postgres/cases_deaths.csv')
    
    df = format_date(df)
    df = discard_rows(df)
    df = _inject_growth(df, 'Weekly', 7)   
    df = _inject_population(df)
    df = _per_capita(df, ["New_cases", "New_deaths", "Cumulative_cases", 
                          "Cumulative_deaths", "Weekly_cases", "Weekly_deaths",])
    
    
    df.to_csv('/opt/airflow/dags/postgres/cases_deaths_wrangled.csv', index=False)

def wrangle_vaccinations():
    df = pd.read_csv('/opt/airflow/dags/postgres/vaccinations.csv')
    # Apply data wrangling here
    # ...
    df.to_csv('/opt/airflow/dags/postgres/vaccinations_wrangled.csv', index=False)

def wrangle_government_measures():
    df = pd.read_csv('/opt/airflow/dags/postgres/government_measures.csv')
    # Apply data wrangling here
    
    # Mantain only the columns of interest
    #df = df[['CountryName', 'CountryCode', 'RegionName', 'RegionCode', 'Jurisdiction', 'Date', 'StringencyIndex_Average', 'GovernmentResponseIndex_Average', 'ContainmentHealthIndex_Average', 'EconomicSupportIndex']]
    
    
    df.to_csv('/opt/airflow/dags/postgres/government_measures_wrangled.csv', index=False)

def wrangle_population_data():
    df = pd.read_csv('/opt/airflow/dags/postgres/population_data.csv')
    # Apply data wrangling here
    # ...
    df.to_csv('/opt/airflow/dags/postgres/population_data_wrangled.csv', index=False)

# I KEPT (COMMENTED) THE FOLLOWING FUNCTIONS (bla_bla_query()) AS A REFERENCE, BUT 
# THEY SHOULD BE MODIFIED BASED ON THE SHAPE OF THE DATA AFTER THE WRANGLING
'''
def _create_cases_deaths_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/cases_deaths.csv')
    with open("/opt/airflow/dags/postgres/cases_deaths_inserts.sql", "w") as f:
        df_iterable = df.iterrows()

        f.write(
            "DROP TABLE IF EXISTS cases_deaths;\n"
            "CREATE TABLE cases_deaths (\n"
            "id SERIAL PRIMARY KEY,\n"
            "date_reported DATE,\n"
            "country_code VARCHAR(10),\n"
            "country VARCHAR(100),\n"
            "who_region VARCHAR(100),\n"
            "new_cases INTEGER,\n"
            "cumulative_cases INTEGER,\n"
            "new_deaths INTEGER,\n"
            "cumulative_deaths INTEGER\n"
            ");\n"
        )
        
        
        for index, row in df_iterable:
            id = index
            date_reported = row['Date_reported']
            country_code = row['Country_code']
            # If the country name contains a single quote, replace it with two single quotes 
            # (the apostrophe is a reserved character in SQL)
            country = row['Country'].replace("'", "''")
            who_region = row['WHO_region']
            new_cases = row['New_cases']
            cumulative_cases = row['Cumulative_cases']
            new_deaths = row['New_deaths']
            cumulative_deaths = row['Cumulative_deaths']

            f.write(
                "INSERT INTO cases_deaths VALUES ("
                f"'{id}', '{date_reported}', '{country_code}', '{country}', '{who_region}', {new_cases}, {cumulative_cases}, {new_deaths}, {cumulative_deaths}"
                ");\n"
            )
            
            # Just for debugging purposes, I limit the number of records to 100
            if index == 100:
                break

        f.close()
        
def _create_government_measures_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/government_measures.csv')
    # Mantain only the columns of interest
    df = df[['CountryName', 'CountryCode', 'RegionName', 'RegionCode', 'Jurisdiction', 'Date', 'StringencyIndex_Average', 'GovernmentResponseIndex_Average', 'ContainmentHealthIndex_Average', 'EconomicSupportIndex']]
    
    with open("/opt/airflow/dags/postgres/government_measures_inserts.sql", "w") as f:
        df_iterable = df.iterrows()

        f.write(
            "DROP TABLE IF EXISTS government_measures;\n"
            "CREATE TABLE government_measures (\n"
            "id SERIAL PRIMARY KEY,\n"
            "country_name VARCHAR(100),\n"
            "country_code VARCHAR(10),\n"
            "region_name VARCHAR(100),\n"
            "region_code VARCHAR(10),\n"
            "jurisdiction VARCHAR(100),\n"
            "date DATE,\n"
            "stringency_index_average FLOAT,\n"
            "government_response_index_average FLOAT,\n"
            "containment_health_index_average FLOAT,\n"
            "economic_support_index FLOAT\n"
            ");\n"
        )
        
        for index, row in df_iterable:
            id = index
            country_name = row['CountryName'].replace("'", "''")
            country_code = row['CountryCode']
            region_name = row['RegionName'] if pd.notnull(row['RegionName']) else "null"
            region_code = row['RegionCode'] if pd.notnull(row['RegionCode']) else "null"
            jurisdiction = row['Jurisdiction'].replace("'", "''") if pd.notnull(row['Jurisdiction']) else "null"
            date = row['Date']
            stringency_index_average = row['StringencyIndex_Average'] if pd.notnull(row['StringencyIndex_Average']) else "null"
            government_response_index_average = row['GovernmentResponseIndex_Average'] if pd.notnull(row['GovernmentResponseIndex_Average']) else "null"
            containment_health_index_average = row['ContainmentHealthIndex_Average'] if pd.notnull(row['ContainmentHealthIndex_Average']) else "null"
            economic_support_index = row['EconomicSupportIndex'] if pd.notnull(row['EconomicSupportIndex']) else "null"

            f.write(
                "INSERT INTO government_measures VALUES ("
                f"'{id}', '{country_name}', '{country_code}', '{region_name}', '{region_code}', '{jurisdiction}', '{date}', {stringency_index_average}, {government_response_index_average}, {containment_health_index_average}, {economic_support_index}"
                ");\n"
            )
            
            # Just for debugging purposes, I limit the number of records to 100
            if index == 100:
                break

        f.close()
        
def _create_vaccinations_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/vaccinations.csv')
    df.fillna("null", inplace=True)
    with open("/opt/airflow/dags/postgres/vaccinations_inserts.sql", "w") as f:
        df_iterable = df.iterrows()
        
        f.write(
            "DROP TABLE IF EXISTS vaccinations;\n"
            "CREATE TABLE vaccinations (\n"
            "id SERIAL PRIMARY KEY,\n"
            "date_ DATE,\n"
            "location_ VARCHAR(100),\n"
            "iso_code VARCHAR(10),\n"
            "total_vaccinations INTEGER,\n"
            "people_vaccinated INTEGER,\n"
            "people_fully_vaccinated INTEGER,\n"
            "daily_vaccinations_raw INTEGER,\n"
            "daily_vaccinations INTEGER,\n"
            "total_vaccinations_per_hundred FLOAT,\n"
            "people_vaccinated_per_hundred FLOAT,\n"
            "people_fully_vaccinated_per_hundred FLOAT,\n"
            "daily_vaccinations_per_million INTEGER,\n"
            "daily_people_vaccinated INTEGER,\n"
            "daily_people_vaccinated_per_hundred FLOAT\n"
            ");\n"
        )
        
        for index, row in df_iterable:
            id = index
            date = row['date']
            location = row['location']
            iso_code = row['iso_code']
            total_vaccinations = row['total_vaccinations']
            people_vaccinated = row['people_vaccinated']
            people_fully_vaccinated = row['people_fully_vaccinated']
            daily_vaccinations_raw = row['daily_vaccinations_raw']
            daily_vaccinations = row['daily_vaccinations']
            total_vaccinations_per_hundred = row['total_vaccinations_per_hundred']
            people_vaccinated_per_hundred = row['people_vaccinated_per_hundred']
            people_fully_vaccinated_per_hundred = row['people_fully_vaccinated_per_hundred']
            daily_vaccinations_per_million = row['daily_vaccinations_per_million']
            daily_people_vaccinated = row['daily_people_vaccinated']
            daily_people_vaccinated_per_hundred = row['daily_people_vaccinated_per_hundred']

            f.write(
                "INSERT INTO vaccinations VALUES ("
                f"'{id}', '{date}', '{location}', '{iso_code}', {total_vaccinations}, {people_vaccinated}, {people_fully_vaccinated}, {daily_vaccinations_raw}, {daily_vaccinations}, {total_vaccinations_per_hundred}, {people_vaccinated_per_hundred}, {people_fully_vaccinated_per_hundred}, {daily_vaccinations_per_million}, {daily_people_vaccinated}, {daily_people_vaccinated_per_hundred}"
                ");\n"
            )
            
            if index == 100:
                break

        f.close()
'''    

# Download the cases_deaths.csv file from the WHO website
download_cases_deaths = PythonOperator(
    task_id='download_cases_deaths',
    dag=dag,
    python_callable=download_cases_deaths,
    op_kwargs={},
    trigger_rule='all_success',
    depends_on_past=False,
)

# Downlaod the vaccinations.csv file from the OWID GitHub repository
download_vaccinations = PythonOperator(
    task_id='download_vaccinations',
    dag=dag,
    python_callable=download_vaccinations,
    op_kwargs={},
    trigger_rule='all_success',
    depends_on_past=False,
)

# Download the government_measures.csv file from the OxCGRT GitHub repository
download_government_measures = PythonOperator(
    task_id='download_government_measures',
    python_callable=download_government_measures,
    dag=dag
)

# Download the population_data.csv file from the World Bank API
download_population_data_task = PythonOperator(
    task_id='download_population_data',
    python_callable=download_population_data,
    dag=dag,
)

wrangle_cases_deaths_task = PythonOperator(
    task_id='wrangle_cases_deaths',
    python_callable=wrangle_cases_deaths,
    dag=dag,
)

wrangle_vaccinations_task = PythonOperator(
    task_id='wrangle_vaccinations',
    python_callable=wrangle_vaccinations,
    dag=dag,
)

wrangle_government_measures_task = PythonOperator(
    task_id='wrangle_government_measures',
    python_callable=wrangle_government_measures,
    dag=dag,
)

# Define the task to wrangle the population data
wrangle_population_data_task = PythonOperator(
    task_id='wrangle_population_data',
    python_callable=wrangle_population_data,
    dag=dag,
)

# I KEPT THE FOLLOWING OPERATORS AS A REFERENCE, BUT THEY SHOULD BE 
# MODIFIED BASED ON THE SHAPE OF THE DATA AFTER THE WRANGLING
'''
# Create the cases_deaths_inserts.sql file with the SQL query to insert the data into the database
create_cases_deaths_query_operator = PythonOperator(
    task_id='create_cases_deaths_query_operator',
    dag=dag,
    python_callable=_create_cases_deaths_query,
    op_kwargs={
        'previous_epoch': '{{ prev_execution_date.int_timestamp }}',
        'output_folder': '/opt/airflow/dags',
    },
    trigger_rule='all_success',
    depends_on_past=False,
)

# Create the vaccinations_inserts.sql file with the SQL query to insert the data into the database
create_vaccinations_query_operator = PythonOperator(
    task_id='create_vaccinations_query_operator',
    dag=dag,
    python_callable=_create_vaccinations_query,
    op_kwargs={
        'previous_epoch': '{{ prev_execution_date.int_timestamp }}',
        'output_folder': '/opt/airflow/dags',
    },
    trigger_rule='all_success',
    depends_on_past=False,
)

# Create the government_measures_inserts.sql file with the SQL query to insert the data into the database
create_government_measures_query_operator = PythonOperator(
    task_id='create_government_measures_query_operator',
    dag=dag,
    python_callable=_create_government_measures_query,
    op_kwargs={
        'previous_epoch': '{{ prev_execution_date.int_timestamp }}',
        'output_folder': '/opt/airflow/dags',
    },
    trigger_rule='all_success',
    depends_on_past=False,
)

# Create the cases_deaths table in the database and insert the data
create_cases_deaths_table = PostgresOperator(
    task_id='create_cases_deaths_table',
    dag=dag,
    postgres_conn_id='postgres_default',
    sql='/postgres/cases_deaths_inserts.sql',
)

# Create the vaccinations table in the database and insert the data
create_vaccinations_table = PostgresOperator(
    task_id='create_vaccinations_table',
    postgres_conn_id='postgres_default',
    sql='/postgres/vaccinations_inserts.sql',
    dag=dag
)

# Create the government_measures table in the database and insert the data
create_government_measures_table = PostgresOperator(
    task_id='create_government_measures_table',
    postgres_conn_id='postgres_default',
    sql='/postgres/government_measures_inserts.sql',
    dag=dag
)
'''

[download_cases_deaths, download_population_data_task] >> wrangle_cases_deaths_task #>> create_cases_deaths_query_operator >> create_cases_deaths_table >> print_vaccinations_operator
[download_vaccinations, download_population_data_task] >> wrangle_vaccinations_task #>> create_vaccinations_query_operator >> create_vaccinations_table
download_government_measures >> wrangle_government_measures_task #>> create_government_measures_query_operator >> create_government_measures_table
download_population_data_task >> wrangle_population_data_task
[wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
join_wrangled_data_task >> create_cases_deaths_table
                                                             
                                                                                          
                                                                   
                                                                                                                    
                                                                                                                            


                
                                                  
                     
                              
                 
                                                  
                     
                             
 

                                                                                                                                       

                            
                                         
                                                                        
                                 

                            
                                         
                                                                        
                                 

                                   
                                                
                                                                               
                                 
        
                                                                                    
                                                                                                     
                               
                                                                                
    
                                                                                    
                                   
    
                                                                                                
                                                                                   
    
                                                                                       

                                                  
                             
                                                                                
             

                     
                             
                                                                                                  
                                                                                                 
                                                  
                                                    
             

                                        
                                       
                                         
                                                         
                                                           

                                           
                                                  
                                                        
                                                                       
              
                                        
     
                                                         
                                                      
                                                            
                                                      
                 
                                          
             
     
    
             
    
                           
                                       
                                                                                 
                                                                         
                                                           
      
                                                                
                                                                               
                                                
    
                    

                              
                            
                                              
                                                       
                                                  
                             
             

                           
                                                                   
    
                        
                         
                                           
                               
                                                                         
                                                                                 
    
    
                                                                                  

                           
                                                                   
                               
         
                                                                                  

                                  
                                                                          
                               
    
                                          
                                                                                                                                                                                                                        
    
    
                                                                                         

                              
                                                                      
                               
         
                                                                                     

                                                                                   
                                                                            
   
                                                                        
                                                                   
                                                                               
                                   

                
                                                  
                                           
                                      
                                   
                                         
                                     
                                        
                                  
                                         
                                   
                                         
                  
         
        
        
                                      
                      
                                                
                                              
                                                                                             
                                                             
                                                       
                                          
                                        
                                                      
                                          
                                                        

                    
                                                   
                                                                                                                                                               
                      
             
            
                                                                               
                            
                     

                 
        
                                                                               
                                                                          
                                          
                                                                                                                                                                                                                       
    
                                                                                      
                                   

                
                                                         
                                                  
                                      
                                          
                                         
                                         
                                        
                                          
                          
                                               
                                                        
                                                       
                                            
                  
         
        
                                      
                      
                                                                
                                             
                                                                                        
                                                                                        
                                                                                                                
                              
                                                                                                                               
                                                                                                                                                        
                                                                                                                                                     
                                                                                                                       

                    
                                                          
                                                                                                                                                                                                                                                          
                      
             
            
                                                                               
                            
                     

                 
        
                                                                        
                                                                   
                                   
                                                                               
                                   
        
                
                                                  
                                           
                                      
                           
                                       
                                     
                                           
                                          
                                                
                                               
                                           
                                                     
                                                    
                                                          
                                                       
                                                
                                                         
                  
         
        
                                      
                      
                              
                                      
                                      
                                                          
                                                        
                                                                    
                                                                  
                                                          
                                                                                  
                                                                                
                                                                                            
                                                                                  
                                                                    
                                                                                            

                    
                                                   
                                                                                                                                                                                                                                                                                                                                                                                                   
                      
             
            
                            
                     

                 
       

                                                         
                                       
                                    
            
                                          
                 
                               
                          
 

                                                                    
                                       
                                    
            
                                          
                 
                               
                          
 

                                                                             
                                              
                                           
                                                 
           
 

                                                               
                                               
                                       
                                             
            
 

                                           
                                   
                                         
            
 

                                           
                                   
                                         
            
 

                                                  
                                          
                                                
            
 

                                                
                                              
                                      
                                            
            
 

                                                                    
                                                             
   
                                                                                                  
                                                    
                                                 
            
                                               
               
                                                                    
                                             
      
                               
                          
 

                                                                                                  
                                                    
                                                 
            
                                               
               
                                                                    
                                             
      
                               
                          
 

                                                                                                         
                                                           
                                                        
            
                                                      
               
                                                                    
                                             
      
                               
                          
 

                                                                   
                                             
                                        
            
                                        
                                             
 

                                                                   
                                             
                                        
                                        
                                             
           
 

                                                                          
                                                    
                                               
                                        
                                                    
           
 
   

                                                                                                                                                                                      
                                                                                                                                                       
                                                                                                                                                  
                                                             
                                                                                                                                                               
                                                    


^
SyntaxError: EOF while scanning triple-quoted string literal
[2023-11-14T15:15:20.236+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:20.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.133 seconds
[2023-11-14T15:15:22.509+0000] {processor.py:157} INFO - Started process (PID=15455) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:22.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:22.514+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:22.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:24.321+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:24.312+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    location
NameError: name 'location' is not defined
[2023-11-14T15:15:24.323+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:24.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.866 seconds
[2023-11-14T15:15:25.141+0000] {processor.py:157} INFO - Started process (PID=15457) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:25.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:25.174+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:25.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:26.438+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:26.431+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    location_
NameError: name 'location_' is not defined
[2023-11-14T15:15:26.440+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:26.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.347 seconds
[2023-11-14T15:15:32.951+0000] {processor.py:157} INFO - Started process (PID=15459) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:32.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:32.962+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:32.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:34.762+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:34.733+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:15:34.766+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:34.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.877 seconds
[2023-11-14T15:15:52.182+0000] {processor.py:157} INFO - Started process (PID=15469) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:52.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:15:52.184+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:52.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:53.501+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:15:53.490+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 443, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:15:53.504+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:15:53.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.382 seconds
[2023-11-14T15:16:00.560+0000] {processor.py:157} INFO - Started process (PID=15481) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:00.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:00.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:00.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:01.860+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:01.833+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    downloa
NameError: name 'down' is not defined
[2023-11-14T15:16:01.863+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:01.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.359 seconds
[2023-11-14T15:16:10.158+0000] {processor.py:157} INFO - Started process (PID=15490) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:10.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:10.172+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:10.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:11.796+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:11.766+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    download_
NameError: name 'download' is not defined
[2023-11-14T15:16:11.798+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:11.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.702 seconds
[2023-11-14T15:16:12.924+0000] {processor.py:157} INFO - Started process (PID=15492) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:12.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:12.934+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:12.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:14.130+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:14.117+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    download_loc
NameError: name 'download_loc' is not defined
[2023-11-14T15:16:14.133+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:14.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.267 seconds
[2023-11-14T15:16:17.263+0000] {processor.py:157} INFO - Started process (PID=15494) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:17.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:17.266+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:17.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:18.063+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:18.056+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 443, in <module>
    [wrangle_cases_deaths_task, wrangle_vaccinations_task, wrangle_government_measures_task] >> [join_wrangled_data_task, create_time_table, create_location_table]
NameError: name 'join_wrangled_data_task' is not defined
[2023-11-14T15:16:18.064+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:18.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.836 seconds
[2023-11-14T15:16:23.306+0000] {processor.py:157} INFO - Started process (PID=15496) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:23.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:23.312+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:23.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:23.379+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:23.375+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442
    download_location_data_task >>
                                  ^
SyntaxError: invalid syntax
[2023-11-14T15:16:23.381+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:23.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.154 seconds
[2023-11-14T15:16:27.019+0000] {processor.py:157} INFO - Started process (PID=15508) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:27.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:27.023+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:27.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:27.995+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:27.987+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    download_location_data_task >> wrangle_location_data_task
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:16:27.998+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:28.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.014 seconds
[2023-11-14T15:16:44.183+0000] {processor.py:157} INFO - Started process (PID=15518) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:44.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:16:44.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:44.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:45.682+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:16:45.659+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    download_location_data_task >> wrangle_location_data_task
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:16:45.684+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:16:45.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.547 seconds
[2023-11-14T15:17:02.171+0000] {processor.py:157} INFO - Started process (PID=15530) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:02.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:02.174+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:02.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:03.528+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:03.522+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    download_location_data_task >> wrangle_location_data_task
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:03.530+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:03.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.394 seconds
[2023-11-14T15:17:06.303+0000] {processor.py:157} INFO - Started process (PID=15539) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:06.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:06.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:06.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:07.430+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:07.424+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:07.432+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:07.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.165 seconds
[2023-11-14T15:17:19.456+0000] {processor.py:157} INFO - Started process (PID=15542) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:19.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:19.459+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:19.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:20.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:20.889+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 443, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:20.908+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:20.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.528 seconds
[2023-11-14T15:17:21.689+0000] {processor.py:157} INFO - Started process (PID=15552) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:21.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:21.692+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:21.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:22.488+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:22.483+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:22.490+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:22.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.826 seconds
[2023-11-14T15:17:24.609+0000] {processor.py:157} INFO - Started process (PID=15554) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:24.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:24.611+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:24.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:25.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:25.333+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:25.341+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:25.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.760 seconds
[2023-11-14T15:17:29.109+0000] {processor.py:157} INFO - Started process (PID=15558) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:29.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:29.112+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:29.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:30.067+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:30.060+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:30.069+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:30.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.988 seconds
[2023-11-14T15:17:31.143+0000] {processor.py:157} INFO - Started process (PID=15560) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:31.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:31.145+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:31.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:31.844+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:31.838+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:31.845+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:31.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.731 seconds
[2023-11-14T15:17:39.093+0000] {processor.py:157} INFO - Started process (PID=15570) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:39.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:39.096+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:39.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:39.760+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:39.754+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:39.762+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:39.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.704 seconds
[2023-11-14T15:17:42.924+0000] {processor.py:157} INFO - Started process (PID=15572) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:42.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:42.931+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:42.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:43.593+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:43.587+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:43.596+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:43.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.698 seconds
[2023-11-14T15:17:51.466+0000] {processor.py:157} INFO - Started process (PID=15582) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:51.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:51.468+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:51.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:52.556+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:52.550+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:52.558+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:52.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.132 seconds
[2023-11-14T15:17:57.534+0000] {processor.py:157} INFO - Started process (PID=15584) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:57.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:17:57.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:57.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:58.115+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:17:58.107+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:17:58.117+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:17:58.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.608 seconds
[2023-11-14T15:18:22.514+0000] {processor.py:157} INFO - Started process (PID=15603) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:18:22.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:18:22.517+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:18:22.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:18:24.087+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:18:24.076+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    python_callable=_create_cases_deaths_query,
NameError: name '_create_cases_deaths_query' is not defined
[2023-11-14T15:18:24.090+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:18:24.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.659 seconds
[2023-11-14T15:18:54.766+0000] {processor.py:157} INFO - Started process (PID=15624) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:18:54.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:18:54.768+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:18:54.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:18:55.377+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:18:55.368+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 442, in <module>
    python_callable=_create_cases_deaths_query,
NameError: name '_create_cases_deaths_query' is not defined
[2023-11-14T15:18:55.379+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:18:55.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.646 seconds
[2023-11-14T15:19:08.732+0000] {processor.py:157} INFO - Started process (PID=15637) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:08.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:08.742+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:08.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:10.062+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:09.994+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:10.079+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:10.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.430 seconds
[2023-11-14T15:19:19.371+0000] {processor.py:157} INFO - Started process (PID=15639) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:19.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:19.374+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:19.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:20.258+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:20.252+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:20.261+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:20.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.927 seconds
[2023-11-14T15:19:22.952+0000] {processor.py:157} INFO - Started process (PID=15649) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:22.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:22.956+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:22.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:24.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:24.390+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:24.397+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:24.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.549 seconds
[2023-11-14T15:19:28.680+0000] {processor.py:157} INFO - Started process (PID=15651) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:28.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:28.683+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:28.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:29.500+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:29.490+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:29.504+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:29.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.864 seconds
[2023-11-14T15:19:30.627+0000] {processor.py:157} INFO - Started process (PID=15653) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:30.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:30.629+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:30.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:31.311+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:31.304+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:31.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:31.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.716 seconds
[2023-11-14T15:19:32.939+0000] {processor.py:157} INFO - Started process (PID=15657) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:32.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:32.957+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:32.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:35.568+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:35.544+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:35.570+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:35.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.680 seconds
[2023-11-14T15:19:51.025+0000] {processor.py:157} INFO - Started process (PID=15667) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:51.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:51.031+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:51.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:52.327+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:52.319+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:19:52.332+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:52.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.363 seconds
[2023-11-14T15:19:57.126+0000] {processor.py:157} INFO - Started process (PID=15677) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:57.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:19:57.132+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:57.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:57.167+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:19:57.163+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445
    create_time_table >>
                        ^
SyntaxError: invalid syntax
[2023-11-14T15:19:57.168+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:19:57.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.081 seconds
[2023-11-14T15:20:03.274+0000] {processor.py:157} INFO - Started process (PID=15678) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:03.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:20:03.291+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:03.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:03.348+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:03.344+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445
    create_time_ >>
                   ^
SyntaxError: invalid syntax
[2023-11-14T15:20:03.350+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:03.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.133 seconds
[2023-11-14T15:20:04.378+0000] {processor.py:157} INFO - Started process (PID=15679) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:04.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:20:04.381+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:04.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:04.412+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:04.410+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445
    create_time_csv >>
                      ^
SyntaxError: invalid syntax
[2023-11-14T15:20:04.414+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:04.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.084 seconds
[2023-11-14T15:20:08.588+0000] {processor.py:157} INFO - Started process (PID=15682) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:08.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:20:08.591+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:08.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:09.603+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:09.594+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 444, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:20:09.606+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:09.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.051 seconds
[2023-11-14T15:20:13.658+0000] {processor.py:157} INFO - Started process (PID=15692) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:13.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:20:13.662+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:13.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:14.399+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:14.389+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:20:14.401+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:14.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.773 seconds
[2023-11-14T15:20:44.816+0000] {processor.py:157} INFO - Started process (PID=15713) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:44.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:20:44.819+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:44.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:45.592+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:20:45.583+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:20:45.594+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:20:45.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.807 seconds
[2023-11-14T15:21:16.696+0000] {processor.py:157} INFO - Started process (PID=15734) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:21:16.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:21:16.704+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:21:16.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:21:20.618+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:21:20.596+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 445, in <module>
    download_location_data_task >> wrangle_location_data_task >> create_location_table
NameError: name 'download_location_data_task' is not defined
[2023-11-14T15:21:20.628+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:21:20.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.988 seconds
[2023-11-14T15:21:50.941+0000] {processor.py:157} INFO - Started process (PID=15762) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:21:50.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:21:50.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:21:50.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:21:51.492+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:21:51.487+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 441, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:21:51.494+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:21:51.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.582 seconds
[2023-11-14T15:22:06.757+0000] {processor.py:157} INFO - Started process (PID=15772) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:06.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:22:06.760+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:06.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:07.668+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:07.661+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:22:07.670+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:07.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.953 seconds
[2023-11-14T15:22:18.236+0000] {processor.py:157} INFO - Started process (PID=15783) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:18.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:22:18.238+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:18.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:19.271+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:19.259+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:22:19.275+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:19.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.088 seconds
[2023-11-14T15:22:26.359+0000] {processor.py:157} INFO - Started process (PID=15785) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:26.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:22:26.362+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:26.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:26.981+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:26.975+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:22:26.982+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:27.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.650 seconds
[2023-11-14T15:22:40.595+0000] {processor.py:157} INFO - Started process (PID=15796) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:40.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:22:40.598+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:40.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:41.396+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:22:41.389+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:22:41.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:22:41.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.832 seconds
[2023-11-14T15:23:11.539+0000] {processor.py:157} INFO - Started process (PID=15824) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:23:11.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:23:11.542+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:23:11.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:23:12.297+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:23:12.291+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:23:12.299+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:23:12.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.789 seconds
[2023-11-14T15:23:42.452+0000] {processor.py:157} INFO - Started process (PID=15844) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:23:42.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:23:42.454+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:23:42.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:23:42.986+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:23:42.979+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:23:42.988+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:23:43.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.560 seconds
[2023-11-14T15:24:03.866+0000] {processor.py:157} INFO - Started process (PID=15865) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:03.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:24:03.869+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:03.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:04.618+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:04.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:24:04.620+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:04.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.792 seconds
[2023-11-14T15:24:06.316+0000] {processor.py:157} INFO - Started process (PID=15867) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:06.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:24:06.320+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:06.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:07.258+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:07.250+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:24:07.260+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:07.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.991 seconds
[2023-11-14T15:24:14.417+0000] {processor.py:157} INFO - Started process (PID=15869) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:14.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:24:14.420+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:14.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:15.196+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:15.189+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:24:15.198+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:15.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.811 seconds
[2023-11-14T15:24:33.502+0000] {processor.py:157} INFO - Started process (PID=15890) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:33.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:24:33.504+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:33.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:34.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:34.068+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:24:34.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:34.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.599 seconds
[2023-11-14T15:24:41.219+0000] {processor.py:157} INFO - Started process (PID=15892) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:41.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:24:41.221+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:41.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:41.804+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:24:41.798+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:24:41.806+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:24:41.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.611 seconds
[2023-11-14T15:25:12.215+0000] {processor.py:157} INFO - Started process (PID=15920) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:12.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:25:12.218+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:12.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:12.718+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:12.713+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:25:12.719+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:12.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.527 seconds
[2023-11-14T15:25:32.400+0000] {processor.py:157} INFO - Started process (PID=15931) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:32.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:25:32.403+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:32.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:32.920+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:32.914+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:25:32.922+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:32.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T15:25:52.131+0000] {processor.py:157} INFO - Started process (PID=15950) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:52.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:25:52.136+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:52.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:53.604+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:53.592+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 354, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:25:53.608+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:53.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.525 seconds
[2023-11-14T15:25:58.778+0000] {processor.py:157} INFO - Started process (PID=15952) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:58.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:25:58.780+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:58.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:59.450+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:25:59.444+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:25:59.451+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:25:59.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.703 seconds
[2023-11-14T15:26:13.666+0000] {processor.py:157} INFO - Started process (PID=15962) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:26:13.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:26:13.668+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:26:13.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:26:14.213+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:26:14.204+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:26:14.214+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:26:14.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.572 seconds
[2023-11-14T15:26:43.940+0000] {processor.py:157} INFO - Started process (PID=15991) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:26:43.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:26:43.942+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:26:43.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:26:44.962+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:26:44.941+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 21, in <module>
    from airflow.operators import CreateLocalFileOperator
ImportError: cannot import name 'CreateLocalFileOperator' from 'airflow.operators' (/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/__init__.py)
[2023-11-14T15:26:44.968+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:26:45.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.141 seconds
[2023-11-14T15:27:11.460+0000] {processor.py:157} INFO - Started process (PID=16012) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:11.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:27:11.463+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:11.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:12.328+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:12.324+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:27:12.329+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:12.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.899 seconds
[2023-11-14T15:27:21.162+0000] {processor.py:157} INFO - Started process (PID=16014) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:21.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:27:21.164+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:21.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:21.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:21.737+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:27:21.746+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:21.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.608 seconds
[2023-11-14T15:27:23.522+0000] {processor.py:157} INFO - Started process (PID=16024) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:23.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:27:23.526+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:23.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:24.127+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:24.120+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:27:24.130+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:24.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.632 seconds
[2023-11-14T15:27:30.933+0000] {processor.py:157} INFO - Started process (PID=16028) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:30.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:27:30.935+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:30.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:31.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:31.461+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:27:31.468+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:31.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.557 seconds
[2023-11-14T15:27:53.385+0000] {processor.py:157} INFO - Started process (PID=16047) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:53.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:27:53.387+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:53.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:54.387+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:27:54.344+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:27:54.392+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:27:54.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.052 seconds
[2023-11-14T15:28:03.534+0000] {processor.py:157} INFO - Started process (PID=16059) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:03.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:03.537+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:03.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:04.318+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:04.313+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:28:04.320+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:04.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.808 seconds
[2023-11-14T15:28:12.530+0000] {processor.py:157} INFO - Started process (PID=16061) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:12.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:12.542+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:12.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:12.593+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:12.590+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 357
    wrangle_vaccinations_task = PythonOperator(
    ^
IndentationError: expected an indented block
[2023-11-14T15:28:12.594+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:12.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.136 seconds
[2023-11-14T15:28:18.765+0000] {processor.py:157} INFO - Started process (PID=16070) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:18.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:18.769+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:18.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:19.732+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:19.726+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 349, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:28:19.734+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:19.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.010 seconds
[2023-11-14T15:28:36.620+0000] {processor.py:157} INFO - Started process (PID=16083) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:36.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:36.622+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:36.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:37.157+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:37.149+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 351, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:28:37.159+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:37.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.562 seconds
[2023-11-14T15:28:39.264+0000] {processor.py:157} INFO - Started process (PID=16085) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:39.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:39.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:39.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:39.298+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:39.295+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 37
    def
      ^
SyntaxError: invalid syntax
[2023-11-14T15:28:39.299+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:39.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.066 seconds
[2023-11-14T15:28:43.326+0000] {processor.py:157} INFO - Started process (PID=16094) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:43.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:43.328+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:43.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:43.352+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:43.350+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:28:43.353+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:43.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.077 seconds
[2023-11-14T15:28:53.523+0000] {processor.py:157} INFO - Started process (PID=16095) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:53.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:28:53.525+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:53.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:53.551+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:28:53.550+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 38
    df =
       ^
SyntaxError: invalid syntax
[2023-11-14T15:28:53.552+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:28:53.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.058 seconds
[2023-11-14T15:29:21.946+0000] {processor.py:157} INFO - Started process (PID=16124) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:29:21.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:29:21.950+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:29:21.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:29:21.975+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:29:21.973+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:29:21.977+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:29:22.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.070 seconds
[2023-11-14T15:29:52.346+0000] {processor.py:157} INFO - Started process (PID=16144) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:29:52.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:29:52.348+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:29:52.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:29:52.369+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:29:52.368+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:29:52.370+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:29:52.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.053 seconds
[2023-11-14T15:30:22.841+0000] {processor.py:157} INFO - Started process (PID=16163) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:30:22.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:30:22.844+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:30:22.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:30:22.870+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:30:22.869+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:30:22.871+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:30:22.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.093 seconds
[2023-11-14T15:30:53.250+0000] {processor.py:157} INFO - Started process (PID=16191) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:30:53.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:30:53.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:30:53.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:30:53.280+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:30:53.278+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:30:53.282+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:30:53.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.067 seconds
[2023-11-14T15:31:23.472+0000] {processor.py:157} INFO - Started process (PID=16211) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:31:23.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:31:23.477+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:31:23.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:31:23.516+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:31:23.514+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:31:23.518+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:31:23.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.115 seconds
[2023-11-14T15:31:38.574+0000] {processor.py:157} INFO - Started process (PID=16222) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:31:38.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:31:38.577+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:31:38.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:31:38.613+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:31:38.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:31:38.615+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:31:38.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.135 seconds
[2023-11-14T15:32:09.074+0000] {processor.py:157} INFO - Started process (PID=16249) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:32:09.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:32:09.078+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:32:09.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:32:09.138+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:32:09.136+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:32:09.140+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:32:09.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.151 seconds
[2023-11-14T15:32:39.363+0000] {processor.py:157} INFO - Started process (PID=16269) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:32:39.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:32:39.366+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:32:39.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:32:39.389+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:32:39.388+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:32:39.390+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:32:39.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.056 seconds
[2023-11-14T15:33:09.696+0000] {processor.py:157} INFO - Started process (PID=16289) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:33:09.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:33:09.699+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:33:09.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:33:09.721+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:33:09.720+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:33:09.722+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:33:09.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.055 seconds
[2023-11-14T15:33:40.126+0000] {processor.py:157} INFO - Started process (PID=16309) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:33:40.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:33:40.130+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:33:40.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:33:40.171+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:33:40.169+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:33:40.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:33:40.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.099 seconds
[2023-11-14T15:34:10.411+0000] {processor.py:157} INFO - Started process (PID=16336) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:34:10.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:34:10.414+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:34:10.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:34:10.450+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:34:10.446+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:34:10.452+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:34:10.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.097 seconds
[2023-11-14T15:34:41.140+0000] {processor.py:157} INFO - Started process (PID=16355) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:34:41.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:34:41.142+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:34:41.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:34:41.171+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:34:41.170+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:34:41.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:34:41.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.085 seconds
[2023-11-14T15:35:11.329+0000] {processor.py:157} INFO - Started process (PID=16375) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:35:11.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:35:11.333+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:35:11.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:35:11.368+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:35:11.366+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:35:11.369+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:35:11.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.081 seconds
[2023-11-14T15:35:41.722+0000] {processor.py:157} INFO - Started process (PID=16394) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:35:41.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:35:41.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:35:41.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:35:41.752+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:35:41.751+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:35:41.753+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:35:41.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.063 seconds
[2023-11-14T15:36:12.541+0000] {processor.py:157} INFO - Started process (PID=16414) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:36:12.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:36:12.579+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:36:12.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:36:13.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:36:13.242+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:36:13.257+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:36:13.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.041 seconds
[2023-11-14T15:36:43.702+0000] {processor.py:157} INFO - Started process (PID=16434) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:36:43.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:36:43.704+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:36:43.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:36:43.729+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:36:43.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:36:43.729+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:36:43.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.064 seconds
[2023-11-14T15:37:14.121+0000] {processor.py:157} INFO - Started process (PID=16460) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:37:14.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:37:14.124+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:37:14.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:37:14.236+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:37:14.232+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:37:14.240+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:37:14.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.191 seconds
[2023-11-14T15:37:44.772+0000] {processor.py:157} INFO - Started process (PID=16482) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:37:44.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:37:44.774+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:37:44.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:37:44.804+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:37:44.803+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:37:44.804+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:37:44.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.067 seconds
[2023-11-14T15:38:15.170+0000] {processor.py:157} INFO - Started process (PID=16501) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:38:15.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:38:15.173+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:38:15.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:38:15.208+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:38:15.207+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:38:15.209+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:38:15.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.069 seconds
[2023-11-14T15:38:45.596+0000] {processor.py:157} INFO - Started process (PID=16530) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:38:45.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:38:45.599+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:38:45.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:38:45.630+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:38:45.628+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:38:45.631+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:38:45.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.071 seconds
[2023-11-14T15:39:15.979+0000] {processor.py:157} INFO - Started process (PID=16549) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:39:15.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:39:15.983+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:39:15.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:39:16.012+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:39:16.011+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:39:16.014+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:39:16.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.067 seconds
[2023-11-14T15:39:46.348+0000] {processor.py:157} INFO - Started process (PID=16577) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:39:46.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:39:46.351+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:39:46.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:39:46.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:39:46.378+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 42
    time_df = pd.DataFrame(columns=['date', 'week', 'month', 'trimester', 'semester', 'year'])
    ^
IndentationError: expected an indented block
[2023-11-14T15:39:46.383+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:39:46.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.096 seconds
[2023-11-14T15:40:03.730+0000] {processor.py:157} INFO - Started process (PID=16586) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:03.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:03.734+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:03.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:03.781+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:03.778+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 40
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T15:40:03.783+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:03.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.120 seconds
[2023-11-14T15:40:14.772+0000] {processor.py:157} INFO - Started process (PID=16597) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:14.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:14.776+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:14.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:15.549+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:15.543+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 41, in <module>
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')
NameError: name 'start_date' is not defined
[2023-11-14T15:40:15.551+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:15.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.813 seconds
[2023-11-14T15:40:22.148+0000] {processor.py:157} INFO - Started process (PID=16599) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:22.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:22.152+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:22.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:23.163+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:23.154+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 41, in <module>
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')
NameError: name 'start_date' is not defined
[2023-11-14T15:40:23.166+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:23.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.065 seconds
[2023-11-14T15:40:24.233+0000] {processor.py:157} INFO - Started process (PID=16601) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:24.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:24.235+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:24.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:24.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:24.817+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 43, in <module>
    'Date': date_range,
NameError: name 'date_range' is not defined
[2023-11-14T15:40:24.827+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:24.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.623 seconds
[2023-11-14T15:40:26.312+0000] {processor.py:157} INFO - Started process (PID=16603) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:26.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:26.314+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:26.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:27.107+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:27.101+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:27.109+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:27.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.830 seconds
[2023-11-14T15:40:30.310+0000] {processor.py:157} INFO - Started process (PID=16613) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:30.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:30.317+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:30.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:31.896+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:31.820+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 50, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:32.067+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:32.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.938 seconds
[2023-11-14T15:40:35.143+0000] {processor.py:157} INFO - Started process (PID=16615) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:35.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:35.146+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:35.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:35.856+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:35.849+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:35.858+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:35.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.744 seconds
[2023-11-14T15:40:37.990+0000] {processor.py:157} INFO - Started process (PID=16619) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:37.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:37.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:37.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:38.571+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:38.564+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:38.573+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:38.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.605 seconds
[2023-11-14T15:40:43.282+0000] {processor.py:157} INFO - Started process (PID=16629) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:43.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:43.287+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:43.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:44.279+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:44.264+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:44.281+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:44.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.082 seconds
[2023-11-14T15:40:45.310+0000] {processor.py:157} INFO - Started process (PID=16631) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:45.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:45.313+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:45.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:45.995+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:45.988+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:45.997+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:46.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.711 seconds
[2023-11-14T15:40:48.100+0000] {processor.py:157} INFO - Started process (PID=16633) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:48.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:48.103+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:48.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:49.092+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:49.073+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:49.095+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:49.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.063 seconds
[2023-11-14T15:40:50.166+0000] {processor.py:157} INFO - Started process (PID=16635) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:50.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:50.171+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:50.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:50.955+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:50.949+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 51, in <module>
    df = pd.DataFrame(data)
NameError: name 'data' is not defined
[2023-11-14T15:40:50.958+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:50.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.821 seconds
[2023-11-14T15:40:54.075+0000] {processor.py:157} INFO - Started process (PID=16637) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:54.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:54.078+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:54.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:54.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:54.650+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 364, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:40:54.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:54.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.607 seconds
[2023-11-14T15:40:55.750+0000] {processor.py:157} INFO - Started process (PID=16647) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:55.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:40:55.752+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:55.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:56.433+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:40:56.421+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 365, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:40:56.435+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:40:56.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.708 seconds
[2023-11-14T15:41:03.405+0000] {processor.py:157} INFO - Started process (PID=16650) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:03.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:03.408+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:03.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:04.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:04.453+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:41:04.462+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:04.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.091 seconds
[2023-11-14T15:41:05.453+0000] {processor.py:157} INFO - Started process (PID=16652) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:05.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:05.456+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:05.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:05.485+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:05.483+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    pd.
      ^
SyntaxError: invalid syntax
[2023-11-14T15:41:05.486+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:05.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.074 seconds
[2023-11-14T15:41:07.711+0000] {processor.py:157} INFO - Started process (PID=16655) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:07.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:07.715+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:07.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:09.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:09.035+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:41:09.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:09.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.415 seconds
[2023-11-14T15:41:25.418+0000] {processor.py:157} INFO - Started process (PID=16674) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:25.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:25.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:25.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:26.200+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:26.194+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:41:26.202+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:26.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.812 seconds
[2023-11-14T15:41:28.505+0000] {processor.py:157} INFO - Started process (PID=16676) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:28.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:28.507+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:28.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:29.190+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:29.185+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:41:29.192+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:29.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.711 seconds
[2023-11-14T15:41:30.296+0000] {processor.py:157} INFO - Started process (PID=16678) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:30.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:30.299+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:30.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:30.979+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:30.971+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:41:30.981+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:31.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.713 seconds
[2023-11-14T15:41:38.597+0000] {processor.py:157} INFO - Started process (PID=16689) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:38.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:41:38.610+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:38.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:40.462+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:41:40.456+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:41:40.464+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:41:40.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.912 seconds
[2023-11-14T15:42:10.629+0000] {processor.py:157} INFO - Started process (PID=16709) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:10.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:10.631+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:10.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:11.052+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:11.045+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 366, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:42:11.054+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:11.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.486 seconds
[2023-11-14T15:42:22.399+0000] {processor.py:157} INFO - Started process (PID=16720) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:22.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:22.403+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:22.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:22.444+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:22.442+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:22.446+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:22.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.092 seconds
[2023-11-14T15:42:26.530+0000] {processor.py:157} INFO - Started process (PID=16721) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:26.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:26.532+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:26.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:26.556+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:26.553+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:26.557+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:26.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.063 seconds
[2023-11-14T15:42:42.801+0000] {processor.py:157} INFO - Started process (PID=16739) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:42.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:42.806+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:42.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:42.830+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:42.827+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:42.831+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:42.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.063 seconds
[2023-11-14T15:42:44.960+0000] {processor.py:157} INFO - Started process (PID=16741) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:44.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:44.964+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:44.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:45.000+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:44.997+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:45.001+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:45.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.122 seconds
[2023-11-14T15:42:47.119+0000] {processor.py:157} INFO - Started process (PID=16742) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:47.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:47.121+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:47.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:47.147+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:47.145+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:47.149+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:47.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.063 seconds
[2023-11-14T15:42:49.192+0000] {processor.py:157} INFO - Started process (PID=16743) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:49.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:49.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:49.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:49.223+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:49.220+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:49.223+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:49.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.060 seconds
[2023-11-14T15:42:53.339+0000] {processor.py:157} INFO - Started process (PID=16744) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:53.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:53.341+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:53.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:53.364+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:53.363+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:53.365+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:53.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.052 seconds
[2023-11-14T15:42:56.405+0000] {processor.py:157} INFO - Started process (PID=16753) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:56.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:42:56.407+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:56.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:56.432+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:42:56.431+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:42:56.433+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:42:56.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.061 seconds
[2023-11-14T15:43:01.513+0000] {processor.py:157} INFO - Started process (PID=16755) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:01.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:43:01.515+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:43:01.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:01.539+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:43:01.538+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:43:01.540+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:01.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.066 seconds
[2023-11-14T15:43:03.629+0000] {processor.py:157} INFO - Started process (PID=16756) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:03.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:43:03.631+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:43:03.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:03.659+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:43:03.658+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:43:03.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:03.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.059 seconds
[2023-11-14T15:43:34.052+0000] {processor.py:157} INFO - Started process (PID=16775) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:34.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:43:34.054+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:43:34.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:34.078+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:43:34.077+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:43:34.079+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:43:34.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.057 seconds
[2023-11-14T15:44:04.434+0000] {processor.py:157} INFO - Started process (PID=16802) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:04.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:44:04.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:44:04.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:04.459+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:44:04.458+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:44:04.460+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:04.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.066 seconds
[2023-11-14T15:44:34.864+0000] {processor.py:157} INFO - Started process (PID=16821) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:34.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:44:34.866+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:44:34.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:34.889+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:44:34.886+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 52
    df.to_csv('/opt/airflow/dags/postgres/time_table.csv', index=False)
                                                                       ^
SyntaxError: invalid syntax
[2023-11-14T15:44:34.891+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:34.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.063 seconds
[2023-11-14T15:44:40.272+0000] {processor.py:157} INFO - Started process (PID=16830) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:40.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:44:40.287+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:44:40.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:41.177+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:44:41.168+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 371, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:44:41.180+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:44:41.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.943 seconds
[2023-11-14T15:45:08.949+0000] {processor.py:157} INFO - Started process (PID=16850) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:08.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:45:08.977+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:45:08.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:10.362+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:45:10.354+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 371, in <module>
    python_callable=download_location_data,
NameError: name 'download_location_data' is not defined
[2023-11-14T15:45:10.365+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:10.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.465 seconds
[2023-11-14T15:45:23.440+0000] {processor.py:157} INFO - Started process (PID=16862) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:23.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:45:23.448+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:45:23.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:25.004+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:45:24.986+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 376, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:45:25.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:25.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.613 seconds
[2023-11-14T15:45:55.379+0000] {processor.py:157} INFO - Started process (PID=16883) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:55.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:45:55.381+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:45:55.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:55.786+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:45:55.770+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 376, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:45:55.787+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:45:55.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.432 seconds
[2023-11-14T15:46:16.019+0000] {processor.py:157} INFO - Started process (PID=16892) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:16.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:46:16.021+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:16.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:16.496+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:16.489+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 376, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:46:16.497+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:16.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.509 seconds
[2023-11-14T15:46:22.822+0000] {processor.py:157} INFO - Started process (PID=16904) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:22.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:46:22.864+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:22.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:24.865+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:24.854+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 376, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:46:24.869+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:24.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.160 seconds
[2023-11-14T15:46:44.311+0000] {processor.py:157} INFO - Started process (PID=16914) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:44.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:46:44.314+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:44.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:45.065+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:45.053+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 378, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:46:45.067+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:45.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.797 seconds
[2023-11-14T15:46:49.628+0000] {processor.py:157} INFO - Started process (PID=16923) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:49.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:46:49.634+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:49.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:49.853+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:49.828+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 334
    '''
def _create_cases_deaths_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/cases_deaths.csv')
    with open("/opt/airflow/dags/postgres/cases_deaths_inserts.sql", "w") as f:
        df_iterable = df.iterrows()

        f.write(
            "DROP TABLE IF EXISTS cases_deaths;\n"
            "CREATE TABLE cases_deaths (\n"
            "id SERIAL PRIMARY KEY,\n"
            "date_reported DATE,\n"
            "country_code VARCHAR(10),\n"
            "country VARCHAR(100),\n"
            "who_region VARCHAR(100),\n"
            "new_cases INTEGER,\n"
            "cumulative_cases INTEGER,\n"
            "new_deaths INTEGER,\n"
            "cumulative_deaths INTEGER\n"
            ");\n"
        )
        
        
        for index, row in df_iterable:
            id = index
            date_reported = row['Date_reported']
            country_code = row['Country_code']
            # If the country name contains a single quote, replace it with two single quotes 
            # (the apostrophe is a reserved character in SQL)
            country = row['Country'].replace("'", "''")
            who_region = row['WHO_region']
            new_cases = row['New_cases']
            cumulative_cases = row['Cumulative_cases']
            new_deaths = row['New_deaths']
            cumulative_deaths = row['Cumulative_deaths']

            f.write(
                "INSERT INTO cases_deaths VALUES ("
                f"'{id}', '{date_reported}', '{country_code}', '{country}', '{who_region}', {new_cases}, {cumulative_cases}, {new_deaths}, {cumulative_deaths}"
                ");\n"
            )
            
            # Just for debugging purposes, I limit the number of records to 100
            if index == 100:
                break

        f.close()
        
def _create_government_measures_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/government_measures.csv')
    # Mantain only the columns of interest
    df = df[['CountryName', 'CountryCode', 'RegionName', 'RegionCode', 'Jurisdiction', 'Date', 'StringencyIndex_Average', 'GovernmentResponseIndex_Average', 'ContainmentHealthIndex_Average', 'EconomicSupportIndex']]
    
    with open("/opt/airflow/dags/postgres/government_measures_inserts.sql", "w") as f:
        df_iterable = df.iterrows()

        f.write(
            "DROP TABLE IF EXISTS government_measures;\n"
            "CREATE TABLE government_measures (\n"
            "id SERIAL PRIMARY KEY,\n"
            "country_name VARCHAR(100),\n"
            "country_code VARCHAR(10),\n"
            "region_name VARCHAR(100),\n"
            "region_code VARCHAR(10),\n"
            "jurisdiction VARCHAR(100),\n"
            "date DATE,\n"
            "stringency_index_average FLOAT,\n"
            "government_response_index_average FLOAT,\n"
            "containment_health_index_average FLOAT,\n"
            "economic_support_index FLOAT\n"
            ");\n"
        )
        
        for index, row in df_iterable:
            id = index
            country_name = row['CountryName'].replace("'", "''")
            country_code = row['CountryCode']
            region_name = row['RegionName'] if pd.notnull(row['RegionName']) else "null"
            region_code = row['RegionCode'] if pd.notnull(row['RegionCode']) else "null"
            jurisdiction = row['Jurisdiction'].replace("'", "''") if pd.notnull(row['Jurisdiction']) else "null"
            date = row['Date']
            stringency_index_average = row['StringencyIndex_Average'] if pd.notnull(row['StringencyIndex_Average']) else "null"
            government_response_index_average = row['GovernmentResponseIndex_Average'] if pd.notnull(row['GovernmentResponseIndex_Average']) else "null"
            containment_health_index_average = row['ContainmentHealthIndex_Average'] if pd.notnull(row['ContainmentHealthIndex_Average']) else "null"
            economic_support_index = row['EconomicSupportIndex'] if pd.notnull(row['EconomicSupportIndex']) else "null"

            f.write(
                "INSERT INTO government_measures VALUES ("
                f"'{id}', '{country_name}', '{country_code}', '{region_name}', '{region_code}', '{jurisdiction}', '{date}', {stringency_index_average}, {government_response_index_average}, {containment_health_index_average}, {economic_support_index}"
                ");\n"
            )
            
            # Just for debugging purposes, I limit the number of records to 100
            if index == 100:
                break

        f.close()
        
def _create_vaccinations_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/vaccinations.csv')
    df.fillna("null", inplace=True)
    with open("/opt/airflow/dags/postgres/vaccinations_inserts.sql", "w") as f:
        df_iterable = df.iterrows()
        
        f.write(
            "DROP TABLE IF EXISTS vaccinations;\n"
            "CREATE TABLE vaccinations (\n"
            "id SERIAL PRIMARY KEY,\n"
            "date_ DATE,\n"
            "location_ VARCHAR(100),\n"
            "iso_code VARCHAR(10),\n"
            "total_vaccinations INTEGER,\n"
            "people_vaccinated INTEGER,\n"
            "people_fully_vaccinated INTEGER,\n"
            "daily_vaccinations_raw INTEGER,\n"
            "daily_vaccinations INTEGER,\n"
            "total_vaccinations_per_hundred FLOAT,\n"
            "people_vaccinated_per_hundred FLOAT,\n"
            "people_fully_vaccinated_per_hundred FLOAT,\n"
            "daily_vaccinations_per_million INTEGER,\n"
            "daily_people_vaccinated INTEGER,\n"
            "daily_people_vaccinated_per_hundred FLOAT\n"
            ");\n"
        )
        
        for index, row in df_iterable:
            id = index
            date = row['date']
            location = row['location']
            iso_code = row['iso_code']
            total_vaccinations = row['total_vaccinations']
            people_vaccinated = row['people_vaccinated']
            people_fully_vaccinated = row['people_fully_vaccinated']
            daily_vaccinations_raw = row['daily_vaccinations_raw']
            daily_vaccinations = row['daily_vaccinations']
            total_vaccinations_per_hundred = row['total_vaccinations_per_hundred']
            people_vaccinated_per_hundred = row['people_vaccinated_per_hundred']
            people_fully_vaccinated_per_hundred = row['people_fully_vaccinated_per_hundred']
            daily_vaccinations_per_million = row['daily_vaccinations_per_million']
            daily_people_vaccinated = row['daily_people_vaccinated']
            daily_people_vaccinated_per_hundred = row['daily_people_vaccinated_per_hundred']

            f.write(
                "INSERT INTO vaccinations VALUES ("
                f"'{id}', '{date}', '{location}', '{iso_code}', {total_vaccinations}, {people_vaccinated}, {people_fully_vaccinated}, {daily_vaccinations_raw}, {daily_vaccinations}, {total_vaccinations_per_hundred}, {people_vaccinated_per_hundred}, {people_fully_vaccinated_per_hundred}, {daily_vaccinations_per_million}, {daily_people_vaccinated}, {daily_people_vaccinated_per_hundred}"
                ");\n"
            )
            
            if index == 100:
                break

        f.close()
'''
    ^
IndentationError: expected an indented block
[2023-11-14T15:46:49.868+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:50.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.441 seconds
[2023-11-14T15:46:51.069+0000] {processor.py:157} INFO - Started process (PID=16925) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:51.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:46:51.076+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:51.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:51.135+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:51.133+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 335
    '''
def _create_cases_deaths_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/cases_deaths.csv')
    with open("/opt/airflow/dags/postgres/cases_deaths_inserts.sql", "w") as f:
        df_iterable = df.iterrows()

        f.write(
            "DROP TABLE IF EXISTS cases_deaths;\n"
            "CREATE TABLE cases_deaths (\n"
            "id SERIAL PRIMARY KEY,\n"
            "date_reported DATE,\n"
            "country_code VARCHAR(10),\n"
            "country VARCHAR(100),\n"
            "who_region VARCHAR(100),\n"
            "new_cases INTEGER,\n"
            "cumulative_cases INTEGER,\n"
            "new_deaths INTEGER,\n"
            "cumulative_deaths INTEGER\n"
            ");\n"
        )
        
        
        for index, row in df_iterable:
            id = index
            date_reported = row['Date_reported']
            country_code = row['Country_code']
            # If the country name contains a single quote, replace it with two single quotes 
            # (the apostrophe is a reserved character in SQL)
            country = row['Country'].replace("'", "''")
            who_region = row['WHO_region']
            new_cases = row['New_cases']
            cumulative_cases = row['Cumulative_cases']
            new_deaths = row['New_deaths']
            cumulative_deaths = row['Cumulative_deaths']

            f.write(
                "INSERT INTO cases_deaths VALUES ("
                f"'{id}', '{date_reported}', '{country_code}', '{country}', '{who_region}', {new_cases}, {cumulative_cases}, {new_deaths}, {cumulative_deaths}"
                ");\n"
            )
            
            # Just for debugging purposes, I limit the number of records to 100
            if index == 100:
                break

        f.close()
        
def _create_government_measures_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/government_measures.csv')
    # Mantain only the columns of interest
    df = df[['CountryName', 'CountryCode', 'RegionName', 'RegionCode', 'Jurisdiction', 'Date', 'StringencyIndex_Average', 'GovernmentResponseIndex_Average', 'ContainmentHealthIndex_Average', 'EconomicSupportIndex']]
    
    with open("/opt/airflow/dags/postgres/government_measures_inserts.sql", "w") as f:
        df_iterable = df.iterrows()

        f.write(
            "DROP TABLE IF EXISTS government_measures;\n"
            "CREATE TABLE government_measures (\n"
            "id SERIAL PRIMARY KEY,\n"
            "country_name VARCHAR(100),\n"
            "country_code VARCHAR(10),\n"
            "region_name VARCHAR(100),\n"
            "region_code VARCHAR(10),\n"
            "jurisdiction VARCHAR(100),\n"
            "date DATE,\n"
            "stringency_index_average FLOAT,\n"
            "government_response_index_average FLOAT,\n"
            "containment_health_index_average FLOAT,\n"
            "economic_support_index FLOAT\n"
            ");\n"
        )
        
        for index, row in df_iterable:
            id = index
            country_name = row['CountryName'].replace("'", "''")
            country_code = row['CountryCode']
            region_name = row['RegionName'] if pd.notnull(row['RegionName']) else "null"
            region_code = row['RegionCode'] if pd.notnull(row['RegionCode']) else "null"
            jurisdiction = row['Jurisdiction'].replace("'", "''") if pd.notnull(row['Jurisdiction']) else "null"
            date = row['Date']
            stringency_index_average = row['StringencyIndex_Average'] if pd.notnull(row['StringencyIndex_Average']) else "null"
            government_response_index_average = row['GovernmentResponseIndex_Average'] if pd.notnull(row['GovernmentResponseIndex_Average']) else "null"
            containment_health_index_average = row['ContainmentHealthIndex_Average'] if pd.notnull(row['ContainmentHealthIndex_Average']) else "null"
            economic_support_index = row['EconomicSupportIndex'] if pd.notnull(row['EconomicSupportIndex']) else "null"

            f.write(
                "INSERT INTO government_measures VALUES ("
                f"'{id}', '{country_name}', '{country_code}', '{region_name}', '{region_code}', '{jurisdiction}', '{date}', {stringency_index_average}, {government_response_index_average}, {containment_health_index_average}, {economic_support_index}"
                ");\n"
            )
            
            # Just for debugging purposes, I limit the number of records to 100
            if index == 100:
                break

        f.close()
        
def _create_vaccinations_query(previous_epoch: int, output_folder: str):
    df = pd.read_csv('/opt/airflow/dags/postgres/vaccinations.csv')
    df.fillna("null", inplace=True)
    with open("/opt/airflow/dags/postgres/vaccinations_inserts.sql", "w") as f:
        df_iterable = df.iterrows()
        
        f.write(
            "DROP TABLE IF EXISTS vaccinations;\n"
            "CREATE TABLE vaccinations (\n"
            "id SERIAL PRIMARY KEY,\n"
            "date_ DATE,\n"
            "location_ VARCHAR(100),\n"
            "iso_code VARCHAR(10),\n"
            "total_vaccinations INTEGER,\n"
            "people_vaccinated INTEGER,\n"
            "people_fully_vaccinated INTEGER,\n"
            "daily_vaccinations_raw INTEGER,\n"
            "daily_vaccinations INTEGER,\n"
            "total_vaccinations_per_hundred FLOAT,\n"
            "people_vaccinated_per_hundred FLOAT,\n"
            "people_fully_vaccinated_per_hundred FLOAT,\n"
            "daily_vaccinations_per_million INTEGER,\n"
            "daily_people_vaccinated INTEGER,\n"
            "daily_people_vaccinated_per_hundred FLOAT\n"
            ");\n"
        )
        
        for index, row in df_iterable:
            id = index
            date = row['date']
            location = row['location']
            iso_code = row['iso_code']
            total_vaccinations = row['total_vaccinations']
            people_vaccinated = row['people_vaccinated']
            people_fully_vaccinated = row['people_fully_vaccinated']
            daily_vaccinations_raw = row['daily_vaccinations_raw']
            daily_vaccinations = row['daily_vaccinations']
            total_vaccinations_per_hundred = row['total_vaccinations_per_hundred']
            people_vaccinated_per_hundred = row['people_vaccinated_per_hundred']
            people_fully_vaccinated_per_hundred = row['people_fully_vaccinated_per_hundred']
            daily_vaccinations_per_million = row['daily_vaccinations_per_million']
            daily_people_vaccinated = row['daily_people_vaccinated']
            daily_people_vaccinated_per_hundred = row['daily_people_vaccinated_per_hundred']

            f.write(
                "INSERT INTO vaccinations VALUES ("
                f"'{id}', '{date}', '{location}', '{iso_code}', {total_vaccinations}, {people_vaccinated}, {people_fully_vaccinated}, {daily_vaccinations_raw}, {daily_vaccinations}, {total_vaccinations_per_hundred}, {people_vaccinated_per_hundred}, {people_fully_vaccinated_per_hundred}, {daily_vaccinations_per_million}, {daily_people_vaccinated}, {daily_people_vaccinated_per_hundred}"
                ");\n"
            )
            
            if index == 100:
                break

        f.close()
'''
    ^
IndentationError: expected an indented block
[2023-11-14T15:46:51.146+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:51.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.161 seconds
[2023-11-14T15:46:54.253+0000] {processor.py:157} INFO - Started process (PID=16926) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:54.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:46:54.256+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:54.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:54.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:46:54.880+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:46:54.892+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:46:54.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.684 seconds
[2023-11-14T15:47:25.323+0000] {processor.py:157} INFO - Started process (PID=16946) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:47:25.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:47:25.328+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:47:25.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:47:26.465+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:47:26.449+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:47:26.466+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:47:26.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.208 seconds
[2023-11-14T15:47:56.863+0000] {processor.py:157} INFO - Started process (PID=16967) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:47:56.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T15:47:56.867+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:47:56.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:47:57.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T15:47:57.321+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T15:47:57.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T15:47:57.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.503 seconds
[2023-11-14T16:18:52.618+0000] {processor.py:157} INFO - Started process (PID=16994) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:18:52.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:18:52.793+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:18:52.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:19:08.093+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:19:07.946+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:19:08.108+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:19:08.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 17.136 seconds
[2023-11-14T16:19:39.342+0000] {processor.py:157} INFO - Started process (PID=17024) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:19:39.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:19:39.356+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:19:39.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:19:41.516+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:19:41.501+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:19:41.519+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:19:41.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.263 seconds
[2023-11-14T16:20:11.959+0000] {processor.py:157} INFO - Started process (PID=17043) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:20:11.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:20:11.962+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:20:11.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:20:12.611+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:20:12.603+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:20:12.612+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:20:12.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.688 seconds
[2023-11-14T16:20:42.985+0000] {processor.py:157} INFO - Started process (PID=17063) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:20:42.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:20:42.988+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:20:42.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:20:43.624+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:20:43.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:20:43.625+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:20:43.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.695 seconds
[2023-11-14T16:21:14.116+0000] {processor.py:157} INFO - Started process (PID=17092) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:21:14.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:21:14.119+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:21:14.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:21:14.808+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:21:14.798+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:21:14.809+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:21:14.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.729 seconds
[2023-11-14T16:21:45.441+0000] {processor.py:157} INFO - Started process (PID=17113) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:21:45.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:21:45.444+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:21:45.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:21:46.112+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:21:46.104+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:21:46.114+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:21:46.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.716 seconds
[2023-11-14T16:22:16.505+0000] {processor.py:157} INFO - Started process (PID=17133) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:22:16.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:22:16.508+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:22:16.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:22:17.022+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:22:17.014+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:22:17.023+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:22:17.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.568 seconds
[2023-11-14T16:22:47.475+0000] {processor.py:157} INFO - Started process (PID=17155) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:22:47.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:22:47.479+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:22:47.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:22:48.592+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:22:48.575+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:22:48.595+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:22:48.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.171 seconds
[2023-11-14T16:23:19.145+0000] {processor.py:157} INFO - Started process (PID=17181) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:23:19.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:23:19.149+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:23:19.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:23:20.735+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:23:20.711+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:23:20.740+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:23:20.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.727 seconds
[2023-11-14T16:23:51.488+0000] {processor.py:157} INFO - Started process (PID=17201) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:23:51.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:23:51.491+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:23:51.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:23:52.030+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:23:52.022+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:23:52.031+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:23:52.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.581 seconds
[2023-11-14T16:24:22.417+0000] {processor.py:157} INFO - Started process (PID=17222) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:24:22.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:24:22.420+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:24:22.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:24:22.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:24:22.984+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:24:22.994+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:24:23.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.617 seconds
[2023-11-14T16:24:53.411+0000] {processor.py:157} INFO - Started process (PID=17243) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:24:53.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:24:53.415+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:24:53.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:24:53.917+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:24:53.912+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:24:53.918+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:24:53.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.536 seconds
[2023-11-14T16:25:24.411+0000] {processor.py:157} INFO - Started process (PID=17265) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:25:24.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:25:24.413+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:25:24.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:25:24.862+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:25:24.854+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:25:24.863+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:25:24.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.478 seconds
[2023-11-14T16:25:55.088+0000] {processor.py:157} INFO - Started process (PID=17295) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:25:55.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:25:55.090+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:25:55.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:25:55.717+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:25:55.706+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:25:55.718+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:25:55.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.662 seconds
[2023-11-14T16:26:26.654+0000] {processor.py:157} INFO - Started process (PID=17316) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:26:26.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:26:26.660+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:26:26.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:26:27.166+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:26:27.158+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:26:27.167+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:26:27.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.549 seconds
[2023-11-14T16:26:57.992+0000] {processor.py:157} INFO - Started process (PID=17337) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:26:57.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:26:57.994+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:26:57.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:26:58.884+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:26:58.876+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:26:58.886+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:26:58.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.947 seconds
[2023-11-14T16:27:29.426+0000] {processor.py:157} INFO - Started process (PID=17364) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:27:29.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:27:29.428+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:27:29.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:27:30.069+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:27:30.058+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:27:30.070+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:27:30.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.679 seconds
[2023-11-14T16:28:00.418+0000] {processor.py:157} INFO - Started process (PID=17384) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:28:00.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:28:00.420+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:28:00.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:28:00.894+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:28:00.885+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:28:00.895+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:28:00.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.506 seconds
[2023-11-14T16:28:31.216+0000] {processor.py:157} INFO - Started process (PID=17414) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:28:31.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:28:31.219+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:28:31.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:28:31.726+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:28:31.717+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:28:31.728+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:28:31.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.540 seconds
[2023-11-14T16:29:02.205+0000] {processor.py:157} INFO - Started process (PID=17435) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:29:02.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:29:02.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:29:02.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:29:02.637+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:29:02.628+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:29:02.638+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:29:02.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.460 seconds
[2023-11-14T16:29:32.988+0000] {processor.py:157} INFO - Started process (PID=17455) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:29:32.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:29:32.992+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:29:32.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:29:33.445+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:29:33.438+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:29:33.446+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:29:33.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.496 seconds
[2023-11-14T16:30:03.771+0000] {processor.py:157} INFO - Started process (PID=17484) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:30:03.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:30:03.773+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:30:03.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:30:04.185+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:30:04.175+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:30:04.185+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:30:04.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.439 seconds
[2023-11-14T16:30:34.576+0000] {processor.py:157} INFO - Started process (PID=17505) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:30:34.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:30:34.579+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:30:34.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:30:35.053+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:30:35.046+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:30:35.054+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:30:35.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.507 seconds
[2023-11-14T16:31:05.388+0000] {processor.py:157} INFO - Started process (PID=17531) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:31:05.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:31:05.391+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:31:05.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:31:05.871+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:31:05.865+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:31:05.872+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:31:05.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.512 seconds
[2023-11-14T16:31:36.238+0000] {processor.py:157} INFO - Started process (PID=17553) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:31:36.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:31:36.240+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:31:36.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:31:36.646+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:31:36.639+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:31:36.647+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:31:36.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.433 seconds
[2023-11-14T16:32:06.954+0000] {processor.py:157} INFO - Started process (PID=17571) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:32:06.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:32:06.956+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:32:06.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:32:07.398+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:32:07.391+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:32:07.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:32:07.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.470 seconds
[2023-11-14T16:32:37.710+0000] {processor.py:157} INFO - Started process (PID=17598) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:32:37.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:32:37.713+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:32:37.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:32:38.120+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:32:38.112+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:32:38.121+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:32:38.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.443 seconds
[2023-11-14T16:33:08.441+0000] {processor.py:157} INFO - Started process (PID=17618) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:33:08.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:33:08.443+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:33:08.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:33:08.868+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:33:08.862+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:33:08.869+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:33:08.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.457 seconds
[2023-11-14T16:33:39.224+0000] {processor.py:157} INFO - Started process (PID=17645) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:33:39.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:33:39.227+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:33:39.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:33:40.059+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:33:40.049+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:33:40.060+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:33:40.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.874 seconds
[2023-11-14T16:34:10.566+0000] {processor.py:157} INFO - Started process (PID=17663) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:34:10.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:34:10.568+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:34:10.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:34:11.006+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:34:10.997+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:34:11.007+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:34:11.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.466 seconds
[2023-11-14T16:34:41.360+0000] {processor.py:157} INFO - Started process (PID=17683) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:34:41.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:34:41.363+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:34:41.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:34:41.773+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:34:41.765+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:34:41.774+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:34:41.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.459 seconds
[2023-11-14T16:35:12.209+0000] {processor.py:157} INFO - Started process (PID=17712) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:35:12.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:35:12.216+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:35:12.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:35:12.629+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:35:12.621+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:35:12.630+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:35:12.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.453 seconds
[2023-11-14T16:35:43.011+0000] {processor.py:157} INFO - Started process (PID=17733) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:35:43.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:35:43.013+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:35:43.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:35:43.437+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:35:43.429+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:35:43.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:35:43.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.462 seconds
[2023-11-14T16:36:13.763+0000] {processor.py:157} INFO - Started process (PID=17762) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:36:13.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:36:13.765+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:36:13.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:36:14.165+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:36:14.158+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:36:14.165+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:36:14.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.426 seconds
[2023-11-14T16:36:44.506+0000] {processor.py:157} INFO - Started process (PID=17782) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:36:44.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:36:44.508+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:36:44.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:36:44.945+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:36:44.938+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:36:44.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:36:44.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.471 seconds
[2023-11-14T16:37:15.361+0000] {processor.py:157} INFO - Started process (PID=17804) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:37:15.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:37:15.364+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:37:15.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:37:15.817+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:37:15.802+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:37:15.817+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:37:15.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.483 seconds
[2023-11-14T16:37:46.151+0000] {processor.py:157} INFO - Started process (PID=17833) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:37:46.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:37:46.153+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:37:46.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:37:46.739+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:37:46.730+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:37:46.740+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:37:46.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.617 seconds
[2023-11-14T16:38:17.188+0000] {processor.py:157} INFO - Started process (PID=17853) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:38:17.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:38:17.192+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:38:17.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:38:17.785+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:38:17.779+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:38:17.786+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:38:17.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.638 seconds
[2023-11-14T16:38:48.195+0000] {processor.py:157} INFO - Started process (PID=17873) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:38:48.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:38:48.197+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:38:48.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:38:48.695+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:38:48.688+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:38:48.696+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:38:48.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.536 seconds
[2023-11-14T16:39:19.031+0000] {processor.py:157} INFO - Started process (PID=17902) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:39:19.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:39:19.034+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:39:19.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:39:19.619+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:39:19.613+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:39:19.620+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:39:19.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.620 seconds
[2023-11-14T16:39:49.754+0000] {processor.py:157} INFO - Started process (PID=17922) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:39:49.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:39:49.758+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:39:49.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:39:50.237+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:39:50.230+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:39:50.238+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:39:50.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.512 seconds
[2023-11-14T16:40:20.651+0000] {processor.py:157} INFO - Started process (PID=17942) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:40:20.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:40:20.656+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:40:20.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:40:21.633+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:40:21.620+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:40:21.637+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:40:21.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.034 seconds
[2023-11-14T16:40:52.100+0000] {processor.py:157} INFO - Started process (PID=17971) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:40:52.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:40:52.104+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:40:52.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:40:52.790+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:40:52.780+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:40:52.791+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:40:52.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.743 seconds
[2023-11-14T16:41:23.341+0000] {processor.py:157} INFO - Started process (PID=17991) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:41:23.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:41:23.351+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:41:23.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:41:24.264+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:41:24.256+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:41:24.265+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:41:24.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.977 seconds
[2023-11-14T16:41:54.653+0000] {processor.py:157} INFO - Started process (PID=18012) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:41:54.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:41:54.656+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:41:54.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:41:55.170+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:41:55.163+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:41:55.171+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:41:55.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.544 seconds
[2023-11-14T16:42:25.497+0000] {processor.py:157} INFO - Started process (PID=18042) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:42:25.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:42:25.500+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:42:25.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:42:26.068+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:42:26.062+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:42:26.070+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:42:26.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.601 seconds
[2023-11-14T16:42:56.341+0000] {processor.py:157} INFO - Started process (PID=18062) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:42:56.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:42:56.356+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:42:56.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:42:57.410+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:42:57.403+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:42:57.411+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:42:57.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.129 seconds
[2023-11-14T16:43:27.555+0000] {processor.py:157} INFO - Started process (PID=18082) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:43:27.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:43:27.557+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:43:27.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:43:28.076+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:43:28.067+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:43:28.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:43:28.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.552 seconds
[2023-11-14T16:43:58.607+0000] {processor.py:157} INFO - Started process (PID=18101) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:43:58.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:43:58.610+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:43:58.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:43:59.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:43:59.059+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:43:59.067+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:43:59.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.608 seconds
[2023-11-14T16:44:29.557+0000] {processor.py:157} INFO - Started process (PID=18129) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:44:29.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:44:29.561+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:44:29.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:44:30.205+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:44:30.188+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:44:30.208+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:44:30.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.691 seconds
[2023-11-14T16:45:00.496+0000] {processor.py:157} INFO - Started process (PID=18150) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:45:00.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:45:00.498+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:45:00.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:45:01.393+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:45:01.380+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:45:01.394+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:45:01.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.939 seconds
[2023-11-14T16:45:32.287+0000] {processor.py:157} INFO - Started process (PID=18170) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:45:32.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:45:32.289+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:45:32.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:45:32.873+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:45:32.862+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:45:32.874+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:45:32.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.625 seconds
[2023-11-14T16:46:03.255+0000] {processor.py:157} INFO - Started process (PID=18198) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:46:03.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:46:03.258+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:46:03.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:46:03.704+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:46:03.698+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:46:03.706+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:46:03.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.480 seconds
[2023-11-14T16:46:34.048+0000] {processor.py:157} INFO - Started process (PID=18219) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:46:34.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:46:34.050+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:46:34.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:46:34.455+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:46:34.449+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:46:34.456+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:46:34.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.436 seconds
[2023-11-14T16:47:04.786+0000] {processor.py:157} INFO - Started process (PID=18239) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:47:04.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:47:04.788+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:47:04.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:47:05.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:47:05.218+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:47:05.226+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:47:05.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.467 seconds
[2023-11-14T16:47:35.701+0000] {processor.py:157} INFO - Started process (PID=18259) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:47:35.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:47:35.703+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:47:35.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:47:36.140+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:47:36.132+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:47:36.141+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:47:36.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.467 seconds
[2023-11-14T16:48:06.469+0000] {processor.py:157} INFO - Started process (PID=18288) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:48:06.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:48:06.471+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:48:06.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:48:06.904+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:48:06.898+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:48:06.905+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:48:06.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.464 seconds
[2023-11-14T16:48:37.728+0000] {processor.py:157} INFO - Started process (PID=18309) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:48:37.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:48:37.732+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:48:37.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:48:38.186+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:48:38.179+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:48:38.187+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:48:38.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.491 seconds
[2023-11-14T16:49:08.805+0000] {processor.py:157} INFO - Started process (PID=18329) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:49:08.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:49:08.813+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:49:08.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:49:09.501+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:49:09.493+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:49:09.503+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:49:09.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.750 seconds
[2023-11-14T16:49:39.844+0000] {processor.py:157} INFO - Started process (PID=18359) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:49:39.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:49:39.846+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:49:39.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:49:40.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:49:40.412+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:49:40.422+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:49:40.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.610 seconds
[2023-11-14T16:50:10.763+0000] {processor.py:157} INFO - Started process (PID=18379) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:50:10.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:50:10.766+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:50:10.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:50:11.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:50:11.429+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:50:11.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:50:11.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.706 seconds
[2023-11-14T16:50:43.234+0000] {processor.py:157} INFO - Started process (PID=18408) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:50:43.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:50:43.268+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:50:43.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:50:46.530+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:50:46.460+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:50:46.550+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:50:46.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.482 seconds
[2023-11-14T16:51:17.267+0000] {processor.py:157} INFO - Started process (PID=18429) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:51:17.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:51:17.275+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:51:17.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:51:18.711+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:51:18.684+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:51:18.725+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:51:18.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.566 seconds
[2023-11-14T16:51:49.409+0000] {processor.py:157} INFO - Started process (PID=18451) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:51:49.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:51:49.412+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:51:49.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:51:50.189+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:51:50.179+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:51:50.189+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:51:50.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.817 seconds
[2023-11-14T16:52:20.885+0000] {processor.py:157} INFO - Started process (PID=18473) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:52:20.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:52:20.888+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:52:20.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:52:21.959+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:52:21.945+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:52:21.962+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:52:22.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.142 seconds
[2023-11-14T16:52:52.538+0000] {processor.py:157} INFO - Started process (PID=18493) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:52:52.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:52:52.543+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:52:52.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:52:53.250+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:52:53.239+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:52:53.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:52:53.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.744 seconds
[2023-11-14T16:53:23.671+0000] {processor.py:157} INFO - Started process (PID=18514) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:53:23.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:53:23.674+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:53:23.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:53:24.069+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:53:24.062+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:53:24.070+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:53:24.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.423 seconds
[2023-11-14T16:53:54.912+0000] {processor.py:157} INFO - Started process (PID=18542) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:53:54.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:53:54.915+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:53:54.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:53:55.407+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:53:55.399+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:53:55.408+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:53:55.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.523 seconds
[2023-11-14T16:54:25.894+0000] {processor.py:157} INFO - Started process (PID=18563) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:54:25.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:54:25.899+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:54:25.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:54:26.689+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:54:26.681+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:54:26.690+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:54:26.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.836 seconds
[2023-11-14T16:54:57.188+0000] {processor.py:157} INFO - Started process (PID=18584) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:54:57.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:54:57.190+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:54:57.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:54:57.657+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:54:57.649+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:54:57.659+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:54:57.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.532 seconds
[2023-11-14T16:55:27.959+0000] {processor.py:157} INFO - Started process (PID=18606) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:55:27.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:55:27.962+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:55:27.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:55:28.454+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:55:28.444+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:55:28.455+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:55:28.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.529 seconds
[2023-11-14T16:55:58.771+0000] {processor.py:157} INFO - Started process (PID=18635) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:55:58.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:55:58.773+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:55:58.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:55:59.336+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:55:59.328+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:55:59.337+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:55:59.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.597 seconds
[2023-11-14T16:56:29.721+0000] {processor.py:157} INFO - Started process (PID=18657) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:56:29.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:56:29.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:56:29.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:56:30.440+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:56:30.429+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:56:30.441+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:56:30.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.765 seconds
[2023-11-14T16:57:00.819+0000] {processor.py:157} INFO - Started process (PID=18678) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:57:00.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:57:00.821+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:57:00.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:57:01.277+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:57:01.269+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:57:01.277+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:57:01.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.486 seconds
[2023-11-14T16:57:31.624+0000] {processor.py:157} INFO - Started process (PID=18707) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:57:31.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:57:31.627+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:57:31.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:57:32.288+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:57:32.279+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:57:32.290+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:57:32.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.699 seconds
[2023-11-14T16:58:02.774+0000] {processor.py:157} INFO - Started process (PID=18728) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:58:02.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:58:02.778+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:58:02.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:58:03.456+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:58:03.447+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:58:03.456+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:58:03.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.719 seconds
[2023-11-14T16:58:33.831+0000] {processor.py:157} INFO - Started process (PID=18748) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:58:33.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:58:33.841+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:58:33.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:58:34.323+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:58:34.301+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:58:34.325+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:58:34.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.541 seconds
[2023-11-14T16:59:04.948+0000] {processor.py:157} INFO - Started process (PID=18776) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:59:04.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:59:04.953+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:59:04.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:59:05.720+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:59:05.711+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:59:05.746+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:59:05.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.842 seconds
[2023-11-14T16:59:36.345+0000] {processor.py:157} INFO - Started process (PID=18796) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:59:36.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T16:59:36.400+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:59:36.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:59:37.916+0000] {logging_mixin.py:151} INFO - [2023-11-14T16:59:37.900+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T16:59:37.917+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T16:59:37.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.651 seconds
[2023-11-14T17:00:08.796+0000] {processor.py:157} INFO - Started process (PID=18816) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:00:08.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:00:08.800+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:00:08.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:00:09.648+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:00:09.637+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:00:09.649+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:00:09.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.947 seconds
[2023-11-14T17:00:40.709+0000] {processor.py:157} INFO - Started process (PID=18837) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:00:40.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:00:40.725+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:00:40.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:00:41.422+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:00:41.411+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:00:41.423+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:00:41.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.853 seconds
[2023-11-14T17:01:12.595+0000] {processor.py:157} INFO - Started process (PID=18858) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:01:12.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:01:12.610+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:01:12.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:01:14.017+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:01:14.006+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:01:14.018+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:01:14.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.502 seconds
[2023-11-14T17:01:44.165+0000] {processor.py:157} INFO - Started process (PID=18878) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:01:44.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:01:44.169+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:01:44.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:01:45.102+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:01:45.092+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:01:45.103+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:01:45.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.047 seconds
[2023-11-14T17:02:15.417+0000] {processor.py:157} INFO - Started process (PID=18898) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:02:15.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:02:15.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:02:15.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:02:16.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:02:16.141+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:02:16.156+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:02:16.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.839 seconds
[2023-11-14T17:02:46.823+0000] {processor.py:157} INFO - Started process (PID=18919) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:02:46.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:02:46.827+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:02:46.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:02:47.699+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:02:47.687+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:02:47.717+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:02:47.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.021 seconds
[2023-11-14T17:03:18.404+0000] {processor.py:157} INFO - Started process (PID=18939) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:03:18.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:03:18.406+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:03:18.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:03:19.205+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:03:19.197+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:03:19.206+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:03:19.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.849 seconds
[2023-11-14T17:03:50.353+0000] {processor.py:157} INFO - Started process (PID=18960) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:03:50.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:03:50.362+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:03:50.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:03:51.164+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:03:51.099+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:03:51.165+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:03:51.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.851 seconds
[2023-11-14T17:04:21.796+0000] {processor.py:157} INFO - Started process (PID=18981) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:04:21.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:04:21.804+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:04:21.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:04:22.758+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:04:22.747+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:04:22.759+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:04:22.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.061 seconds
[2023-11-14T17:04:53.514+0000] {processor.py:157} INFO - Started process (PID=19001) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:04:53.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:04:53.540+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:04:53.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:04:54.424+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:04:54.411+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:04:54.425+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:04:54.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.966 seconds
[2023-11-14T17:05:25.208+0000] {processor.py:157} INFO - Started process (PID=19023) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:05:25.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:05:25.213+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:05:25.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:05:26.085+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:05:26.069+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:05:26.087+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:05:26.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.929 seconds
[2023-11-14T17:05:56.824+0000] {processor.py:157} INFO - Started process (PID=19043) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:05:56.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:05:56.828+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:05:56.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:05:58.025+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:05:58.012+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:05:58.026+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:05:58.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.239 seconds
[2023-11-14T17:06:28.204+0000] {processor.py:157} INFO - Started process (PID=19063) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:06:28.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:06:28.208+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:06:28.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:06:29.273+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:06:29.259+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:06:29.275+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:06:29.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.129 seconds
[2023-11-14T17:06:59.515+0000] {processor.py:157} INFO - Started process (PID=19084) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:06:59.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:06:59.519+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:06:59.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:07:00.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:07:00.324+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:07:00.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:07:00.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.287 seconds
[2023-11-14T17:07:30.908+0000] {processor.py:157} INFO - Started process (PID=19103) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:07:30.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:07:30.912+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:07:30.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:07:31.824+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:07:31.816+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:07:31.825+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:07:31.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.958 seconds
[2023-11-14T17:08:02.062+0000] {processor.py:157} INFO - Started process (PID=19122) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:08:02.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:08:02.083+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:08:02.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:08:03.396+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:08:03.383+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:08:03.397+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:08:03.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.452 seconds
[2023-11-14T17:08:33.875+0000] {processor.py:157} INFO - Started process (PID=19135) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:08:33.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:08:33.878+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:08:33.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:08:34.828+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:08:34.817+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:08:34.830+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:08:34.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.016 seconds
[2023-11-14T17:09:05.417+0000] {processor.py:157} INFO - Started process (PID=19155) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:09:05.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:09:05.420+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:09:05.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:09:06.436+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:09:06.401+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:09:06.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:09:06.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.060 seconds
[2023-11-14T17:09:36.922+0000] {processor.py:157} INFO - Started process (PID=19175) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:09:36.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:09:36.926+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:09:36.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:09:38.098+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:09:38.066+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:09:38.099+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:09:38.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.249 seconds
[2023-11-14T17:10:08.403+0000] {processor.py:157} INFO - Started process (PID=19195) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:10:08.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:10:08.406+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:10:08.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:10:09.522+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:10:09.513+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:10:09.523+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:10:09.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.203 seconds
[2023-11-14T17:10:40.174+0000] {processor.py:157} INFO - Started process (PID=19215) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:10:40.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:10:40.183+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:10:40.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:10:41.510+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:10:41.449+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:10:41.511+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:10:41.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.380 seconds
[2023-11-14T17:11:11.945+0000] {processor.py:157} INFO - Started process (PID=19245) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:11:11.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:11:11.948+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:11:11.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:11:12.916+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:11:12.905+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:11:12.917+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:11:13.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.064 seconds
[2023-11-14T17:11:43.499+0000] {processor.py:157} INFO - Started process (PID=19265) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:11:43.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:11:43.504+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:11:43.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:11:44.369+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:11:44.360+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:11:44.369+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:11:44.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.913 seconds
[2023-11-14T17:12:15.007+0000] {processor.py:157} INFO - Started process (PID=19286) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:12:15.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:12:15.013+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:12:15.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:12:16.181+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:12:16.167+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:12:16.183+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:12:16.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.271 seconds
[2023-11-14T17:12:46.899+0000] {processor.py:157} INFO - Started process (PID=19305) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:12:46.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:12:46.909+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:12:46.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:12:48.259+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:12:48.247+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:12:48.260+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:12:48.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.459 seconds
[2023-11-14T17:13:18.848+0000] {processor.py:157} INFO - Started process (PID=19326) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:13:18.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:13:18.861+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:13:18.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:13:20.332+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:13:20.312+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:13:20.334+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:13:20.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.554 seconds
[2023-11-14T17:13:50.828+0000] {processor.py:157} INFO - Started process (PID=19346) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:13:50.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:13:50.832+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:13:50.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:13:51.700+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:13:51.688+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:13:51.701+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:13:51.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.907 seconds
[2023-11-14T17:14:22.213+0000] {processor.py:157} INFO - Started process (PID=19366) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:14:22.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:14:22.220+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:14:22.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:14:23.096+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:14:23.085+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:14:23.097+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:14:23.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.933 seconds
[2023-11-14T17:14:53.805+0000] {processor.py:157} INFO - Started process (PID=19387) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:14:53.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:14:53.812+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:14:53.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:14:55.527+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:14:55.493+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:14:55.531+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:14:55.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.890 seconds
[2023-11-14T17:15:26.141+0000] {processor.py:157} INFO - Started process (PID=19408) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:15:26.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:15:26.149+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:15:26.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:15:27.712+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:15:27.694+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:15:27.714+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:15:27.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.663 seconds
[2023-11-14T17:15:58.387+0000] {processor.py:157} INFO - Started process (PID=19429) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:15:58.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:15:58.394+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:15:58.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:16:00.856+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:16:00.640+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:16:00.861+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:16:01.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.685 seconds
[2023-11-14T17:16:31.656+0000] {processor.py:157} INFO - Started process (PID=19450) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:16:31.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:16:31.677+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:16:31.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:16:32.668+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:16:32.656+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:16:32.669+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:16:32.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.062 seconds
[2023-11-14T17:17:02.986+0000] {processor.py:157} INFO - Started process (PID=19471) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:17:02.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:17:02.990+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:17:02.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:17:04.175+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:17:04.165+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:17:04.176+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:17:04.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.228 seconds
[2023-11-14T17:17:34.514+0000] {processor.py:157} INFO - Started process (PID=19491) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:17:34.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:17:34.526+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:17:34.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:17:35.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:17:35.698+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:17:35.712+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:17:35.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.314 seconds
[2023-11-14T17:18:06.321+0000] {processor.py:157} INFO - Started process (PID=19510) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:18:06.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:18:06.324+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:18:06.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:18:07.498+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:18:07.487+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:18:07.499+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:18:07.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.273 seconds
[2023-11-14T17:18:37.815+0000] {processor.py:157} INFO - Started process (PID=19530) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:18:37.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:18:37.827+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:18:37.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:18:38.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:18:38.783+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:18:38.798+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:18:38.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.044 seconds
[2023-11-14T17:19:09.004+0000] {processor.py:157} INFO - Started process (PID=19551) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:19:09.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:19:09.008+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:19:09.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:19:10.263+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:19:10.248+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:19:10.265+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:19:10.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.331 seconds
[2023-11-14T17:19:40.907+0000] {processor.py:157} INFO - Started process (PID=19572) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:19:40.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:19:40.911+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:19:40.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:19:42.180+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:19:42.147+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:19:42.193+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:19:42.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.387 seconds
[2023-11-14T17:20:12.521+0000] {processor.py:157} INFO - Started process (PID=19599) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:20:12.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:20:12.525+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:20:12.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:20:14.509+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:20:14.475+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:20:14.510+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:20:14.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.047 seconds
[2023-11-14T17:20:45.184+0000] {processor.py:157} INFO - Started process (PID=19620) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:20:45.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:20:45.188+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:20:45.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:20:46.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:20:46.292+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:20:46.307+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:20:46.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.165 seconds
[2023-11-14T17:21:16.961+0000] {processor.py:157} INFO - Started process (PID=19640) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:21:16.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:21:16.965+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:21:16.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:21:18.594+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:21:18.585+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:21:18.595+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:21:18.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.724 seconds
[2023-11-14T17:21:49.132+0000] {processor.py:157} INFO - Started process (PID=19659) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:21:49.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:21:49.136+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:21:49.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:21:50.239+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:21:50.229+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:21:50.240+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:21:50.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.200 seconds
[2023-11-14T17:22:20.905+0000] {processor.py:157} INFO - Started process (PID=19679) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:22:20.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:22:20.913+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:22:20.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:22:22.863+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:22:22.836+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:22:22.866+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:22:22.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.074 seconds
[2023-11-14T17:22:53.151+0000] {processor.py:157} INFO - Started process (PID=19699) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:22:53.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:22:53.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:22:53.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:22:54.865+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:22:54.852+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:22:54.866+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:22:54.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.766 seconds
[2023-11-14T17:23:25.150+0000] {processor.py:157} INFO - Started process (PID=19711) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:23:25.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:23:25.153+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:23:25.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:23:26.062+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:23:26.049+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:23:26.063+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:23:26.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.959 seconds
[2023-11-14T17:23:57.094+0000] {processor.py:157} INFO - Started process (PID=19731) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:23:57.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:23:57.099+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:23:57.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:23:58.474+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:23:58.462+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:23:58.476+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:23:58.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.438 seconds
[2023-11-14T17:24:29.199+0000] {processor.py:157} INFO - Started process (PID=19750) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:24:29.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:24:29.208+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:24:29.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:24:30.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:24:30.555+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:24:30.566+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:24:30.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.419 seconds
[2023-11-14T17:25:00.896+0000] {processor.py:157} INFO - Started process (PID=19770) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:25:00.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:25:00.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:25:00.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:25:02.212+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:25:02.203+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:25:02.213+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:25:02.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.362 seconds
[2023-11-14T17:25:32.463+0000] {processor.py:157} INFO - Started process (PID=19792) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:25:32.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:25:32.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:25:32.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:25:33.401+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:25:33.390+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:25:33.403+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:25:33.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.002 seconds
[2023-11-14T17:26:03.762+0000] {processor.py:157} INFO - Started process (PID=19812) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:26:03.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:26:03.768+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:26:03.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:26:06.780+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:26:06.762+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:26:06.784+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:26:06.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.217 seconds
[2023-11-14T17:26:37.707+0000] {processor.py:157} INFO - Started process (PID=19832) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:26:37.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:26:37.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:26:37.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:26:38.974+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:26:38.959+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:26:38.975+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:26:39.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.302 seconds
[2023-11-14T17:27:09.617+0000] {processor.py:157} INFO - Started process (PID=19852) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:27:09.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:27:09.622+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:27:09.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:27:11.061+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:27:11.050+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:27:11.063+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:27:11.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.492 seconds
[2023-11-14T17:27:41.852+0000] {processor.py:157} INFO - Started process (PID=19873) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:27:41.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:27:41.857+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:27:41.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:27:42.954+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:27:42.946+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:27:42.954+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:27:43.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.160 seconds
[2023-11-14T17:28:13.281+0000] {processor.py:157} INFO - Started process (PID=19899) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:28:13.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:28:13.284+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:28:13.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:28:14.651+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:28:14.641+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:28:14.654+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:28:14.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.416 seconds
[2023-11-14T17:28:45.162+0000] {processor.py:157} INFO - Started process (PID=19919) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:28:45.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:28:45.168+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:28:45.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:28:46.384+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:28:46.374+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:28:46.385+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:28:46.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.261 seconds
[2023-11-14T17:29:17.167+0000] {processor.py:157} INFO - Started process (PID=19939) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:29:17.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:29:17.176+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:29:17.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:29:18.449+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:29:18.438+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:29:18.451+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:29:18.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.327 seconds
[2023-11-14T17:29:49.072+0000] {processor.py:157} INFO - Started process (PID=19958) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:29:49.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:29:49.085+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:29:49.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:29:50.165+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:29:50.156+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:29:50.166+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:29:50.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.181 seconds
[2023-11-14T17:30:20.977+0000] {processor.py:157} INFO - Started process (PID=19978) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:30:20.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:30:20.989+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:30:20.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:30:22.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:30:22.178+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:30:22.196+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:30:22.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.313 seconds
[2023-11-14T17:30:52.808+0000] {processor.py:157} INFO - Started process (PID=19999) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:30:52.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:30:52.812+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:30:52.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:30:53.733+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:30:53.723+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:30:53.734+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:30:53.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.962 seconds
[2023-11-14T17:31:24.075+0000] {processor.py:157} INFO - Started process (PID=20021) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:31:24.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:31:24.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:31:24.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:31:25.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:31:25.215+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:31:25.226+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:31:25.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.223 seconds
[2023-11-14T17:31:55.696+0000] {processor.py:157} INFO - Started process (PID=20041) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:31:55.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:31:55.699+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:31:55.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:31:56.711+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:31:56.700+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:31:56.712+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:31:56.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.058 seconds
[2023-11-14T17:32:27.348+0000] {processor.py:157} INFO - Started process (PID=20060) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:32:27.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:32:27.351+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:32:27.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:32:28.473+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:32:28.464+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:32:28.473+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:32:28.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.168 seconds
[2023-11-14T17:32:59.353+0000] {processor.py:157} INFO - Started process (PID=20072) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:32:59.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:32:59.362+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:32:59.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:33:04.932+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:33:04.877+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:33:04.937+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:33:05.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 5.784 seconds
[2023-11-14T17:33:27.804+0000] {processor.py:157} INFO - Started process (PID=20090) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:33:27.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:33:27.867+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:33:27.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:33:39.535+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:33:39.480+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:33:39.546+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:33:39.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 12.017 seconds
[2023-11-14T17:34:02.055+0000] {processor.py:157} INFO - Started process (PID=20100) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:34:02.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:34:02.201+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:34:02.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:34:19.935+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:34:16.290+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:34:20.327+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:34:28.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 26.584 seconds
[2023-11-14T17:35:11.045+0000] {processor.py:157} INFO - Started process (PID=20126) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:35:11.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:35:11.409+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:35:11.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:35:50.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:35:50.793+0000] {timeout.py:68} ERROR - Process timed out, PID: 20126
[2023-11-14T17:35:50.833+0000] {logging_mixin.py:151} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7fa4c93b5310>
[2023-11-14T17:35:50.835+0000] {logging_mixin.py:151} WARNING - Traceback (most recent call last):
[2023-11-14T17:35:50.836+0000] {logging_mixin.py:151} WARNING -   File "/usr/local/lib/python3.8/weakref.py", line 345, in remove
[2023-11-14T17:35:50.837+0000] {logging_mixin.py:151} WARNING -     def remove(k, selfref=ref(self)):
[2023-11-14T17:35:50.838+0000] {logging_mixin.py:151} WARNING -   File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2023-11-14T17:35:50.839+0000] {logging_mixin.py:151} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2023-11-14T17:35:50.853+0000] {logging_mixin.py:151} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/Dag_postgres.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.1/best-practices.html#reducing-dag-complexity, PID: 20126
[2023-11-14T17:35:53.811+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:35:53.759+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:35:53.833+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:35:53.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 43.832 seconds
[2023-11-14T17:36:25.056+0000] {processor.py:157} INFO - Started process (PID=20162) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:36:25.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:36:25.061+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:36:25.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:36:27.383+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:36:27.372+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 382, in <module>
    create_time_csv = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'download_location_data' has already been added to the DAG
[2023-11-14T17:36:27.384+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:36:27.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.369 seconds
[2023-11-14T17:36:57.113+0000] {processor.py:157} INFO - Started process (PID=20181) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:36:57.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:36:57.162+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:36:57.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:01.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:02.430+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:02.428+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T17:37:02.435+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:02.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:37:02.562+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:02.559+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:37:02.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 5.699 seconds
[2023-11-14T17:37:06.126+0000] {processor.py:157} INFO - Started process (PID=20186) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:06.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:37:06.133+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:06.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:09.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:09.458+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:09.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:37:09.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:09.546+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:37:09.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.525 seconds
[2023-11-14T17:37:40.253+0000] {processor.py:157} INFO - Started process (PID=20211) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:40.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:37:40.266+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:40.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:43.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:37:44.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:44.742+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T17:37:44.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:44.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:37:44.859+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:37:44.858+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:37:44.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.751 seconds
[2023-11-14T17:38:15.897+0000] {processor.py:157} INFO - Started process (PID=20223) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:38:15.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:38:15.905+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:38:15.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:38:18.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:38:18.446+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:38:18.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:38:18.531+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:38:18.530+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:38:18.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.712 seconds
[2023-11-14T17:38:49.821+0000] {processor.py:157} INFO - Started process (PID=20242) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:38:49.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:38:49.909+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:38:49.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:39:11.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:39:11.584+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:39:11.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:39:11.826+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:39:11.825+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:39:11.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 22.505 seconds
[2023-11-14T17:39:43.163+0000] {processor.py:157} INFO - Started process (PID=20273) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:39:43.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:39:43.200+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:39:43.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:39:55.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:39:56.142+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:39:56.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:39:57.426+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:39:57.425+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:39:57.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 14.866 seconds
[2023-11-14T17:40:29.868+0000] {processor.py:157} INFO - Started process (PID=20294) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:40:29.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:40:29.922+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:40:29.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:40:38.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:40:38.292+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:40:38.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:40:38.400+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:40:38.399+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:40:38.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 8.946 seconds
[2023-11-14T17:41:08.933+0000] {processor.py:157} INFO - Started process (PID=20314) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:08.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:41:08.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:08.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:10.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:10.688+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:10.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:41:10.738+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:10.738+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:41:10.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.887 seconds
[2023-11-14T17:41:28.213+0000] {processor.py:157} INFO - Started process (PID=20327) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:28.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:41:28.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:28.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:30.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:31.164+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:31.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:41:31.345+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:31.344+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:41:31.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.294 seconds
[2023-11-14T17:41:34.572+0000] {processor.py:157} INFO - Started process (PID=20339) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:34.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:41:34.576+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:34.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:36.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:41:36.058+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:36.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:41:36.102+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:41:36.102+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:41:36.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.580 seconds
[2023-11-14T17:42:06.400+0000] {processor.py:157} INFO - Started process (PID=20358) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:42:06.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:42:06.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:42:06.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:42:07.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:42:07.706+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:42:07.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:42:07.743+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:42:07.742+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:42:07.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.393 seconds
[2023-11-14T17:42:38.029+0000] {processor.py:157} INFO - Started process (PID=20380) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:42:38.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:42:38.032+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:42:38.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:42:38.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:42:38.894+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:42:38.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:42:38.937+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:42:38.937+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:42:38.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.946 seconds
[2023-11-14T17:43:09.935+0000] {processor.py:157} INFO - Started process (PID=20399) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:09.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:43:09.944+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:09.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:11.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:11.045+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:11.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:43:11.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:11.082+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:43:11.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.210 seconds
[2023-11-14T17:43:41.919+0000] {processor.py:157} INFO - Started process (PID=20418) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:41.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:43:41.950+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:41.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:43.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:43.503+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:43.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:43:43.553+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:43.552+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:43:43.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.707 seconds
[2023-11-14T17:43:46.224+0000] {processor.py:157} INFO - Started process (PID=20420) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:46.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:43:46.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:46.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:46.275+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:43:46.270+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:43:46.277+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:43:46.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.120 seconds
[2023-11-14T17:44:16.499+0000] {processor.py:157} INFO - Started process (PID=20442) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:44:16.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:44:16.502+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:44:16.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:44:16.540+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:44:16.538+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:44:16.542+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:44:16.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.102 seconds
[2023-11-14T17:44:47.214+0000] {processor.py:157} INFO - Started process (PID=20461) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:44:47.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:44:47.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:44:47.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:44:47.316+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:44:47.312+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:44:47.319+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:44:47.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.200 seconds
[2023-11-14T17:45:17.874+0000] {processor.py:157} INFO - Started process (PID=20480) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:45:17.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:45:17.876+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:45:17.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:45:17.916+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:45:17.914+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:45:17.917+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:45:17.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.094 seconds
[2023-11-14T17:45:48.662+0000] {processor.py:157} INFO - Started process (PID=20499) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:45:48.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:45:48.665+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:45:48.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:45:48.702+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:45:48.700+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:45:48.703+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:45:48.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.091 seconds
[2023-11-14T17:46:19.194+0000] {processor.py:157} INFO - Started process (PID=20518) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:46:19.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:46:19.198+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:46:19.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:46:19.262+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:46:19.261+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:46:19.264+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:46:19.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.115 seconds
[2023-11-14T17:46:49.863+0000] {processor.py:157} INFO - Started process (PID=20536) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:46:49.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:46:49.867+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:46:49.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:46:49.928+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:46:49.924+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:46:49.930+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:46:50.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.171 seconds
[2023-11-14T17:47:20.587+0000] {processor.py:157} INFO - Started process (PID=20556) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:47:20.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:47:20.600+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:47:20.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:47:20.696+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:47:20.688+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 56
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:47:20.699+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:47:20.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.291 seconds
[2023-11-14T17:47:37.927+0000] {processor.py:157} INFO - Started process (PID=20566) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:47:38.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:47:38.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:47:38.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:47:38.509+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:47:38.503+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:47:38.519+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:47:38.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.836 seconds
[2023-11-14T17:48:09.769+0000] {processor.py:157} INFO - Started process (PID=20584) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:48:09.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:48:09.776+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:48:09.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:48:09.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:48:09.851+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:48:09.858+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:48:09.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.167 seconds
[2023-11-14T17:48:40.414+0000] {processor.py:157} INFO - Started process (PID=20603) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:48:40.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:48:40.427+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:48:40.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:48:40.508+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:48:40.504+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:48:40.509+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:48:40.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.176 seconds
[2023-11-14T17:49:10.748+0000] {processor.py:157} INFO - Started process (PID=20623) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:49:10.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:49:10.761+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:49:10.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:49:11.128+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:49:11.117+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:49:11.132+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:49:11.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.516 seconds
[2023-11-14T17:49:41.693+0000] {processor.py:157} INFO - Started process (PID=20634) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:49:41.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:49:41.716+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:49:41.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:49:41.801+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:49:41.798+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:49:41.803+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:49:42.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.483 seconds
[2023-11-14T17:50:12.723+0000] {processor.py:157} INFO - Started process (PID=20655) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:50:12.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:50:12.727+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:50:12.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:50:12.781+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:50:12.779+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:50:12.783+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:50:12.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.149 seconds
[2023-11-14T17:50:43.652+0000] {processor.py:157} INFO - Started process (PID=20676) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:50:43.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:50:43.666+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:50:43.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:50:43.762+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:50:43.759+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:50:43.766+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:50:43.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.197 seconds
[2023-11-14T17:51:14.439+0000] {processor.py:157} INFO - Started process (PID=20696) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:14.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:51:14.444+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:14.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:14.494+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:14.491+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:51:14.496+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:14.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.114 seconds
[2023-11-14T17:51:40.496+0000] {processor.py:157} INFO - Started process (PID=20707) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:40.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:51:40.687+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:40.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:41.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:41.990+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 69
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:51:41.997+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:42.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.994 seconds
[2023-11-14T17:51:47.273+0000] {processor.py:157} INFO - Started process (PID=20715) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:47.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:51:47.369+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:47.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:49.137+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:49.133+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle datasets download -d andradaolteanu/country-mapping-iso-continent-region
           ^
SyntaxError: invalid syntax
[2023-11-14T17:51:49.150+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:49.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.044 seconds
[2023-11-14T17:51:53.575+0000] {processor.py:157} INFO - Started process (PID=20717) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:53.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:51:53.589+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:53.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:53.708+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:53.698+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 58
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T17:51:53.713+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:53.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.345 seconds
[2023-11-14T17:51:55.425+0000] {processor.py:157} INFO - Started process (PID=20718) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:55.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:51:55.430+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:55.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:55.471+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:55.469+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    kaggle_api_key = "your_api_key"
    ^
IndentationError: expected an indented block
[2023-11-14T17:51:55.473+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:55.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.119 seconds
[2023-11-14T17:51:58.537+0000] {processor.py:157} INFO - Started process (PID=20721) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:58.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:51:58.543+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:58.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:58.606+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:51:58.604+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 60
    subprocess.run(['kaggle', 'config', 'set', '-n', 'api_key', '-v', kaggle_api_key])
    ^
IndentationError: expected an indented block
[2023-11-14T17:51:58.608+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:51:58.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.173 seconds
[2023-11-14T17:52:00.491+0000] {processor.py:157} INFO - Started process (PID=20722) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:00.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:52:00.520+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:00.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:02.427+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:02.420+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 60, in <module>
    subprocess.run(['kaggle', 'config', 'set', '-n', 'api_key', '-v', kaggle_api_key])
NameError: name 'kaggle_api_key' is not defined
[2023-11-14T17:52:02.428+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:02.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.993 seconds
[2023-11-14T17:52:05.421+0000] {processor.py:157} INFO - Started process (PID=20724) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:05.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:52:05.426+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:05.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:08.479+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:08.335+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 60, in <module>
    subprocess.run(['kaggle', 'config', 'set', '-n', 'api_key', '-v', kaggle_api_key])
NameError: name 'kaggle_api_key' is not defined
[2023-11-14T17:52:08.506+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:08.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.173 seconds
[2023-11-14T17:52:12.703+0000] {processor.py:157} INFO - Started process (PID=20735) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:12.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:52:12.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:12.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:14.956+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:14.925+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 66, in <module>
    subprocess.run(['kaggle', 'datasets', 'download', '-d', dataset_name, '--unzip'])
  File "/usr/local/lib/python3.8/subprocess.py", line 493, in run
    with Popen(*popenargs, **kwargs) as process:
  File "/usr/local/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1720, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
PermissionError: [Errno 13] Permission denied: 'kaggle'
[2023-11-14T17:52:14.958+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:14.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.304 seconds
[2023-11-14T17:52:18.039+0000] {processor.py:157} INFO - Started process (PID=20738) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:18.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:52:18.045+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:18.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:19.670+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:19.663+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 66, in <module>
    subprocess.run(['kaggle', 'datasets', 'download', '-d', dataset_name, '--unzip'])
NameError: name 'dataset_name' is not defined
[2023-11-14T17:52:19.672+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:19.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.667 seconds
[2023-11-14T17:52:21.437+0000] {processor.py:157} INFO - Started process (PID=20740) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:21.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:52:21.443+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:21.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:22.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:23.339+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:23.337+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T17:52:23.341+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:23.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:52:23.407+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:23.406+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:52:23.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.068 seconds
[2023-11-14T17:52:39.449+0000] {processor.py:157} INFO - Started process (PID=20752) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:39.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:52:39.456+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:39.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:41.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:52:41.155+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:41.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:52:41.206+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:52:41.206+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:52:41.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.817 seconds
[2023-11-14T17:53:11.415+0000] {processor.py:157} INFO - Started process (PID=20772) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:53:11.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:53:11.420+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:53:11.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:53:12.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:53:12.861+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:53:12.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:53:12.953+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:53:12.952+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:53:13.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.705 seconds
[2023-11-14T17:53:43.301+0000] {processor.py:157} INFO - Started process (PID=20792) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:53:43.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:53:43.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:53:43.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:53:44.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:53:44.818+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:53:44.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:53:44.899+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:53:44.897+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:53:44.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.674 seconds
[2023-11-14T17:54:15.259+0000] {processor.py:157} INFO - Started process (PID=20812) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:54:15.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:54:15.262+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:54:15.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:54:16.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:54:16.577+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:54:16.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:54:16.637+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:54:16.637+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:54:16.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.484 seconds
[2023-11-14T17:54:46.886+0000] {processor.py:157} INFO - Started process (PID=20832) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:54:46.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:54:46.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:54:46.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:54:48.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:54:48.222+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:54:48.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:54:48.282+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:54:48.281+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:54:48.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.452 seconds
[2023-11-14T17:55:18.549+0000] {processor.py:157} INFO - Started process (PID=20853) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:55:18.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:55:18.555+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:55:18.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:55:19.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:55:20.136+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:55:20.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:55:20.270+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:55:20.269+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:55:20.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.814 seconds
[2023-11-14T17:55:51.103+0000] {processor.py:157} INFO - Started process (PID=20874) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:55:51.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:55:51.107+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:55:51.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:55:52.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:55:52.349+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:55:52.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:55:52.401+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:55:52.401+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:55:52.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.349 seconds
[2023-11-14T17:56:22.882+0000] {processor.py:157} INFO - Started process (PID=20894) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:56:22.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:56:22.890+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:56:22.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:56:24.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:56:25.279+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:56:25.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:56:25.713+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:56:25.712+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:56:25.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.984 seconds
[2023-11-14T17:56:56.759+0000] {processor.py:157} INFO - Started process (PID=20907) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:56:56.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:56:56.766+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:56:56.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:56:58.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:56:58.138+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:56:58.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:56:58.181+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:56:58.181+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:56:58.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.533 seconds
[2023-11-14T17:57:28.879+0000] {processor.py:157} INFO - Started process (PID=20927) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:57:28.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:57:28.884+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:57:28.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:57:30.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:57:30.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:57:30.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:57:30.280+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:57:30.279+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:57:30.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.563 seconds
[2023-11-14T17:58:01.504+0000] {processor.py:157} INFO - Started process (PID=20947) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:58:01.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:58:01.514+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:58:01.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:58:05.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:58:06.017+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:58:06.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:58:06.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:58:06.251+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:58:06.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 5.050 seconds
[2023-11-14T17:58:38.947+0000] {processor.py:157} INFO - Started process (PID=20966) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:58:38.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:58:39.024+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:58:38.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:58:45.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:58:45.634+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:58:45.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:58:45.968+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:58:45.963+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:58:46.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 7.256 seconds
[2023-11-14T17:59:17.122+0000] {processor.py:157} INFO - Started process (PID=20987) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:59:17.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:59:17.184+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:59:17.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:59:20.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:59:21.027+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:59:21.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:59:21.086+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:59:21.086+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:59:21.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.042 seconds
[2023-11-14T17:59:51.413+0000] {processor.py:157} INFO - Started process (PID=21007) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:59:51.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T17:59:51.419+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:59:51.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:59:53.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T17:59:53.450+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:59:53.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T17:59:53.514+0000] {logging_mixin.py:151} INFO - [2023-11-14T17:59:53.514+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T17:59:53.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.151 seconds
[2023-11-14T18:00:24.068+0000] {processor.py:157} INFO - Started process (PID=21026) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:00:24.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:00:24.073+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:00:24.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:00:26.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:00:26.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:00:26.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:00:26.533+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:00:26.531+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:00:26.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.552 seconds
[2023-11-14T18:00:56.839+0000] {processor.py:157} INFO - Started process (PID=21048) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:00:56.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:00:56.843+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:00:56.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:00:58.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:00:58.161+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:00:58.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:00:58.205+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:00:58.205+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:00:58.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.428 seconds
[2023-11-14T18:01:28.355+0000] {processor.py:157} INFO - Started process (PID=21069) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:01:28.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:01:28.358+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:01:28.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:01:29.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:01:29.633+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:01:29.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:01:29.670+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:01:29.670+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:01:29.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.354 seconds
[2023-11-14T18:02:00.250+0000] {processor.py:157} INFO - Started process (PID=21089) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:02:00.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:02:00.253+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:02:00.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:02:01.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:02:01.946+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:02:01.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:02:02.022+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:02:02.022+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:02:02.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.816 seconds
[2023-11-14T18:02:32.788+0000] {processor.py:157} INFO - Started process (PID=21110) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:02:32.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:02:32.800+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:02:32.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:02:33.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:02:33.930+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:02:33.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:02:34.018+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:02:34.017+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:02:34.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.333 seconds
[2023-11-14T18:03:04.479+0000] {processor.py:157} INFO - Started process (PID=21130) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:03:04.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:03:04.483+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:03:04.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:03:05.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:03:05.940+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:03:05.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:03:06.004+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:03:06.004+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:03:06.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.579 seconds
[2023-11-14T18:03:36.711+0000] {processor.py:157} INFO - Started process (PID=21150) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:03:36.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:03:36.719+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:03:36.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:03:37.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:03:38.110+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:03:38.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:03:38.293+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:03:38.292+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:03:38.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.655 seconds
[2023-11-14T18:04:08.680+0000] {processor.py:157} INFO - Started process (PID=21179) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:04:08.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:04:08.683+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:04:08.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:04:09.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:04:09.544+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:04:09.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:04:09.591+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:04:09.590+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:04:09.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.957 seconds
[2023-11-14T18:04:40.068+0000] {processor.py:157} INFO - Started process (PID=21200) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:04:40.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:04:40.074+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:04:40.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:04:41.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:04:41.534+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:04:41.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:04:41.583+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:04:41.582+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:04:41.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.660 seconds
[2023-11-14T18:05:12.375+0000] {processor.py:157} INFO - Started process (PID=21222) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:05:12.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:05:12.378+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:05:12.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:05:13.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:05:13.196+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:05:13.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:05:13.234+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:05:13.233+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:05:13.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.976 seconds
[2023-11-14T18:05:43.967+0000] {processor.py:157} INFO - Started process (PID=21243) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:05:43.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:05:43.974+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:05:43.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:05:45.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:05:45.373+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:05:45.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:05:45.409+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:05:45.408+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:05:45.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.575 seconds
[2023-11-14T18:06:16.040+0000] {processor.py:157} INFO - Started process (PID=21264) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:06:16.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:06:16.044+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:06:16.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:06:16.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:06:16.969+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:06:16.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:06:17.032+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:06:17.032+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:06:17.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.043 seconds
[2023-11-14T18:06:47.531+0000] {processor.py:157} INFO - Started process (PID=21285) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:06:47.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:06:47.540+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:06:47.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:06:48.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:06:48.496+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:06:48.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:06:48.535+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:06:48.534+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:06:48.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.055 seconds
[2023-11-14T18:07:19.135+0000] {processor.py:157} INFO - Started process (PID=21306) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:19.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:07:19.144+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:19.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:20.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:21.063+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:21.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:07:21.163+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:21.162+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:07:21.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.224 seconds
[2023-11-14T18:07:51.158+0000] {processor.py:157} INFO - Started process (PID=21327) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:51.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:07:51.168+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:51.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:53.209+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:53.197+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:07:53.211+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:53.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.102 seconds
[2023-11-14T18:07:58.358+0000] {processor.py:157} INFO - Started process (PID=21337) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:58.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:07:58.362+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:58.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:58.419+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:07:58.411+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 58
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:07:58.421+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:07:58.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.155 seconds
[2023-11-14T18:08:11.992+0000] {processor.py:157} INFO - Started process (PID=21349) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:11.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:08:12.009+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:08:12.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:12.053+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:08:12.051+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 58
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:08:12.054+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:12.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.127 seconds
[2023-11-14T18:08:36.025+0000] {processor.py:157} INFO - Started process (PID=21360) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:36.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:08:36.028+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:08:36.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:36.057+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:08:36.056+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 59
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:08:36.058+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:36.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.073 seconds
[2023-11-14T18:08:55.307+0000] {processor.py:157} INFO - Started process (PID=21378) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:55.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:08:55.312+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:08:55.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:55.346+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:08:55.342+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 58
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:08:55.348+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:08:55.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.095 seconds
[2023-11-14T18:09:25.572+0000] {processor.py:157} INFO - Started process (PID=21397) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:09:25.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:09:25.578+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:09:25.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:09:25.647+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:09:25.644+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 58
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:09:25.649+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:09:25.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.179 seconds
[2023-11-14T18:09:56.703+0000] {processor.py:157} INFO - Started process (PID=21409) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:09:56.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:09:56.709+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:09:56.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:09:56.756+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:09:56.754+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 58
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:09:56.758+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:09:56.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.124 seconds
[2023-11-14T18:10:07.017+0000] {processor.py:157} INFO - Started process (PID=21418) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:07.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:10:07.020+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:10:07.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:08.194+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:10:08.178+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:10:08.199+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:08.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.229 seconds
[2023-11-14T18:10:15.206+0000] {processor.py:157} INFO - Started process (PID=21429) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:15.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:10:15.215+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:10:15.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:18.468+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:10:18.458+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:10:18.471+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:18.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.321 seconds
[2023-11-14T18:10:41.771+0000] {processor.py:157} INFO - Started process (PID=21441) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:41.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:10:41.783+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:10:41.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:43.308+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:10:43.273+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 383, in <module>
    python_callable=download_location_table,
NameError: name 'download_location_table' is not defined
[2023-11-14T18:10:43.317+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:10:43.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.648 seconds
[2023-11-14T18:11:02.154+0000] {processor.py:157} INFO - Started process (PID=21454) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:02.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:11:02.161+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:02.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:02.318+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:02.316+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:11:02.319+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:02.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.249 seconds
[2023-11-14T18:11:05.750+0000] {processor.py:157} INFO - Started process (PID=21455) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:05.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:11:05.768+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:05.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:07.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:09.427+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:09.420+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T18:11:09.432+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:09.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:11:09.545+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:09.544+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:11:09.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.022 seconds
[2023-11-14T18:11:41.862+0000] {processor.py:157} INFO - Started process (PID=21480) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:41.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:11:41.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:41.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:43.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:11:44.252+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:44.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:11:44.478+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:11:44.477+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:11:44.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.914 seconds
[2023-11-14T18:12:20.106+0000] {processor.py:157} INFO - Started process (PID=21501) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:12:20.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:12:20.166+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:12:20.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:12:39.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:12:40.351+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:12:40.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:12:42.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:12:42.536+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:12:43.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 23.413 seconds
[2023-11-14T18:13:15.029+0000] {processor.py:157} INFO - Started process (PID=21530) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:13:15.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:13:15.130+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:13:15.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:13:20.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:13:21.519+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:13:21.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:13:21.679+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:13:21.678+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:13:22.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 7.054 seconds
[2023-11-14T18:13:53.663+0000] {processor.py:157} INFO - Started process (PID=21543) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:13:53.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:13:53.745+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:13:53.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:14:03.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:14:06.266+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:14:06.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:14:07.290+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:14:07.290+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:14:07.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 13.896 seconds
[2023-11-14T18:14:38.427+0000] {processor.py:157} INFO - Started process (PID=21572) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:14:38.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:14:38.441+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:14:38.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:14:46.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:14:46.711+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:14:46.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:14:47.260+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:14:47.259+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:14:47.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 9.320 seconds
[2023-11-14T18:15:18.901+0000] {processor.py:157} INFO - Started process (PID=21593) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:15:18.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:15:18.964+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:15:18.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:15:24.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:15:24.711+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:15:24.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:15:25.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:15:25.074+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:15:25.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 6.814 seconds
[2023-11-14T18:15:56.030+0000] {processor.py:157} INFO - Started process (PID=21607) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:15:56.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:15:56.048+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:15:56.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:16:02.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:16:03.040+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:16:03.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:16:03.718+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:16:03.717+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:16:04.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 8.202 seconds
[2023-11-14T18:16:35.498+0000] {processor.py:157} INFO - Started process (PID=21627) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:16:35.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:16:35.539+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:16:35.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:16:41.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:16:41.541+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:16:41.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:16:41.748+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:16:41.748+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:16:41.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 6.724 seconds
[2023-11-14T18:17:13.520+0000] {processor.py:157} INFO - Started process (PID=21653) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:17:13.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:17:13.562+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:17:13.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:17:20.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:17:20.906+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:17:20.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:17:21.640+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:17:21.639+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:17:21.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 8.783 seconds
[2023-11-14T18:17:52.850+0000] {processor.py:157} INFO - Started process (PID=21675) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:17:52.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:17:52.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:17:52.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:18:01.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:18:01.276+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:18:01.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:18:01.476+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:18:01.476+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:18:01.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 9.204 seconds
[2023-11-14T18:18:32.536+0000] {processor.py:157} INFO - Started process (PID=21695) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:18:32.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:18:32.550+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:18:32.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:18:35.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:18:36.493+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:18:36.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:18:36.708+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:18:36.708+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:18:36.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.473 seconds
[2023-11-14T18:19:07.663+0000] {processor.py:157} INFO - Started process (PID=21717) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:19:07.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:19:07.676+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:19:07.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:19:08.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:19:08.806+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:19:08.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:19:08.982+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:19:08.979+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:19:09.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.560 seconds
[2023-11-14T18:19:39.990+0000] {processor.py:157} INFO - Started process (PID=21741) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:19:39.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:19:39.994+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:19:39.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:19:41.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:19:41.895+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:19:41.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:19:41.980+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:19:41.979+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:19:42.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.105 seconds
[2023-11-14T18:20:12.356+0000] {processor.py:157} INFO - Started process (PID=21762) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:20:12.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:20:12.372+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:20:12.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:20:13.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:20:14.196+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:20:14.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:20:14.296+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:20:14.296+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:20:14.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.033 seconds
[2023-11-14T18:20:44.962+0000] {processor.py:157} INFO - Started process (PID=21784) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:20:44.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:20:44.969+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:20:44.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:20:45.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:20:45.772+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:20:45.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:20:45.821+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:20:45.820+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:20:45.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.935 seconds
[2023-11-14T18:21:16.487+0000] {processor.py:157} INFO - Started process (PID=21806) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:21:16.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:21:16.493+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:21:16.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:21:17.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:21:17.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:21:17.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:21:17.627+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:21:17.626+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:21:17.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.196 seconds
[2023-11-14T18:21:47.881+0000] {processor.py:157} INFO - Started process (PID=21826) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:21:47.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:21:47.893+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:21:47.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:21:49.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:21:50.750+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:21:50.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:21:50.818+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:21:50.817+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:21:50.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.000 seconds
[2023-11-14T18:22:21.451+0000] {processor.py:157} INFO - Started process (PID=21846) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:22:21.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:22:21.454+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:22:21.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:22:22.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:22:22.167+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:22:22.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:22:22.207+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:22:22.207+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:22:22.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.842 seconds
[2023-11-14T18:22:53.051+0000] {processor.py:157} INFO - Started process (PID=21867) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:22:53.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:22:53.066+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:22:53.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:22:54.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:22:54.241+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:22:54.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:22:54.290+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:22:54.290+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:22:54.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.303 seconds
[2023-11-14T18:23:24.885+0000] {processor.py:157} INFO - Started process (PID=21889) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:23:24.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:23:24.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:23:24.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:23:26.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:23:26.597+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:23:26.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:23:26.685+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:23:26.683+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:23:26.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.915 seconds
[2023-11-14T18:23:57.631+0000] {processor.py:157} INFO - Started process (PID=21918) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:23:57.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:23:57.649+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:23:57.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:23:59.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:23:59.459+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:23:59.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:23:59.554+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:23:59.554+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:23:59.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.020 seconds
[2023-11-14T18:24:29.980+0000] {processor.py:157} INFO - Started process (PID=21933) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:24:29.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:24:29.985+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:24:29.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:24:31.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:24:31.486+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:24:31.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:24:31.686+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:24:31.686+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:24:31.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.826 seconds
[2023-11-14T18:25:02.696+0000] {processor.py:157} INFO - Started process (PID=21956) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:25:02.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:25:02.699+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:25:02.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:25:03.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:25:03.638+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:25:03.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:25:03.732+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:25:03.731+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:25:03.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.221 seconds
[2023-11-14T18:25:34.040+0000] {processor.py:157} INFO - Started process (PID=21978) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:25:34.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:25:34.044+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:25:34.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:25:35.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:25:35.810+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:25:35.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:25:35.870+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:25:35.869+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:25:35.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.882 seconds
[2023-11-14T18:26:06.133+0000] {processor.py:157} INFO - Started process (PID=21998) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:26:06.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:26:06.241+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:26:06.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:26:07.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:26:07.941+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:26:07.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:26:08.019+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:26:08.018+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:26:08.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.980 seconds
[2023-11-14T18:26:38.970+0000] {processor.py:157} INFO - Started process (PID=22020) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:26:38.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:26:38.975+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:26:38.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:26:40.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:26:40.348+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:26:40.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:26:40.527+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:26:40.526+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:26:40.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.633 seconds
[2023-11-14T18:27:10.792+0000] {processor.py:157} INFO - Started process (PID=22041) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:10.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:27:10.802+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:10.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:11.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:11.710+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:11.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:27:11.751+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:11.751+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:27:11.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.000 seconds
[2023-11-14T18:27:34.777+0000] {processor.py:157} INFO - Started process (PID=22051) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:34.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:27:34.786+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:34.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:36.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:38.256+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:38.255+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T18:27:38.259+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:38.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:27:38.329+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:38.329+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:27:38.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.760 seconds
[2023-11-14T18:27:44.988+0000] {processor.py:157} INFO - Started process (PID=22063) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:44.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:27:44.993+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:44.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:46.365+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:46.340+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57, in <module>
    kaggle.api.authenticate()
NameError: name 'kaggle' is not defined
[2023-11-14T18:27:46.369+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:46.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.445 seconds
[2023-11-14T18:27:49.241+0000] {processor.py:157} INFO - Started process (PID=22065) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:49.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:27:49.248+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:49.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:50.108+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:50.099+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 57, in <module>
    kaggle.api.dataset_download_files('andradaolteanu/country-mapping-iso-continent-region', path='./..', unzip=True)
NameError: name 'kaggle' is not defined
[2023-11-14T18:27:50.110+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:50.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.910 seconds
[2023-11-14T18:27:52.291+0000] {processor.py:157} INFO - Started process (PID=22067) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:52.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:27:52.299+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:52.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:52.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:53.020+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:53.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:27:53.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:53.059+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:27:53.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.824 seconds
[2023-11-14T18:27:59.925+0000] {processor.py:157} INFO - Started process (PID=22078) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:27:59.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:27:59.947+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:27:59.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:01.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:01.107+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:01.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:28:01.234+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:01.233+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:28:01.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.421 seconds
[2023-11-14T18:28:03.116+0000] {processor.py:157} INFO - Started process (PID=22080) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:03.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:28:03.118+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:03.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:04.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:04.346+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:04.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:28:04.390+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:04.390+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:28:04.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.357 seconds
[2023-11-14T18:28:11.636+0000] {processor.py:157} INFO - Started process (PID=22082) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:11.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:28:11.643+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:11.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:13.092+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:13.074+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:28:13.101+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:13.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.564 seconds
[2023-11-14T18:28:16.985+0000] {processor.py:157} INFO - Started process (PID=22094) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:16.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:28:16.991+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:16.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:19.708+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:19.697+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:28:19.710+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:19.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.771 seconds
[2023-11-14T18:28:50.776+0000] {processor.py:157} INFO - Started process (PID=22116) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:50.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:28:50.786+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:50.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:51.782+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:28:51.769+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:28:51.785+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:28:51.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.070 seconds
[2023-11-14T18:29:22.584+0000] {processor.py:157} INFO - Started process (PID=22129) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:29:22.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:29:22.588+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:29:22.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:29:23.193+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:29:23.184+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:29:23.195+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:29:23.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.644 seconds
[2023-11-14T18:29:53.694+0000] {processor.py:157} INFO - Started process (PID=22158) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:29:53.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:29:53.696+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:29:53.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:29:54.107+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:29:54.098+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:29:54.110+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:29:54.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.440 seconds
[2023-11-14T18:30:24.547+0000] {processor.py:157} INFO - Started process (PID=22179) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:30:24.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:30:24.549+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:30:24.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:30:25.257+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:30:25.248+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:30:25.261+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:30:25.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.747 seconds
[2023-11-14T18:30:55.402+0000] {processor.py:157} INFO - Started process (PID=22199) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:30:55.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:30:55.405+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:30:55.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:30:55.799+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:30:55.790+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:30:55.801+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:30:55.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.445 seconds
[2023-11-14T18:31:26.408+0000] {processor.py:157} INFO - Started process (PID=22222) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:31:26.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:31:26.414+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:31:26.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:31:28.057+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:31:28.038+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:31:28.060+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:31:28.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.712 seconds
[2023-11-14T18:31:58.308+0000] {processor.py:157} INFO - Started process (PID=22243) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:31:58.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:31:58.311+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:31:58.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:31:58.712+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:31:58.702+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
ModuleNotFoundError: No module named 'kaggle'
[2023-11-14T18:31:58.714+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:31:58.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.436 seconds
[2023-11-14T18:35:59.480+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:35:59.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:35:59.495+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:35:59.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:36:05.219+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:36:05.183+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:36:05.223+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:36:05.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 5.864 seconds
[2023-11-14T18:36:36.306+0000] {processor.py:157} INFO - Started process (PID=141) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:36:36.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:36:36.310+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:36:36.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:36:36.890+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:36:36.881+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:36:36.891+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:36:36.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.617 seconds
[2023-11-14T18:37:07.428+0000] {processor.py:157} INFO - Started process (PID=175) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:37:07.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:37:07.440+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:37:07.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:37:08.253+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:37:08.246+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:37:08.263+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:37:08.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.899 seconds
[2023-11-14T18:37:38.987+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:37:38.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:37:38.991+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:37:38.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:37:39.556+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:37:39.547+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:37:39.557+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:37:39.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.595 seconds
[2023-11-14T18:38:10.079+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:38:10.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:38:10.082+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:38:10.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:38:10.667+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:38:10.656+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:38:10.668+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:38:10.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.623 seconds
[2023-11-14T18:38:41.278+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:38:41.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:38:41.281+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:38:41.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:38:41.920+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:38:41.905+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:38:41.922+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:38:41.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.678 seconds
[2023-11-14T18:39:12.435+0000] {processor.py:157} INFO - Started process (PID=295) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:39:12.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:39:12.438+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:39:12.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:39:12.944+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:39:12.937+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:39:12.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:39:12.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.537 seconds
[2023-11-14T18:39:43.474+0000] {processor.py:157} INFO - Started process (PID=330) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:39:43.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:39:43.477+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:39:43.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:39:44.018+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:39:44.010+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:39:44.019+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:39:44.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.572 seconds
[2023-11-14T18:40:14.598+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:40:14.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:40:14.601+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:40:14.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:40:15.171+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:40:15.156+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:40:15.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:40:15.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.603 seconds
[2023-11-14T18:40:45.691+0000] {processor.py:157} INFO - Started process (PID=393) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:40:45.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:40:45.694+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:40:45.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:40:46.205+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:40:46.197+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:40:46.206+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:40:46.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.541 seconds
[2023-11-14T18:41:16.983+0000] {processor.py:157} INFO - Started process (PID=419) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:41:16.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:41:16.986+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:41:16.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:41:17.718+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:41:17.710+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:41:17.719+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:41:17.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.773 seconds
[2023-11-14T18:41:48.322+0000] {processor.py:157} INFO - Started process (PID=454) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:41:48.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:41:48.325+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:41:48.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:41:48.901+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:41:48.880+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:41:48.902+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:41:48.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.665 seconds
[2023-11-14T18:42:19.464+0000] {processor.py:157} INFO - Started process (PID=481) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:42:19.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:42:19.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:42:19.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:42:20.989+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:42:20.973+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:42:20.990+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:42:21.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.565 seconds
[2023-11-14T18:42:51.550+0000] {processor.py:157} INFO - Started process (PID=516) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:42:51.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:42:51.564+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:42:51.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:42:52.275+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:42:52.267+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:42:52.276+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:42:52.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.761 seconds
[2023-11-14T18:43:18.211+0000] {processor.py:157} INFO - Started process (PID=544) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:18.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:43:18.227+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:18.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:21.046+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:21.035+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:43:21.047+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:21.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.906 seconds
[2023-11-14T18:43:31.883+0000] {processor.py:157} INFO - Started process (PID=555) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:31.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:43:31.923+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:31.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:33.676+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:33.664+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:43:33.678+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:33.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.873 seconds
[2023-11-14T18:43:38.867+0000] {processor.py:157} INFO - Started process (PID=572) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:38.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:43:38.870+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:38.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:39.852+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:39.842+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:43:39.853+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:39.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.018 seconds
[2023-11-14T18:43:40.987+0000] {processor.py:157} INFO - Started process (PID=580) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:40.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:43:40.992+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:40.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:42.464+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:43:42.454+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:43:42.466+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:43:42.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.516 seconds
[2023-11-14T18:44:12.968+0000] {processor.py:157} INFO - Started process (PID=607) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:12.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:44:12.971+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:44:12.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:13.570+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:44:13.563+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:44:13.571+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:13.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.636 seconds
[2023-11-14T18:44:43.780+0000] {processor.py:157} INFO - Started process (PID=642) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:43.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:44:43.782+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:44:43.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:44.282+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:44:44.272+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:44:44.283+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:44.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.529 seconds
[2023-11-14T18:44:56.772+0000] {processor.py:157} INFO - Started process (PID=660) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:56.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:44:56.782+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:44:56.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:59.626+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:44:59.520+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:44:59.634+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:44:59.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.031 seconds
[2023-11-14T18:45:30.178+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:45:30.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:45:30.181+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:45:30.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:45:30.736+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:45:30.722+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:45:30.737+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:45:30.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.586 seconds
[2023-11-14T18:46:01.480+0000] {processor.py:157} INFO - Started process (PID=722) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:01.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:46:01.483+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:01.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:02.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:02.020+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:46:02.030+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:02.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.583 seconds
[2023-11-14T18:46:32.612+0000] {processor.py:157} INFO - Started process (PID=749) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:32.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:46:32.617+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:32.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:33.747+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:33.738+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:46:33.748+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:33.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.168 seconds
[2023-11-14T18:46:36.930+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:36.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:46:36.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:36.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:40.163+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:39.806+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:46:40.194+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:40.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 3.578 seconds
[2023-11-14T18:46:42.640+0000] {processor.py:157} INFO - Started process (PID=774) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:42.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:46:42.647+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:42.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:45.484+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:46:45.474+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:46:45.486+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:46:45.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.902 seconds
[2023-11-14T18:47:15.618+0000] {processor.py:157} INFO - Started process (PID=801) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:47:15.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:47:15.620+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:47:15.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:47:16.221+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:47:16.212+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:47:16.221+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:47:16.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.636 seconds
[2023-11-14T18:47:34.387+0000] {processor.py:157} INFO - Started process (PID=818) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:47:34.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:47:34.391+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:47:34.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:47:35.313+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:47:35.303+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:47:35.315+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:47:35.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.975 seconds
[2023-11-14T18:48:05.777+0000] {processor.py:157} INFO - Started process (PID=853) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:48:05.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:48:05.779+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:48:05.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:48:06.260+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:48:06.252+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:48:06.261+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:48:06.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.510 seconds
[2023-11-14T18:48:36.428+0000] {processor.py:157} INFO - Started process (PID=880) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:48:36.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:48:36.430+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:48:36.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:48:36.933+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:48:36.926+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:48:36.934+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:48:36.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.533 seconds
[2023-11-14T18:49:07.129+0000] {processor.py:157} INFO - Started process (PID=907) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:49:07.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:49:07.131+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:49:07.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:49:07.943+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:49:07.929+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:49:07.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:49:07.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.855 seconds
[2023-11-14T18:49:38.273+0000] {processor.py:157} INFO - Started process (PID=943) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:49:38.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:49:38.277+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:49:38.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:49:39.009+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:49:39.001+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:49:39.010+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:49:39.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.763 seconds
[2023-11-14T18:50:09.873+0000] {processor.py:157} INFO - Started process (PID=970) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:50:09.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:50:09.876+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:50:09.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:50:10.457+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:50:10.442+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:50:10.460+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:50:10.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.621 seconds
[2023-11-14T18:50:40.972+0000] {processor.py:157} INFO - Started process (PID=1007) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:50:40.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:50:40.976+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:50:40.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:50:42.986+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:50:42.973+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:50:42.991+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:50:43.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.109 seconds
[2023-11-14T18:51:13.848+0000] {processor.py:157} INFO - Started process (PID=1035) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:51:13.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:51:13.851+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:51:13.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:51:14.355+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:51:14.348+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:51:14.356+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:51:14.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.532 seconds
[2023-11-14T18:51:44.798+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:51:44.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:51:44.803+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:51:44.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:51:45.964+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:51:45.946+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:51:45.969+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:51:46.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.235 seconds
[2023-11-14T18:52:16.526+0000] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:52:16.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:52:16.531+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:52:16.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:52:17.305+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:52:17.292+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:52:17.306+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:52:17.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.813 seconds
[2023-11-14T18:52:47.834+0000] {processor.py:157} INFO - Started process (PID=1126) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:52:47.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:52:47.837+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:52:47.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:52:48.421+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:52:48.413+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:52:48.422+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:52:48.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.621 seconds
[2023-11-14T18:53:18.851+0000] {processor.py:157} INFO - Started process (PID=1153) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:53:18.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:53:18.854+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:53:18.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:53:19.370+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:53:19.363+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:53:19.370+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:53:19.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T18:53:49.928+0000] {processor.py:157} INFO - Started process (PID=1189) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:53:49.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:53:49.937+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:53:49.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:53:50.547+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:53:50.538+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:53:50.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:53:50.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.649 seconds
[2023-11-14T18:54:21.018+0000] {processor.py:157} INFO - Started process (PID=1216) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:54:21.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:54:21.021+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:54:21.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:54:21.779+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:54:21.772+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:54:21.780+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:54:21.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.789 seconds
[2023-11-14T18:54:52.211+0000] {processor.py:157} INFO - Started process (PID=1251) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:54:52.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:54:52.214+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:54:52.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:54:52.767+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:54:52.759+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:54:52.768+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:54:52.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.585 seconds
[2023-11-14T18:55:23.247+0000] {processor.py:157} INFO - Started process (PID=1280) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:55:23.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:55:23.251+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:55:23.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:55:23.757+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:55:23.743+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:55:23.759+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:55:23.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.545 seconds
[2023-11-14T18:55:54.793+0000] {processor.py:157} INFO - Started process (PID=1315) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:55:54.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:55:54.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:55:54.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:55:55.664+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:55:55.657+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:55:55.665+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:55:55.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.899 seconds
[2023-11-14T18:56:26.534+0000] {processor.py:157} INFO - Started process (PID=1343) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:56:26.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:56:26.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:56:26.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:56:27.623+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:56:27.613+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:56:27.624+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:56:27.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.123 seconds
[2023-11-14T18:56:57.809+0000] {processor.py:157} INFO - Started process (PID=1370) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:56:57.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:56:57.812+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:56:57.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:56:58.501+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:56:58.491+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:56:58.502+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:56:58.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.734 seconds
[2023-11-14T18:57:28.936+0000] {processor.py:157} INFO - Started process (PID=1405) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:28.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:28.938+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:28.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:29.614+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:29.605+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:57:29.615+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:29.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.705 seconds
[2023-11-14T18:57:36.170+0000] {processor.py:157} INFO - Started process (PID=1415) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:36.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:36.181+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:36.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:36.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:36.220+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 62
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:57:36.227+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:36.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.115 seconds
[2023-11-14T18:57:43.372+0000] {processor.py:157} INFO - Started process (PID=1426) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:43.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:43.374+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:43.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:43.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:43.394+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 62
    def download_cases_deaths():
    ^
IndentationError: expected an indented block
[2023-11-14T18:57:43.396+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:43.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.051 seconds
[2023-11-14T18:57:49.541+0000] {processor.py:157} INFO - Started process (PID=1427) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:49.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:49.544+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:49.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:50.372+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:50.364+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:57:50.373+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:50.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.855 seconds
[2023-11-14T18:57:52.516+0000] {processor.py:157} INFO - Started process (PID=1441) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:52.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:52.521+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:52.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:53.830+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:53.793+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:57:53.831+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:53.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.373 seconds
[2023-11-14T18:57:55.015+0000] {processor.py:157} INFO - Started process (PID=1451) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:55.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:55.022+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:55.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:56.295+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:56.286+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:57:56.296+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:56.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.324 seconds
[2023-11-14T18:57:57.058+0000] {processor.py:157} INFO - Started process (PID=1459) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:57.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:57:57.060+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:57.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:58.202+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:57:58.193+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:57:58.203+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:57:58.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.191 seconds
[2023-11-14T18:58:01.187+0000] {processor.py:157} INFO - Started process (PID=1469) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:01.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:58:01.190+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:01.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:02.279+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:02.263+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 17, in <module>
    import kaggle
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/__init__.py", line 23, in <module>
    api.authenticate()
  File "/home/airflow/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py", line 403, in authenticate
    raise IOError('Could not find {}. Make sure it\'s located in'
OSError: Could not find kaggle.json. Make sure it's located in /home/airflow/.kaggle. Or use the environment method.
[2023-11-14T18:58:02.281+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:02.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.155 seconds
[2023-11-14T18:58:06.379+0000] {processor.py:157} INFO - Started process (PID=1477) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:06.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:58:06.382+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:06.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:06.791+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:06.784+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    os.environ["KAGGLE_USERNAME"] = "nicolacn"
NameError: name 'os' is not defined
[2023-11-14T18:58:06.794+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:06.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.439 seconds
[2023-11-14T18:58:07.468+0000] {processor.py:157} INFO - Started process (PID=1486) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:07.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:58:07.470+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:07.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:08.545+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:08.521+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/Dag_postgres.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/Dag_postgres.py", line 18, in <module>
    os.environ["KAGGLE_USERNAME"] = "nicolacn"
NameError: name 'os' is not defined
[2023-11-14T18:58:08.554+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:08.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.192 seconds
[2023-11-14T18:58:29.360+0000] {processor.py:157} INFO - Started process (PID=1498) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:29.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:58:29.393+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:29.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:32.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:58:33.590+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:33.589+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:covid_data_dag_postgres' as access control is unset.
[2023-11-14T18:58:33.592+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:33.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:58:33.644+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:58:33.644+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:58:33.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.551 seconds
[2023-11-14T18:59:00.674+0000] {processor.py:157} INFO - Started process (PID=1520) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:59:00.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:59:00.679+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:59:00.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:59:01.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:59:01.381+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:59:01.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:59:01.460+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:59:01.458+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:59:01.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.883 seconds
[2023-11-14T18:59:32.069+0000] {processor.py:157} INFO - Started process (PID=1552) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:59:32.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T18:59:32.076+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:59:32.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:59:33.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T18:59:33.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:59:33.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T18:59:39.453+0000] {logging_mixin.py:151} INFO - [2023-11-14T18:59:39.453+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T18:59:39.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 7.425 seconds
[2023-11-14T19:00:10.812+0000] {processor.py:157} INFO - Started process (PID=1580) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:00:10.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:00:10.846+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:00:10.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:00:13.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:00:15.075+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:00:15.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:00:15.133+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:00:15.132+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:00:15.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 4.481 seconds
[2023-11-14T19:00:45.783+0000] {processor.py:157} INFO - Started process (PID=1601) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:00:45.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:00:45.785+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:00:45.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:00:46.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:00:46.261+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:00:46.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:00:46.536+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:00:46.535+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:00:46.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.791 seconds
[2023-11-14T19:01:17.499+0000] {processor.py:157} INFO - Started process (PID=1632) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:01:17.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:01:17.502+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:01:17.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:01:18.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:01:18.997+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:01:18.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:01:19.048+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:01:19.048+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:01:19.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.588 seconds
[2023-11-14T19:01:49.709+0000] {processor.py:157} INFO - Started process (PID=1654) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:01:49.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:01:49.713+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:01:49.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:01:50.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:01:50.480+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:01:50.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:01:50.520+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:01:50.519+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:01:50.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.859 seconds
[2023-11-14T19:02:19.051+0000] {processor.py:157} INFO - Started process (PID=1675) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:19.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:02:19.053+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:19.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:19.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:19.881+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:19.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:02:20.228+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:20.227+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:02:20.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.330 seconds
[2023-11-14T19:02:25.489+0000] {processor.py:157} INFO - Started process (PID=1688) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:25.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:02:25.493+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:25.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:26.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:26.798+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:26.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:02:26.894+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:26.893+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:02:26.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.463 seconds
[2023-11-14T19:02:31.002+0000] {processor.py:157} INFO - Started process (PID=1690) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:31.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:02:31.005+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:31.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:31.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:02:31.677+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:31.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:02:31.706+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:02:31.705+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:02:31.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.744 seconds
[2023-11-14T19:03:02.052+0000] {processor.py:157} INFO - Started process (PID=1713) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:03:02.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:03:02.055+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:03:02.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:03:02.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:03:02.618+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:03:02.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:03:02.643+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:03:02.643+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:03:02.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.618 seconds
[2023-11-14T19:03:32.886+0000] {processor.py:157} INFO - Started process (PID=1745) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:03:32.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:03:32.888+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:03:32.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:03:33.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:03:33.392+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:03:33.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:03:33.578+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:03:33.578+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:03:33.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.719 seconds
[2023-11-14T19:04:03.818+0000] {processor.py:157} INFO - Started process (PID=1767) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:04:03.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:04:03.821+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:04:03.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:04:04.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:04:04.395+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:04:04.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:04:04.424+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:04:04.424+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:04:04.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.632 seconds
[2023-11-14T19:04:34.702+0000] {processor.py:157} INFO - Started process (PID=1796) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:04:34.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:04:34.706+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:04:34.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:04:35.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:04:35.434+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:04:35.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:04:35.466+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:04:35.466+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:04:35.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.816 seconds
[2023-11-14T19:05:05.676+0000] {processor.py:157} INFO - Started process (PID=1817) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:05:05.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:05:05.678+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:05:05.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:05:06.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:05:06.133+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:05:06.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:05:06.295+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:05:06.295+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:05:06.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.656 seconds
[2023-11-14T19:05:36.630+0000] {processor.py:157} INFO - Started process (PID=1846) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:05:36.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:05:36.636+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:05:36.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:05:37.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:05:37.229+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:05:37.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:05:37.253+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:05:37.253+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:05:37.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.649 seconds
[2023-11-14T19:06:07.465+0000] {processor.py:157} INFO - Started process (PID=1867) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:06:07.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:06:07.467+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:06:07.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:06:08.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:06:08.083+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:06:08.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:06:08.117+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:06:08.117+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:06:08.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.682 seconds
[2023-11-14T19:06:38.450+0000] {processor.py:157} INFO - Started process (PID=1889) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:06:38.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:06:38.452+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:06:38.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:06:38.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:06:39.031+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:06:39.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:06:39.057+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:06:39.057+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:06:39.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.634 seconds
[2023-11-14T19:07:09.384+0000] {processor.py:157} INFO - Started process (PID=1919) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:07:09.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:07:09.386+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:07:09.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:07:09.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:07:09.955+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:07:09.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:07:09.980+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:07:09.980+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:07:10.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.623 seconds
[2023-11-14T19:07:40.154+0000] {processor.py:157} INFO - Started process (PID=1940) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:07:40.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:07:40.156+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:07:40.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:07:40.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:07:40.777+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:07:40.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:07:40.803+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:07:40.803+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:07:40.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.676 seconds
[2023-11-14T19:08:11.050+0000] {processor.py:157} INFO - Started process (PID=1970) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:08:11.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:08:11.052+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:08:11.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:08:11.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:08:11.602+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:08:11.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:08:11.626+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:08:11.626+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:08:11.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.604 seconds
[2023-11-14T19:08:41.852+0000] {processor.py:157} INFO - Started process (PID=1990) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:08:41.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:08:41.855+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:08:41.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:08:42.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:08:42.409+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:08:42.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:08:42.435+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:08:42.435+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:08:42.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.609 seconds
[2023-11-14T19:09:12.824+0000] {processor.py:157} INFO - Started process (PID=2019) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:09:12.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:09:12.828+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:09:12.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:09:13.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:09:13.430+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:09:13.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:09:13.472+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:09:13.472+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:09:13.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.692 seconds
[2023-11-14T19:09:43.817+0000] {processor.py:157} INFO - Started process (PID=2041) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:09:43.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:09:43.819+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:09:43.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:09:44.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:09:44.572+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:09:44.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:09:44.598+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:09:44.598+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:09:44.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.811 seconds
[2023-11-14T19:10:14.786+0000] {processor.py:157} INFO - Started process (PID=2062) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:10:14.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:10:14.791+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:10:14.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:10:15.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:10:15.542+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:10:15.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:10:15.627+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:10:15.627+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:10:15.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.894 seconds
[2023-11-14T19:10:45.827+0000] {processor.py:157} INFO - Started process (PID=2092) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:10:45.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:10:45.835+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:10:45.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:10:46.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:10:46.620+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:10:46.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:10:46.650+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:10:46.649+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:10:46.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.863 seconds
[2023-11-14T19:11:17.042+0000] {processor.py:157} INFO - Started process (PID=2113) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:11:17.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:11:17.044+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:11:17.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:11:17.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:11:17.590+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:11:17.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:11:17.616+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:11:17.616+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:11:17.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.602 seconds
[2023-11-14T19:11:47.993+0000] {processor.py:157} INFO - Started process (PID=2134) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:11:47.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:11:48.000+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:11:48.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:11:48.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:11:48.736+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:11:48.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:11:48.768+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:11:48.768+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:11:48.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.805 seconds
[2023-11-14T19:12:19.111+0000] {processor.py:157} INFO - Started process (PID=2163) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:12:19.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:12:19.114+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:12:19.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:12:19.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:12:19.704+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:12:19.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:12:19.729+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:12:19.729+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:12:19.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.647 seconds
[2023-11-14T19:12:50.104+0000] {processor.py:157} INFO - Started process (PID=2184) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:12:50.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:12:50.107+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:12:50.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:12:50.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:12:50.898+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:12:50.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:12:50.928+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:12:50.927+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:12:50.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.859 seconds
[2023-11-14T19:13:21.333+0000] {processor.py:157} INFO - Started process (PID=2213) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:13:21.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:13:21.335+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:13:21.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:13:21.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:13:21.957+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:13:21.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:13:21.980+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:13:21.980+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:13:22.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.674 seconds
[2023-11-14T19:13:52.612+0000] {processor.py:157} INFO - Started process (PID=2234) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:13:52.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:13:52.614+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:13:52.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:13:53.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:13:53.198+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:13:53.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:13:53.225+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:13:53.224+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:13:53.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.640 seconds
[2023-11-14T19:14:23.426+0000] {processor.py:157} INFO - Started process (PID=2261) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:14:23.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:14:23.429+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:14:23.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:14:24.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:14:24.499+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:14:24.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:14:24.554+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:14:24.554+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:14:24.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.162 seconds
[2023-11-14T19:14:55.051+0000] {processor.py:157} INFO - Started process (PID=2282) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:14:55.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:14:55.054+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:14:55.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:14:55.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:14:55.699+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:14:55.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:14:55.751+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:14:55.750+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:14:55.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.763 seconds
[2023-11-14T19:15:26.363+0000] {processor.py:157} INFO - Started process (PID=2303) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:26.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:15:26.366+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:26.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:27.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:27.303+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:27.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:15:27.383+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:27.382+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:15:27.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.080 seconds
[2023-11-14T19:15:44.888+0000] {processor.py:157} INFO - Started process (PID=2325) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:44.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:15:44.891+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:44.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:45.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:45.744+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:45.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:15:45.772+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:45.772+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:15:45.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.933 seconds
[2023-11-14T19:15:48.037+0000] {processor.py:157} INFO - Started process (PID=2327) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:48.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:15:48.055+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:48.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:49.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:49.742+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:49.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:15:49.797+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:49.797+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:15:49.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.833 seconds
[2023-11-14T19:15:53.977+0000] {processor.py:157} INFO - Started process (PID=2337) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:53.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:15:53.981+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:53.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:54.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:54.712+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:54.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:15:54.742+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:54.742+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:15:54.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.806 seconds
[2023-11-14T19:15:57.199+0000] {processor.py:157} INFO - Started process (PID=2339) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:57.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:15:57.202+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:57.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:57.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:57.897+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:57.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:15:57.958+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:57.958+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:15:58.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.908 seconds
[2023-11-14T19:15:58.910+0000] {processor.py:157} INFO - Started process (PID=2343) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:58.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:15:58.913+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:58.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:59.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:15:59.595+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:59.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:15:59.621+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:15:59.621+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:15:59.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.751 seconds
[2023-11-14T19:16:01.627+0000] {processor.py:157} INFO - Started process (PID=2345) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:01.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:16:01.630+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:01.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:02.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:02.380+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:02.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:16:02.407+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:02.407+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:16:02.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.817 seconds
[2023-11-14T19:16:06.565+0000] {processor.py:157} INFO - Started process (PID=2357) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:06.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:16:06.568+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:06.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:07.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:07.426+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:07.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:16:07.510+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:07.509+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:16:07.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.003 seconds
[2023-11-14T19:16:08.616+0000] {processor.py:157} INFO - Started process (PID=2359) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:08.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:16:08.619+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:08.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:09.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:09.550+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:09.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:16:09.590+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:09.590+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:16:09.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 1.020 seconds
[2023-11-14T19:16:19.831+0000] {processor.py:157} INFO - Started process (PID=2361) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:19.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:16:19.833+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:19.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:20.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:20.426+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:20.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:16:20.453+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:20.453+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:16:20.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.660 seconds
[2023-11-14T19:16:31.026+0000] {processor.py:157} INFO - Started process (PID=2372) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:31.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:16:31.029+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:31.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:32.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:16:32.586+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:32.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:16:32.720+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:16:32.719+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:16:33.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 2.060 seconds
[2023-11-14T19:17:03.762+0000] {processor.py:157} INFO - Started process (PID=2403) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:17:03.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:17:03.764+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:17:03.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:17:04.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:17:04.358+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:17:04.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:17:04.388+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:17:04.388+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:17:04.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.655 seconds
[2023-11-14T19:17:35.376+0000] {processor.py:157} INFO - Started process (PID=2423) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:17:35.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:17:35.378+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:17:35.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:17:35.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:17:35.930+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:17:35.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:17:35.955+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:17:35.954+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:17:35.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.606 seconds
[2023-11-14T19:18:06.497+0000] {processor.py:157} INFO - Started process (PID=2452) to work on /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:18:06.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/Dag_postgres.py for tasks to queue
[2023-11-14T19:18:06.499+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:18:06.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:18:07.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['covid_data_dag_postgres']) retrieved from /opt/airflow/dags/Dag_postgres.py
[2023-11-14T19:18:07.139+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:18:07.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2023-11-14T19:18:07.163+0000] {logging_mixin.py:151} INFO - [2023-11-14T19:18:07.162+0000] {dag.py:3696} INFO - Setting next_dagrun for covid_data_dag_postgres to 2023-11-14T00:00:00+00:00, run_after=2023-11-15T00:00:00+00:00
[2023-11-14T19:18:07.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/Dag_postgres.py took 0.700 seconds
